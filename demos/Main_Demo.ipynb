{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwNGLlWWTq-Q"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHFBo5CpTq-R"
      },
      "source": [
        "# Transformer Lens Main Demo Notebook\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
        "\n",
        "This is a reference notebook covering the main features of the [TransformerLens](https://github.com/neelnanda-io/TransformerLens) library for mechanistic interpretability. See [Callum McDougall's tutorial](https://transformerlens-intro.streamlit.app/TransformerLens_&_induction_circuits) for a more structured and gentler introduction to the library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juIhK_VUTq-R"
      },
      "source": [
        "**Tips for reading this Colab:**\n",
        "* You can run all this code for yourself!\n",
        "* The graphs are interactive!\n",
        "* Use the table of contents pane in the sidebar to navigate\n",
        "* Collapse irrelevant sections with the dropdown arrows\n",
        "* Search the page using the search in the sidebar, not CTRL+F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_gdyED3Tq-S"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hSAcVv_fTq-S",
        "outputId": "4e2f04ac-9d50-4e9b-e797-90bf7db13bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-1.14.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.23.0 (from transformer_lens)\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer_lens)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.25-py3-none-any.whl (39 kB)\n",
            "Collecting numpy>=1.24 (from transformer_lens)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.0)\n",
            "Collecting torch!=2.0,!=2.1.0,>=1.10 (from transformer_lens)\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m571.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.1)\n",
            "Requirement already satisfied: transformers>=4.34 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.35.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.5.0)\n",
            "Collecting wandb>=0.13.5 (from transformer_lens)\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.3)\n",
            "Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n",
            "Collecting typing-extensions (from transformer_lens)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (0.15.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading sentry_sdk-1.40.0-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: better-abc, typing-extensions, typeguard, triton, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, gitdb, nvidia-cusolver-cu12, GitPython, wandb, torch, datasets, accelerate, transformer_lens\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.41 accelerate-0.26.1 beartype-0.14.1 better-abc-0.0.3 datasets-2.16.1 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 jaxtyping-0.2.25 multiprocess-0.70.15 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 sentry-sdk-1.40.0 setproctitle-1.3.3 smmap-5.0.1 torch-2.2.0 transformer_lens-1.14.0 triton-2.2.0 typeguard-2.13.3 typing-extensions-4.9.0 wandb-0.16.2\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (7.0.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (1.26.3)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from circuitsvis)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.2.0)\n",
            "Collecting triton==2.1.0 (from circuitsvis)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.3.101)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch>=1.10 (from circuitsvis)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->circuitsvis) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->circuitsvis) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nccl-cu12, torch, circuitsvis\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.0\n",
            "    Uninstalling torch-2.2.0:\n",
            "      Successfully uninstalled torch-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed circuitsvis-1.43.2 nvidia-nccl-cu12-2.18.1 torch-2.1.2 triton-2.1.0\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n",
            "\n",
            "  \n",
            "  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n",
            "  install Node.js is deprecated now and will eventually be made inactive.\n",
            "\n",
            "  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n",
            "  instructions to migrate your repo.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n",
            "  information about which versions of Node.js and which Linux distributions\n",
            "  are supported and how to install it.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\n",
            "                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n",
            "Continuing in 60 seconds (press Ctrl-C to abort) ...\n",
            "\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,333 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,268 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,678 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,164 kB]\n",
            "Fetched 6,693 kB in 2s (3,013 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,359 B in 2s (3,525 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 1s (44.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 121730 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "DEVELOPMENT_MODE = False\n",
        "# Detect if we're running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install if in Colab\n",
        "if IN_COLAB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis\n",
        "    # Install a faster Node version\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
        "\n",
        "# Hot reload in development mode & not running on the CD\n",
        "if not IN_COLAB:\n",
        "    from IPython import get_ipython\n",
        "    ip = get_ipython()\n",
        "    if not ip.extension_manager.loaded:\n",
        "        ip.extension_manager.load('autoreload')\n",
        "        %autoreload 2\n",
        "\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
        "IN_GITHUB = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PRKLZv0HTq-T",
        "outputId": "d3c0d786-d9e3-43b7-a51d-adf810ed9bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "miqJmY_3Tq-T",
        "outputId": "351f9672-ce73-4f5d-b318-448b134161d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7ab9542127a0>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-9c0aa667-bfd2\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-9c0aa667-bfd2\",\n",
              "      Hello,\n",
              "      {\"name\": \"Neel\"}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import circuitsvis as cv\n",
        "# Testing that the library works\n",
        "cv.examples.hello(\"Neel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FEtRAtT1Tq-U"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "from jaxtyping import Float\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l8pKG8LkTq-U"
      },
      "outputs": [],
      "source": [
        "# import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, FactoredMatrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rUGxxZeTq-U"
      },
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0VFDCZWxTq-U",
        "outputId": "2e02050a-dada-487e-c110-4f53bf1e339c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7ab8552f4490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4k9p8s4Tq-U"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DE-JAX-aTq-U"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfeg6b_OTq-U"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTaB6zsATq-U"
      },
      "source": [
        "This is a demo notebook for [TransformerLens](https://github.com/neelnanda-io/TransformerLens), **a library I ([Neel Nanda](https://neelnanda.io)) wrote for doing [mechanistic interpretability](https://distill.pub/2020/circuits/zoom-in/) of GPT-2 Style language models.** The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3, PaLM, etc), yet we have no idea how they work nor how to write one ourselves. This offends me greatly, and I would like to solve this! Mechanistic interpretability is a very young and small field, and there are a *lot* of open problems - if you would like to help, please try working on one! **If you want to skill up, check out [my guide to getting started](https://neelnanda.io/getting-started), and if you want to jump into an open problem check out my sequence [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems).**\n",
        "\n",
        "I wrote this library because after I left the Anthropic interpretability team and started doing independent research, I got extremely frustrated by the state of open source tooling. There's a lot of excellent infrastructure like HuggingFace and DeepSpeed to *use* or *train* models, but very little to dig into their internals and reverse engineer how they work. **This library tries to solve that**, and to make it easy to get into the field even if you don't work at an industry org with real infrastructure! The core features were heavily inspired by [Anthropic's excellent Garcon tool](https://transformer-circuits.pub/2021/garcon/index.html). Credit to Nelson Elhage and Chris Olah for building Garcon and showing me the value of good infrastructure for accelerating exploratory research!\n",
        "\n",
        "The core design principle I've followed is to enable exploratory analysis - one of the most fun parts of mechanistic interpretability compared to normal ML is the extremely short feedback loops! The point of this library is to keep the gap between having an experiment idea and seeing the results as small as possible, to make it easy for **research to feel like play** and to enter a flow state. This notebook demonstrates how the library works and how to use it, but if you want to see how well it works for exploratory research, check out [my notebook analysing Indirect Objection Identification](https://neelnanda.io/exploratory-analysis-demo) or [my recording of myself doing research](https://www.youtube.com/watch?v=yo4QvDn-vsU)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRNreRT3Tq-U"
      },
      "source": [
        "## Loading and Running Models\n",
        "\n",
        "TransformerLens comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. For this demo notebook we'll look at GPT-2 Small, an 80M parameter model, see the Available Models section for info on the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IG_6eKQ1Tq-U"
      },
      "outputs": [],
      "source": [
        "device = utils.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rfiAmh_sTq-U",
        "outputId": "759caf03-e132-4dca-edea-0b6ca170382f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "c92f4727002149d18498a871a7f5e5ed",
            "2091b2c859f54d3ebe3f1e1add0e93ef",
            "072507e920d5403aa52586d2c9fac973",
            "3287f0bea87f4d4d9db66c4edeacf8d5",
            "eee1e9d7530e415ab3e42512ee8e3209",
            "e32f0a93ce9443b5a9503107e8e0bf16",
            "5e733695b21f4d58816e4570b4d6a827",
            "7147bd0fc7f540ba859d4c1de0953fa1",
            "db24854bb8bc4cca89f5ceaa4d44af24",
            "bcb759d7d33942b694c37c87e944949b",
            "7ac7ca8ee960434eaf93a9714a729766",
            "5ecf6ab872f742229b2cb273d1e64537",
            "ae3b48589f1b47398ae42509de9682bb",
            "18dff247fe8c466cab56231e7c842a52",
            "83ed570715884746a483b21794dac845",
            "f1eded877c1943b6add09f1d673c6834",
            "8c3e0d35a42d48abb5db20b0955fb5ec",
            "0389cf284821416ea0e753b58b70755f",
            "6c883751fe624ed6b54cd6d6c0ad0c8b",
            "edb7e9cecf4b4e6199c689f03bdf9202",
            "3538e6f0d9a7451ba2366e5f848ee49c",
            "d1264a2b3d7c4057bd62bf7049eb408f",
            "18cfe09e499b4e04b3435171de3ea2c6",
            "89cc1cb9f2de43788133ad3500dc7d7c",
            "159fb8938c594ffcb8f9c8641583363c",
            "0965257960af4f8ca2b3985735ec83eb",
            "cd8a648b154a4a93b9205e5bdac5314f",
            "14855bc51e9d473785a4d88233211f2a",
            "cd475ddf6723418faf2031998097d413",
            "171c6aae133b4b6687e72ce6fe41779f",
            "d19d71d6066c472b96738c303f10bbd5",
            "8a200d6e9676452ba20fad03bc7a188d",
            "4ab784bf88dd4cb8ae2852742e212fc5",
            "b8fe3d93130d4656a6b2f006e228fa6c",
            "6d9bac38228c421f85230458ee5d7cf8",
            "26c0dde47219425a9e6adb7df1469e6f",
            "fc020fb6426549beb69285faa9f47b9e",
            "b57d629055854c009c18dd76ea0a845b",
            "550b5195fafa4151a2444a4a26afd3ee",
            "f61603958ef744f08295362b6df2e063",
            "7c3149a028844b7ba52b9a559120abf7",
            "6cd5adbbb390480fbce95a7854e6b944",
            "8c593c1e5663466c93f349867ee4cb3f",
            "bac498965ca2480b8416872d21ccbe86",
            "1d524ff688064d78b038c14c394f2d06",
            "51a882e6004040cba1ca3b95b8bc2079",
            "c101add0002945c6b9c30eac7926d80f",
            "4394f3ea155a4769b492daef20cfdd5f",
            "2fbc921b89ca4674a1a5b76a6ad7e5ed",
            "491d3df2241c4285884b7eef31361d18",
            "670ce8dcff2b44fdb4b22ac413f23b9f",
            "07cc0282bf134a24991c8fb06f0a7987",
            "1e42294fe5124b9e95b199fa25da9f94",
            "513e223681504ca4891829ed46a4063a",
            "ab881e7421d34bcb87ba32104cb1e8cc",
            "141297a0f9704ff1ae679248d9ef30f8",
            "d8f8c1c71103461486ec3ed5e7d371d1",
            "684dd6be54df462087a018d0e156ae3c",
            "6f761cdf14264847b58161210280e162",
            "7dcc81c28a224e77b6fedfa3641ddf49",
            "5189e96f77894d20af55315a45cbb7a5",
            "ffb9217cc7654ada86a8753cafca01c8",
            "c406133446fc47d4a3cccebcf9c0153e",
            "1d958eb0a74246da990e18ca5961d0a1",
            "4620181d9e7744639af61fa6693a3930",
            "d756cd7440e54289a7ecd7ab38190696"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c92f4727002149d18498a871a7f5e5ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ecf6ab872f742229b2cb273d1e64537"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18cfe09e499b4e04b3435171de3ea2c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8fe3d93130d4656a6b2f006e228fa6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d524ff688064d78b038c14c394f2d06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "141297a0f9704ff1ae679248d9ef30f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6jwG6_Tq-V"
      },
      "source": [
        "To try the model out, let's find the loss on this text! Models can be run on a single string or a tensor of tokens (shape: [batch, position], all integers), and the possible return types are:\n",
        "* \"logits\" (shape [batch, position, d_vocab], floats),\n",
        "* \"loss\" (the cross-entropy loss when predicting the next token),\n",
        "* \"both\" (a tuple of (logits, loss))\n",
        "* None (run the model, but don't calculate the logits - this is faster when we only want to use intermediate activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O8PqJafyTq-V",
        "outputId": "cc2d40f7-f764-4a59-e0e5-3359bfccae37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(4.1758)\n"
          ]
        }
      ],
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
        "loss = model(model_description_text, return_type=\"loss\")\n",
        "print(\"Model loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wrpskDoTq-V"
      },
      "source": [
        "## Caching all Activations\n",
        "\n",
        "The first basic operation when doing mechanistic interpretability is to break open the black box of the model and look at all of the internal activations of a model. This can be done with `logits, cache = model.run_with_cache(tokens)`. Let's try this out on the first line of the abstract of the GPT-2 paper.\n",
        "\n",
        "<details><summary>On `remove_batch_dim`</summary>\n",
        "\n",
        "Every activation inside the model begins with a batch dimension. Here, because we only entered a single batch dimension, that dimension is always length 1 and kinda annoying, so passing in the `remove_batch_dim=True` keyword removes it. `gpt2_cache_no_batch_dim = gpt2_cache.remove_batch_dim()` would have achieved the same effect.\n",
        "</details?>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R8-LhmRJTq-V",
        "outputId": "1adece30-157d-4e24-d0a2-b76aa6d46ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
        "gpt2_tokens = model.to_tokens(gpt2_text)\n",
        "print(gpt2_tokens.device)\n",
        "gpt2_logits, gpt2_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSM1dxgoTq-V"
      },
      "source": [
        "Let's visualize the attention pattern of all the heads in layer 0, using [Alan Cooney's CircuitsVis library](https://github.com/alan-cooney/CircuitsVis) (based on [Anthropic's PySvelte library](https://github.com/anthropics/PySvelte)).\n",
        "\n",
        "We look this the attention pattern in `gpt2_cache`, an `ActivationCache` object, by entering in the name of the activation, followed by the layer index (here, the activation is called \"attn\" and the layer index is 0). This has shape [head_index, destination_position, source_position], and we use the `model.to_str_tokens` method to convert the text to a list of tokens as strings, since there is an attention weight between each pair of tokens.\n",
        "\n",
        "This visualization is interactive! Try hovering over a token or head, and click to lock. The grid on the top left and for each head is the attention pattern as a destination position by source position grid. It's lower triangular because GPT-2 has **causal attention**, attention can only look backwards, so information can only move forwards in the network.\n",
        "\n",
        "See the ActivationCache section for more on what `gpt2_cache` can do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vI4KAp0UTq-V",
        "outputId": "9e22eaa9-1950-4186-b89f-6179ba5b4e8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
            "torch.Size([12, 33, 33])\n"
          ]
        }
      ],
      "source": [
        "print(type(gpt2_cache))\n",
        "attention_pattern = gpt2_cache[\"pattern\", 0, \"attn\"]\n",
        "print(attention_pattern.shape)\n",
        "gpt2_str_tokens = model.to_str_tokens(gpt2_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fqNrAJ_WTq-V",
        "outputId": "2289aafa-2a5f-4022-89bc-b133c4eca25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 Head Attention Patterns:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7ab875cf7130>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-f1189c3f-6922\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-f1189c3f-6922\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"Natural\", \" language\", \" processing\", \" tasks\", \",\", \" such\", \" as\", \" question\", \" answering\", \",\", \" machine\", \" translation\", \",\", \" reading\", \" comprehension\", \",\", \" and\", \" summar\", \"ization\", \",\", \" are\", \" typically\", \" approached\", \" with\", \" supervised\", \" learning\", \" on\", \" tasks\", \"pe\", \"cific\", \" datasets\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639418721199036, 0.03605814278125763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8389372825622559, 0.1182878240942955, 0.042774852365255356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47436124086380005, 0.13382022082805634, 0.27371737360954285, 0.11810111999511719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3560643196105957, 0.10184915363788605, 0.23054225742816925, 0.20397399365901947, 0.10757029801607132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6660143136978149, 0.1686638742685318, 0.045356765389442444, 0.03885501250624657, 0.06775481253862381, 0.013355252332985401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38626962900161743, 0.2851092517375946, 0.07609007507562637, 0.059083808213472366, 0.07223352044820786, 0.03979633376002312, 0.08141742646694183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3775395154953003, 0.1883881539106369, 0.11723987758159637, 0.0868559330701828, 0.06669178605079651, 0.035000160336494446, 0.09693007171154022, 0.03135443106293678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4869752824306488, 0.06781316548585892, 0.07952877879142761, 0.08480790257453918, 0.1590261310338974, 0.029577823355793953, 0.02568591758608818, 0.016474608331918716, 0.05011039599776268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29065507650375366, 0.0401349812746048, 0.14614854753017426, 0.09940598160028458, 0.1538918912410736, 0.03900160640478134, 0.024988971650600433, 0.031841300427913666, 0.10222819447517395, 0.07170343399047852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39624103903770447, 0.09694179147481918, 0.027270672842860222, 0.02355135791003704, 0.03723450377583504, 0.006502409465610981, 0.08118754625320435, 0.013088470324873924, 0.06990595906972885, 0.24043095111846924, 0.007645336911082268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24864791333675385, 0.1380206197500229, 0.09235323220491409, 0.08676120638847351, 0.1381969302892685, 0.05914197862148285, 0.032238587737083435, 0.031582415103912354, 0.03048943728208542, 0.03873484209179878, 0.06671836972236633, 0.03711448237299919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19148443639278412, 0.1617259532213211, 0.07445938885211945, 0.07740947604179382, 0.021961115300655365, 0.03392128273844719, 0.05125020816922188, 0.019519241526722908, 0.03132448345422745, 0.04020153358578682, 0.03874269127845764, 0.21578861773014069, 0.042211662977933884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3704317510128021, 0.08681418746709824, 0.024584675207734108, 0.02161632478237152, 0.03238871693611145, 0.005422739312052727, 0.07275222986936569, 0.011272798292338848, 0.06329694390296936, 0.21726815402507782, 0.006367162801325321, 0.02960381843149662, 0.05099845305085182, 0.007182061206549406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19737645983695984, 0.04603997617959976, 0.0439998134970665, 0.13373452425003052, 0.054248202592134476, 0.025475719943642616, 0.027563493698835373, 0.02157093770802021, 0.05171824246644974, 0.06458096951246262, 0.028064634650945663, 0.23551598191261292, 0.0191297959536314, 0.029963519424200058, 0.021017691120505333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08907236158847809, 0.01928834617137909, 0.16653534770011902, 0.07281260937452316, 0.04738643020391464, 0.024487899616360664, 0.02898734249174595, 0.019370367750525475, 0.026673035696148872, 0.0731663852930069, 0.025704579427838326, 0.04242357984185219, 0.05869461968541145, 0.028932703658938408, 0.18119068443775177, 0.0952736958861351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28167295455932617, 0.06441289186477661, 0.01800854690372944, 0.01616961881518364, 0.023183899000287056, 0.0037532937712967396, 0.05472248047590256, 0.007909763604402542, 0.046164706349372864, 0.16947263479232788, 0.004361641593277454, 0.02101135067641735, 0.03549071028828621, 0.0049325693398714066, 0.0955522209405899, 0.1472633332014084, 0.005917445290833712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2130548357963562, 0.059123694896698, 0.033820878714323044, 0.027476871386170387, 0.028393536806106567, 0.008422903716564178, 0.040085311979055405, 0.011629276908934116, 0.05295189842581749, 0.154046431183815, 0.00983181968331337, 0.03610192984342575, 0.04737287759780884, 0.011069191619753838, 0.09972472488880157, 0.13971354067325592, 0.013185336254537106, 0.01399495080113411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15871694684028625, 0.04387890174984932, 0.08712150156497955, 0.08998466283082962, 0.030738577246665955, 0.034148938953876495, 0.02491724118590355, 0.03139194846153259, 0.0248238705098629, 0.01979033090174198, 0.036254845559597015, 0.020694417878985405, 0.04284067824482918, 0.038208991289138794, 0.06234658136963844, 0.10919703543186188, 0.0413760170340538, 0.04916759952902794, 0.05440092086791992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10485510528087616, 0.12122291326522827, 0.0648748129606247, 0.0876871794462204, 0.03434053435921669, 0.017483945935964584, 0.03415180742740631, 0.01528915110975504, 0.023312130942940712, 0.02830648608505726, 0.01872047409415245, 0.028111929073929787, 0.04190532863140106, 0.02098955772817135, 0.04678507521748543, 0.08659635484218597, 0.02363184653222561, 0.024273177608847618, 0.16702404618263245, 0.010438218712806702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22901976108551025, 0.05184381082653999, 0.013585194945335388, 0.01233725156635046, 0.018005432561039925, 0.002770362189039588, 0.04238129034638405, 0.005856258329004049, 0.036144886165857315, 0.13039220869541168, 0.00315342890098691, 0.015672577545046806, 0.02780039794743061, 0.0035543262492865324, 0.07460816949605942, 0.11298283189535141, 0.004272272810339928, 0.0068322052247822285, 0.18569742143154144, 0.018073629587888718, 0.005016356240957975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18869924545288086, 0.034387119114398956, 0.02234475128352642, 0.019972743466496468, 0.016354037448763847, 0.006856545340269804, 0.020859049633145332, 0.005696005187928677, 0.03415916487574577, 0.07260986417531967, 0.007857208140194416, 0.01804024912416935, 0.026904473081231117, 0.009020394645631313, 0.06876447051763535, 0.17578735947608948, 0.010720070451498032, 0.00928453542292118, 0.1925639659166336, 0.02518032118678093, 0.012639068067073822, 0.021299347281455994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1195831149816513, 0.022259404882788658, 0.032947149127721786, 0.020170262083411217, 0.03565331920981407, 0.013459902256727219, 0.017516475170850754, 0.010057869367301464, 0.025856446474790573, 0.05955956131219864, 0.015084506943821907, 0.015008730813860893, 0.05317465960979462, 0.016597602516412735, 0.04155528545379639, 0.13129331171512604, 0.019296666607260704, 0.01585504598915577, 0.17925086617469788, 0.016183817759156227, 0.022295529022812843, 0.015463407151401043, 0.10187706351280212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14615534245967865, 0.02672751061618328, 0.01662455126643181, 0.018987692892551422, 0.06278638541698456, 0.015317173674702644, 0.01979224383831024, 0.014227774925529957, 0.025458162650465965, 0.04530351236462593, 0.01636434905230999, 0.037493057548999786, 0.013288663700222969, 0.01749655045568943, 0.0399458222091198, 0.05881752446293831, 0.019260985776782036, 0.024616047739982605, 0.03821967542171478, 0.02157779596745968, 0.020949900150299072, 0.07973217219114304, 0.05017608031630516, 0.17068108916282654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321669071912766, 0.03674636408686638, 0.011786578223109245, 0.010274861939251423, 0.020370660349726677, 0.00524388300254941, 0.015918835997581482, 0.005266785155981779, 0.024891745299100876, 0.06593260914087296, 0.005933654960244894, 0.018209027126431465, 0.021020203828811646, 0.006667500361800194, 0.034828800708055496, 0.13742125034332275, 0.007927055470645428, 0.008618668653070927, 0.1137719377875328, 0.013557425700128078, 0.0092778280377388, 0.026121364906430244, 0.08499341458082199, 0.19073913991451263, 0.011263743042945862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1333770900964737, 0.02621661312878132, 0.038271524012088776, 0.0715256854891777, 0.053177691996097565, 0.013925841078162193, 0.0070841871201992035, 0.013450143858790398, 0.009841452352702618, 0.011789785698056221, 0.013537583872675896, 0.03815499693155289, 0.041933052241802216, 0.013882276602089405, 0.03707147017121315, 0.13838455080986023, 0.014846324920654297, 0.03156951814889908, 0.05598175525665283, 0.015536673367023468, 0.01595636084675789, 0.04545554891228676, 0.016699669882655144, 0.025325775146484375, 0.0367189384996891, 0.08028542995452881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1060897558927536, 0.019107729196548462, 0.024468645453453064, 0.027496378868818283, 0.016365814954042435, 0.005011423025280237, 0.010413102805614471, 0.006081143859773874, 0.005301063880324364, 0.011143164709210396, 0.004565385635942221, 0.01896991766989231, 0.004321119748055935, 0.004814977757632732, 0.02940940670669079, 0.028682025149464607, 0.005097254179418087, 0.007234354503452778, 0.03412593901157379, 0.010370594449341297, 0.0056432681158185005, 0.007283585146069527, 0.02938956953585148, 0.01003879215568304, 0.00913451611995697, 0.5466631650924683, 0.012777912430465221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10467307269573212, 0.03321940451860428, 0.015341237187385559, 0.009373541921377182, 0.026595458388328552, 0.005787800997495651, 0.013571344316005707, 0.004554887767881155, 0.02805890329182148, 0.02610723488032818, 0.006353443488478661, 0.013315827585756779, 0.026628248393535614, 0.006888873875141144, 0.06204749271273613, 0.058907054364681244, 0.008068051189184189, 0.007557096425443888, 0.08522789925336838, 0.017075739800930023, 0.009256887249648571, 0.019695749506354332, 0.1261780560016632, 0.13061514496803284, 0.011351032182574272, 0.08984378725290298, 0.046381521970033646, 0.007325290702283382, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08561894297599792, 0.02143893763422966, 0.05641258880496025, 0.05706660449504852, 0.01980220340192318, 0.006727499887347221, 0.005809157155454159, 0.004516263958066702, 0.003164749126881361, 0.01761520281434059, 0.0061746020801365376, 0.08767978101968765, 0.0122998571023345, 0.0063504548743367195, 0.017522135749459267, 0.14295218884944916, 0.006585485767573118, 0.007875689305365086, 0.030078928917646408, 0.013907487504184246, 0.007376695051789284, 0.007684790063649416, 0.022160829976201057, 0.012385029345750809, 0.011890069581568241, 0.08669781684875488, 0.19902533292770386, 0.013594483025372028, 0.02958623133599758, 0.0, 0.0, 0.0, 0.0], [0.1406458467245102, 0.013298697769641876, 0.015702957287430763, 0.017357872799038887, 0.02233150787651539, 0.029672270640730858, 0.04172081500291824, 0.018995430320501328, 0.038277123123407364, 0.048635609447956085, 0.030946899205446243, 0.016023898497223854, 0.020880894735455513, 0.03243822976946831, 0.030558142811059952, 0.022808346897363663, 0.035377584397792816, 0.03145158663392067, 0.03497114032506943, 0.018679112195968628, 0.03821909800171852, 0.02257886901497841, 0.06819558143615723, 0.04214096441864967, 0.028620850294828415, 0.037750035524368286, 0.01857805624604225, 0.03376871719956398, 0.03641696646809578, 0.012956839986145496, 0.0, 0.0, 0.0], [0.07168619334697723, 0.06924441456794739, 0.019306892529129982, 0.014161993749439716, 0.01682320050895214, 0.019380604848265648, 0.019257426261901855, 0.022003689780831337, 0.013706532306969166, 0.035783786326646805, 0.01846517063677311, 0.05207167938351631, 0.02008516900241375, 0.019862134009599686, 0.020662108436226845, 0.04725159332156181, 0.0210767462849617, 0.03678726404905319, 0.02432408183813095, 0.0038275488186627626, 0.023920677602291107, 0.008533235639333725, 0.026241624727845192, 0.0273800790309906, 0.034612011164426804, 0.0228841844946146, 0.10047896951436996, 0.06913502514362335, 0.025474581867456436, 0.06495604664087296, 0.03061535768210888, 0.0, 0.0], [0.06910780072212219, 0.037012264132499695, 0.038621142506599426, 0.05933321639895439, 0.015923552215099335, 0.007918555289506912, 0.010371049866080284, 0.006615667603909969, 0.0025200785603374243, 0.026019388809800148, 0.007905222475528717, 0.029652036726474762, 0.04000624269247055, 0.008451337926089764, 0.0107411565259099, 0.050275612622499466, 0.009428862482309341, 0.013601033017039299, 0.050369229167699814, 0.031767114996910095, 0.010793029330670834, 0.0072168041951954365, 0.006478432100266218, 0.014800596982240677, 0.021585971117019653, 0.15769490599632263, 0.0888475775718689, 0.01901692897081375, 0.02972932904958725, 0.03316134214401245, 0.050883643329143524, 0.0341508574783802, 0.0], [0.14375509321689606, 0.01681104116141796, 0.009386665187776089, 0.006830308586359024, 0.011656847782433033, 0.0015672266017645597, 0.019711477681994438, 0.0023980382829904556, 0.021235886961221695, 0.046836789697408676, 0.0016905132215470076, 0.005827190354466438, 0.011979990638792515, 0.0018251369474455714, 0.04231332242488861, 0.054913729429244995, 0.0021786526776850224, 0.0024170123506337404, 0.09604070335626602, 0.00575287314131856, 0.0025577889755368233, 0.007121228612959385, 0.08889925479888916, 0.10852086544036865, 0.005179052706807852, 0.03657734394073486, 0.024719927459955215, 0.003734763478860259, 0.031077073886990547, 0.016887927427887917, 0.094508595764637, 0.07171523571014404, 0.003372319508343935]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004246651369612664, 0.9995753169059753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621903110295534, 0.01640726439654827, 0.9830306172370911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001162757514975965, 0.0216820165514946, 0.003762046108022332, 0.9733933210372925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.724443740793504e-05, 0.00017202318122144789, 0.0002814398321788758, 0.0027421461418271065, 0.9967671632766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008268442004919052, 0.00023985578445717692, 7.361903408309445e-05, 6.437728006858379e-05, 0.00017566324095241725, 0.9911779761314392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012215040624141693, 0.005400451831519604, 0.0016716319369152188, 0.00040775633533485234, 0.0006163658108562231, 0.0010931185679510236, 0.9895892143249512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001245975960046053, 0.000912121613509953, 0.0005976713728159666, 0.00013656872033607215, 0.0003304101701360196, 0.0015722765820100904, 0.003880807664245367, 0.9913241863250732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00028217487852089107, 0.004068182315677404, 0.0026605194434523582, 0.0013093105517327785, 0.008030479773879051, 0.0002879090898204595, 0.00022922919015400112, 0.0003948427038267255, 0.9827372431755066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.47393324773293e-05, 0.00039538455894216895, 0.00013272723299451172, 0.0002585228648968041, 0.0010855586733669043, 9.198043699143454e-05, 0.00032670784275978804, 0.0005427454598248005, 0.006105930078774691, 0.9910256266593933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003378510009497404, 5.0908805860672146e-05, 1.645207521505654e-05, 1.6926180251175538e-05, 4.1814146243268624e-05, 0.493940532207489, 0.00012981274630874395, 0.0008837340865284204, 3.221199949621223e-05, 2.7252091967966408e-05, 0.501481831073761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.416055788984522e-05, 0.0013417241862043738, 0.0012613608269020915, 0.0021450743079185486, 0.004042362328618765, 0.0004830540856346488, 0.0001158266604761593, 0.00015203609655145556, 2.6925305064651184e-05, 0.00012675137259066105, 0.00031289938488043845, 0.9899077415466309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00037822307785972953, 0.000983756734058261, 0.03934124484658241, 0.0027322471141815186, 0.003668021410703659, 0.00011039181117666885, 0.0001293103414354846, 0.00021743500838056207, 0.00010623285197652876, 0.0007748190546408296, 6.647672853432596e-05, 0.0003148665127810091, 0.9511770009994507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00210172007791698, 2.443686025799252e-05, 7.788777111272793e-06, 8.651618372823577e-06, 2.0140050764894113e-05, 0.29971376061439514, 7.525253022322431e-05, 0.0004898309707641602, 1.845947736001108e-05, 1.5344554412877187e-05, 0.3283386528491974, 4.175802678219043e-05, 6.4691917032178026e-06, 0.3691376745700836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014968313917052, 0.00011296597222099081, 0.0003629484854172915, 0.00018591186380945146, 0.00016460877668578178, 4.1432256693951786e-05, 2.8764718081220053e-05, 7.786935748299584e-05, 0.0009200984495691955, 0.010340185835957527, 2.7572366889216937e-05, 1.783320476533845e-05, 0.00033054465893656015, 2.4375704015255906e-05, 0.9872152805328369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010753796232165769, 0.002178182825446129, 0.002042605308815837, 0.004251916892826557, 0.006989872083067894, 2.511867569410242e-05, 0.0007779006846249104, 0.0005783525411970913, 0.0029378319159150124, 0.03322529420256615, 1.719921601761598e-05, 0.0008936444064602256, 0.0015238532796502113, 1.4656750863650814e-05, 0.006222618278115988, 0.9382133483886719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013634881470352411, 1.3226039300207049e-05, 4.013936177216237e-06, 4.803058345714817e-06, 1.0257444955641404e-05, 0.19665950536727905, 4.5272561692399904e-05, 0.0002776260080281645, 1.17144372779876e-05, 9.473314094066154e-06, 0.22919581830501556, 2.643065818119794e-05, 4.101845206605503e-06, 0.26576104760169983, 8.515357876603957e-06, 4.536018423095811e-06, 0.3066001534461975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008924755384214222, 0.00013490796845871955, 4.779840674018487e-05, 5.803708336316049e-05, 0.00010480154014658183, 0.012799108400940895, 0.0007168236770667136, 0.03257950767874718, 2.6449932192917913e-05, 0.00011185053881490603, 0.011884260922670364, 4.010270276921801e-05, 5.5553988204337656e-05, 0.01237786840647459, 0.00010783460311358795, 5.404360490501858e-05, 0.013122137635946274, 0.9148864150047302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.075314675195841e-06, 4.3961426854366437e-05, 3.398511398700066e-05, 7.940301293274388e-05, 5.477911327034235e-05, 7.921550491118978e-07, 9.313342161476612e-06, 7.72709336160915e-06, 8.597270061727613e-05, 0.00012274066102690995, 5.141494057170348e-07, 1.702795316305128e-06, 3.834182643913664e-05, 4.4509752683552506e-07, 0.00013928249245509505, 0.00032758069573901594, 3.994804558260512e-07, 3.948137873521773e-06, 0.999043881893158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.346216393169016e-05, 0.0018395755905658007, 0.002523318398743868, 0.01808730512857437, 0.0029363830108195543, 0.0002733588626142591, 4.872983481618576e-05, 0.0004212784406263381, 0.0001562439138069749, 0.0009748375159688294, 0.00020533663337118924, 0.001022886368446052, 0.0019548090640455484, 0.00019470420375000685, 0.0011294226860627532, 0.0016656150110065937, 0.00018734094919636846, 0.0009503471083007753, 0.0004455189628060907, 0.9648895859718323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010859699686989188, 8.512331987731159e-06, 2.530733127059648e-06, 3.062522864638595e-06, 5.9751278058683965e-06, 0.13292624056339264, 3.345322693348862e-05, 0.00018891259969677776, 8.477763003611472e-06, 6.540420145029202e-06, 0.16445893049240112, 1.813005110307131e-05, 3.062745008719503e-06, 0.19719165563583374, 6.429840141208842e-06, 3.444735511948238e-06, 0.2331714779138565, 0.0022796255070716143, 3.7134323065401986e-06, 3.5288056096760556e-05, 0.268558531999588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004197949019726366, 0.00011805002577602863, 0.0001424048823537305, 3.796784585574642e-05, 0.00019043161591980606, 0.0017651208909228444, 0.0005709825200028718, 0.0005008853622712195, 8.840746158966795e-05, 0.0001420867774868384, 0.0016639818204566836, 3.3481079299235716e-05, 2.441395918140188e-05, 0.0017546487506479025, 6.520305760204792e-05, 2.414262417005375e-05, 0.0018299149814993143, 0.0015691017033532262, 3.97487347072456e-05, 0.000157123853568919, 0.0018554466078057885, 0.9870065450668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.501784421037883e-05, 0.0014379840577021241, 6.345151632558554e-05, 0.00010864839714486152, 0.00015633167640771717, 3.210126124031376e-06, 0.0022032777778804302, 0.0002207657671533525, 5.2403069275896996e-05, 4.88158839289099e-05, 2.264461500089965e-06, 1.5327248547691852e-05, 4.157144758210052e-06, 2.0228408175171353e-06, 6.2968028942123055e-06, 4.8486737796338275e-05, 1.992900934055797e-06, 3.247004497097805e-05, 0.00126951327547431, 1.96326454897644e-05, 1.8090950106852688e-06, 0.000581029336899519, 0.9936450719833374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.450151315424591e-05, 0.0006139386096037924, 0.0009361195843666792, 0.0008487807353958488, 0.002850632881745696, 1.0365041816839948e-05, 0.00021614276920445263, 0.00017397530609741807, 0.0020508375018835068, 0.005805305205285549, 8.05523814051412e-06, 8.086584421107545e-05, 0.000770243932493031, 7.28818440620671e-06, 0.0010576159693300724, 0.0022755973041057587, 6.6632615016715135e-06, 0.00011621028534136713, 0.0005972451181150973, 8.736297604627907e-05, 6.332331849989714e-06, 6.096452852943912e-05, 6.090577517170459e-05, 0.9812840819358826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005848738364875317, 0.0001590918836882338, 1.0836472029041033e-05, 7.365470082731918e-05, 0.00011349524720571935, 0.0008256652508862317, 0.00031910985126160085, 0.018529964610934258, 1.0226591257378459e-05, 4.9587179091759026e-05, 0.000771641090977937, 4.4548200094141066e-05, 9.86501618172042e-06, 0.0008067172020673752, 2.2673864805256017e-05, 1.2464129213185515e-05, 0.000844910042360425, 0.008790099062025547, 3.579237818485126e-05, 3.662859307951294e-05, 0.0008917524828575552, 0.001079176552593708, 0.0003708464791998267, 0.00010837137961061671, 0.9654980301856995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6459925973322242e-05, 0.00017152438522316515, 3.2083211408462375e-05, 0.00010234182263957337, 0.0026318745221942663, 9.886184670904186e-06, 3.2508516596863046e-05, 3.7417539715534076e-05, 0.00012631528079509735, 4.991215973859653e-05, 8.302548849314917e-06, 8.443422120762989e-05, 3.127968739136122e-05, 7.633370842086151e-06, 1.0101362931891344e-05, 5.6673809012863785e-05, 7.442136393365217e-06, 2.7689680791809224e-05, 1.841835728555452e-05, 2.8794345325877657e-06, 6.840427886345424e-06, 4.279879249224905e-06, 0.0004317661514505744, 0.00017617484263610095, 8.995590906124562e-05, 0.9958257675170898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6368048565927893e-05, 0.0001800870813895017, 0.0001808295346563682, 0.00030464722658507526, 0.0003939090820495039, 4.674840602092445e-05, 2.723169200180564e-05, 4.873490979662165e-05, 0.0002913166827056557, 0.0004206172889098525, 3.804640073212795e-05, 0.0002524516312405467, 5.6067383411573246e-05, 3.820368874585256e-05, 0.0015365114668384194, 0.0012537245638668537, 3.593425208237022e-05, 2.3036618586047553e-05, 0.0001803626073524356, 0.00012266090197954327, 3.5177839890820906e-05, 6.924678746145219e-05, 0.0001126729475799948, 0.0008507381426170468, 0.00014361889043357223, 0.00023527958546765149, 0.9930958151817322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007048251572996378, 5.6753891840344295e-05, 3.351289251440903e-06, 7.472657671314664e-06, 1.785946005838923e-05, 0.0008156527765095234, 4.9529528041603044e-05, 0.0013530971482396126, 3.741763430298306e-05, 0.00014378006744664162, 0.000763933639973402, 9.991685146815144e-06, 2.884435843952815e-06, 0.0007552225724793971, 0.00010159601515624672, 3.120541123280418e-06, 0.0008060952532105148, 0.0011406762059777975, 1.4343117982207332e-05, 9.910167136695236e-06, 0.0008649186929687858, 8.663273911224678e-05, 3.4695473004831e-05, 0.0001026583049679175, 0.007663471158593893, 4.1878953197738156e-05, 3.4908698580693454e-06, 0.9844048619270325, 0.0, 0.0, 0.0, 0.0, 0.0], [2.0288327505113557e-05, 2.9542719858000055e-05, 5.037501978222281e-05, 0.0009778327075764537, 0.3728255331516266, 6.661304723820649e-06, 1.573365443618968e-05, 3.9812464819988236e-05, 0.00022353224630933255, 0.0001267432962777093, 5.118443823448615e-06, 0.00024116146960295737, 1.2973835509910714e-05, 4.8006900215114e-06, 2.332163421669975e-05, 7.723532326053828e-05, 4.593436187860789e-06, 1.9647141016321257e-05, 0.00021129970264155418, 1.1453507795522455e-05, 4.38048436990357e-06, 1.4442680367210414e-05, 3.67674911103677e-05, 0.00011845329572679475, 3.797718454734422e-05, 0.0007802760228514671, 0.0004048360278829932, 1.0429552276036702e-05, 0.6236647963523865, 0.0, 0.0, 0.0, 0.0], [2.0582907382049598e-05, 8.831234299577773e-05, 0.00020454861805774271, 0.0003018892602995038, 8.223887562053278e-05, 1.970439734577667e-05, 0.0001408509851898998, 2.8963144359295256e-05, 7.669377737329341e-06, 3.724613270605914e-05, 1.673677070357371e-05, 6.404696614481509e-05, 0.0006910577067174017, 1.6027554011088796e-05, 0.00015603650535922498, 0.00014825898688286543, 1.5700054063927382e-05, 9.155381849268451e-05, 8.525074372300878e-05, 4.904512934444938e-06, 1.5784382412675768e-05, 5.293107096804306e-05, 0.0005298349424265325, 0.0005658389418385923, 6.167324318084866e-05, 6.729490996804088e-05, 0.0003077442815992981, 1.0369139090471435e-05, 6.799335824325681e-05, 0.9960988759994507, 0.0, 0.0, 0.0], [1.3371331988309976e-05, 0.0009821535786613822, 0.0004154812777414918, 0.0001144233756349422, 0.0003873075474984944, 5.660860551870428e-06, 0.0012746269349008799, 0.000570806791074574, 0.000638362136669457, 0.0005776660400442779, 4.127733518544119e-06, 9.161743037111592e-06, 9.142841736320406e-05, 3.774864126171451e-06, 1.3575295270129573e-05, 0.0002916179655585438, 3.4474890071578557e-06, 7.899177580839023e-05, 0.003189122537150979, 4.885083853878314e-06, 3.165286670991918e-06, 1.4087455383560155e-05, 0.0001567144354339689, 0.00035448907874524593, 0.00017265455971937627, 0.0013050615089014173, 0.00021867647592443973, 2.6776719096233137e-05, 0.00026460207300260663, 1.3334542018128559e-05, 0.9888005256652832, 0.0, 0.0], [2.745508936641272e-05, 0.00016438262537121773, 7.996438216650859e-05, 0.0011914977803826332, 0.0007883630460128188, 2.658417088241549e-06, 3.0057650292292237e-05, 7.457976153091295e-06, 0.00014940995606593788, 2.8857215511379763e-05, 1.8738293192654965e-06, 0.0003328806778881699, 5.16086547577288e-05, 1.757749942044029e-06, 0.00012656577746383846, 0.000142670251079835, 1.6954471675489913e-06, 2.1952595488983206e-05, 0.00023040825908537954, 4.4293432438280433e-05, 1.6103306279546814e-06, 2.7008050892618485e-05, 0.0002388486755080521, 0.0001904603559523821, 9.496164238953497e-06, 0.000446643796749413, 0.00022095811436884105, 5.379181402531685e-06, 0.0006956413271836936, 0.00015470781363546848, 0.0002548544143792242, 0.9943286776542664, 0.0], [0.006231046747416258, 9.722806862555444e-05, 6.871603090985445e-06, 2.1151136024855077e-05, 5.828053326695226e-05, 0.007238905411213636, 2.0987916286685504e-05, 0.00025459096650592983, 6.2438593886327e-05, 2.09246627491666e-05, 0.007872136309742928, 5.5853244703030214e-05, 9.868757842923515e-06, 0.009169397875666618, 7.203003042377532e-05, 7.068680588417919e-06, 0.010345976799726486, 0.0013096530456095934, 3.803680374403484e-05, 8.022697147680447e-05, 0.012053250335156918, 4.071998773724772e-05, 3.6860749332845444e-06, 3.471342279226519e-05, 0.0005061827832832932, 8.918932871893048e-05, 2.9112034098943695e-05, 0.0012772815534844995, 8.489656465826556e-05, 0.00018447425100021064, 0.00013425729412119836, 6.813048094045371e-05, 0.9425214529037476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.943029522895813, 0.05697045475244522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9185556173324585, 0.03280003368854523, 0.048644352704286575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8779287934303284, 0.05643429234623909, 0.04271192103624344, 0.022925030440092087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.804131805896759, 0.029098210856318474, 0.07556727528572083, 0.05643591657280922, 0.03476677089929581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49431052803993225, 0.02018354833126068, 0.027966564521193504, 0.018319061025977135, 0.0314420647919178, 0.40777823328971863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6057478189468384, 0.029242422431707382, 0.09491507709026337, 0.07609350979328156, 0.06614662706851959, 0.08705780655145645, 0.04079665243625641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44838207960128784, 0.04542432725429535, 0.0740148052573204, 0.06864849478006363, 0.09376626461744308, 0.08774261921644211, 0.0653427392244339, 0.11667871475219727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4916927218437195, 0.13782072067260742, 0.03955019265413284, 0.061533186584711075, 0.045399654656648636, 0.04073144495487213, 0.062287040054798126, 0.05861865356564522, 0.06236641854047775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5404125452041626, 0.04442666471004486, 0.039578523486852646, 0.041888076812028885, 0.07529858499765396, 0.0466950349509716, 0.0484752394258976, 0.055005207657814026, 0.08293058723211288, 0.025289513170719147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28273555636405945, 0.014234174974262714, 0.017647741362452507, 0.011433064937591553, 0.021741710603237152, 0.266653835773468, 0.015403537079691887, 0.047349292784929276, 0.017767539247870445, 0.013926072046160698, 0.29110750555992126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.344966322183609, 0.046116799116134644, 0.05771547183394432, 0.11131862550973892, 0.11289363354444504, 0.027930330485105515, 0.038591887801885605, 0.05656527727842331, 0.058640558272600174, 0.06648591160774231, 0.02611437253654003, 0.05266084149479866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46992185711860657, 0.03201569616794586, 0.107728973031044, 0.027006767690181732, 0.04465881735086441, 0.022773539647459984, 0.023117076605558395, 0.025491515174508095, 0.049502693116664886, 0.02657395228743553, 0.019708862528204918, 0.06337953358888626, 0.08812074363231659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2066175937652588, 0.010379290208220482, 0.01226192805916071, 0.008319087326526642, 0.016007088124752045, 0.1952773630619049, 0.011453285813331604, 0.03475672006607056, 0.01307358406484127, 0.010938974097371101, 0.21602493524551392, 0.005866492632776499, 0.02364230528473854, 0.23538126051425934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3399347960948944, 0.02916165068745613, 0.09540717303752899, 0.03395187109708786, 0.0844046026468277, 0.012559536844491959, 0.029358645901083946, 0.024564167484641075, 0.10622430592775345, 0.04689214378595352, 0.011469585821032524, 0.006369189824908972, 0.11145279556512833, 0.011317996308207512, 0.05693149194121361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40408816933631897, 0.024195685982704163, 0.03891003504395485, 0.014727432280778885, 0.024456575512886047, 0.03845001012086868, 0.03923032060265541, 0.037171393632888794, 0.06030001863837242, 0.041985444724559784, 0.03716715797781944, 0.016391245648264885, 0.039289675652980804, 0.03772979974746704, 0.13448575139045715, 0.011421289294958115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15876439213752747, 0.008203903213143349, 0.00929525587707758, 0.00622171675786376, 0.011793217621743679, 0.15069784224033356, 0.008851953782141209, 0.026313554495573044, 0.010186920873820782, 0.008433726616203785, 0.1676224023103714, 0.004420032259076834, 0.018211793154478073, 0.18350809812545776, 0.020927326753735542, 0.006447782274335623, 0.2001000940799713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1753920465707779, 0.020569656044244766, 0.01829143427312374, 0.009298022836446762, 0.01737789623439312, 0.042534757405519485, 0.02070157416164875, 0.05044391751289368, 0.025438031181693077, 0.01721823774278164, 0.04311535879969597, 0.013349817134439945, 0.028528617694973946, 0.04597253352403641, 0.03408820927143097, 0.019834203645586967, 0.04992839694023132, 0.3679172694683075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2603333294391632, 0.017148379236459732, 0.03745279461145401, 0.07594800740480423, 0.04674705117940903, 0.018068520352244377, 0.03134644031524658, 0.037415146827697754, 0.07175807654857635, 0.058725371956825256, 0.017078706994652748, 0.040305912494659424, 0.05706357955932617, 0.0171135812997818, 0.1049133688211441, 0.046705372631549835, 0.017230208963155746, 0.02468215301632881, 0.01996397040784359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30547070503234863, 0.051904961466789246, 0.04346896708011627, 0.021846860647201538, 0.021017195656895638, 0.03390473499894142, 0.04190472140908241, 0.039092883467674255, 0.028871944174170494, 0.023003436625003815, 0.0320579968392849, 0.02333449013531208, 0.07110599428415298, 0.03290087357163429, 0.06164193153381348, 0.03183261305093765, 0.03376764804124832, 0.045714907348155975, 0.03501523286104202, 0.022141898050904274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1224295049905777, 0.006105297710746527, 0.006670292001217604, 0.004581777844578028, 0.009337793104350567, 0.11381792277097702, 0.006783360615372658, 0.019719911739230156, 0.007580860517919064, 0.0066136447712779045, 0.12765930593013763, 0.003502657637000084, 0.014002335257828236, 0.1400098353624344, 0.01568487659096718, 0.00509260781109333, 0.15336216986179352, 0.03527418151497841, 0.022465620189905167, 0.006954459007829428, 0.17235161364078522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20538491010665894, 0.034778520464897156, 0.014682925306260586, 0.031183309853076935, 0.030931279063224792, 0.021952755749225616, 0.03290863335132599, 0.05740533396601677, 0.05587515980005264, 0.04864276573061943, 0.023520758375525475, 0.01510855183005333, 0.027386324480175972, 0.024518456310033798, 0.060604557394981384, 0.03477614372968674, 0.026137840002775192, 0.05168436840176582, 0.06281402707099915, 0.020291468128561974, 0.028601735830307007, 0.09081020206212997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23978593945503235, 0.03132351487874985, 0.050377536565065384, 0.015869436785578728, 0.039014607667922974, 0.02280554361641407, 0.04285355657339096, 0.02888231724500656, 0.04046263173222542, 0.0341072604060173, 0.022644516080617905, 0.03923070430755615, 0.0723857432603836, 0.022345518693327904, 0.04958108067512512, 0.03193335980176926, 0.023325592279434204, 0.04521363973617554, 0.030554380267858505, 0.022876497358083725, 0.024732284247875214, 0.05549481511116028, 0.014199568890035152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2358168214559555, 0.020558306947350502, 0.04375005513429642, 0.029704859480261803, 0.03703877329826355, 0.014953458681702614, 0.04004311189055443, 0.027184367179870605, 0.04576181620359421, 0.03809262439608574, 0.014181885868310928, 0.03789154440164566, 0.06518244743347168, 0.014182931743562222, 0.05489494279026985, 0.023720968514680862, 0.014592777006328106, 0.025570034980773926, 0.07356180250644684, 0.03918234631419182, 0.014925519935786724, 0.04628867655992508, 0.027801059186458588, 0.015118872746825218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14254964888095856, 0.012010158970952034, 0.016881290823221207, 0.020742563530802727, 0.03245177119970322, 0.029626009985804558, 0.030295196920633316, 0.05620869621634483, 0.029608745127916336, 0.029481831938028336, 0.03263988345861435, 0.010038218460977077, 0.04078616574406624, 0.03462786227464676, 0.03391636908054352, 0.020155727863311768, 0.03684321418404579, 0.060646943747997284, 0.04744711145758629, 0.032525304704904556, 0.04040035605430603, 0.05947759002447128, 0.031293995678424835, 0.04792546480894089, 0.07141983509063721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22229069471359253, 0.059111353009939194, 0.0370267778635025, 0.04059012979269028, 0.027254480868577957, 0.019174769520759583, 0.031715359538793564, 0.0204621609300375, 0.03811328113079071, 0.019927889108657837, 0.018538929522037506, 0.015436705201864243, 0.04536491259932518, 0.01935577392578125, 0.05035829916596413, 0.033281393349170685, 0.020179755985736847, 0.03679434210062027, 0.0433138832449913, 0.028476417064666748, 0.021317338570952415, 0.04771285131573677, 0.01310703344643116, 0.026336034759879112, 0.030211376026272774, 0.03454805165529251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28438133001327515, 0.023870108649134636, 0.04641878232359886, 0.010260088369250298, 0.033909872174263, 0.018301473930478096, 0.02370886504650116, 0.02476685121655464, 0.0257677361369133, 0.022968826815485954, 0.016735462471842766, 0.013406937941908836, 0.04598662257194519, 0.016673240810632706, 0.08106391131877899, 0.05033262446522713, 0.01672617346048355, 0.019904814660549164, 0.030325351282954216, 0.01014631800353527, 0.017318226397037506, 0.019040964543819427, 0.011081119067966938, 0.052046407014131546, 0.0333535298705101, 0.03880883753299713, 0.012695525772869587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11854352056980133, 0.013350935652852058, 0.013422025367617607, 0.030273202806711197, 0.02616293914616108, 0.020776186138391495, 0.0212801992893219, 0.03798934817314148, 0.03536440059542656, 0.036651790142059326, 0.022004006430506706, 0.015380024909973145, 0.030023103579878807, 0.023299690335989, 0.03000754490494728, 0.014861369505524635, 0.024521950632333755, 0.03999801352620125, 0.039001572877168655, 0.036007679998874664, 0.026851214468479156, 0.06795871257781982, 0.038931313902139664, 0.057258062064647675, 0.06659835577011108, 0.03075685352087021, 0.02334320917725563, 0.05938269942998886, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25091859698295593, 0.011351886205375195, 0.023033946752548218, 0.018849756568670273, 0.013208831660449505, 0.016430390998721123, 0.03763696178793907, 0.02151942066848278, 0.03823146969079971, 0.031223108991980553, 0.01608109660446644, 0.017179002985358238, 0.08239651471376419, 0.01577541045844555, 0.04969310760498047, 0.03397901728749275, 0.016469139605760574, 0.025656115263700485, 0.053269315510988235, 0.02438098005950451, 0.017032913863658905, 0.031062565743923187, 0.014834257774055004, 0.043107789009809494, 0.027818359434604645, 0.015127947553992271, 0.012749837711453438, 0.026852669194340706, 0.014129594899713993, 0.0, 0.0, 0.0, 0.0], [0.19256946444511414, 0.022833669558167458, 0.014495886862277985, 0.02805502526462078, 0.03290428966283798, 0.018577080219984055, 0.02377672865986824, 0.01498892717063427, 0.027755476534366608, 0.019952157512307167, 0.018426887691020966, 0.026808448135852814, 0.04026198387145996, 0.018957341089844704, 0.01998024433851242, 0.039050307124853134, 0.019494330510497093, 0.030714338645339012, 0.07932321727275848, 0.03619769960641861, 0.020379595458507538, 0.023319289088249207, 0.01872384361922741, 0.05692768841981888, 0.02392754703760147, 0.03924325481057167, 0.02178352139890194, 0.020374221727252007, 0.04178831726312637, 0.00840923935174942, 0.0, 0.0, 0.0], [0.18919390439987183, 0.01435207761824131, 0.027829360216856003, 0.018936041742563248, 0.054552339017391205, 0.024302393198013306, 0.020752551034092903, 0.030501794070005417, 0.016900410875678062, 0.029904041439294815, 0.02311178296804428, 0.02166484296321869, 0.0333598293364048, 0.023050501942634583, 0.027927035465836525, 0.026253484189510345, 0.024257967248558998, 0.024394983425736427, 0.017666678875684738, 0.02208106964826584, 0.025441516190767288, 0.02399672009050846, 0.01594141311943531, 0.021863477304577827, 0.04876274615526199, 0.010234065353870392, 0.025762982666492462, 0.06192328408360481, 0.06737107038497925, 0.018184125423431396, 0.009525515139102936, 0.0, 0.0], [0.27111953496932983, 0.05460578203201294, 0.039705973118543625, 0.03512894734740257, 0.020313767716288567, 0.008183852769434452, 0.022556617856025696, 0.014036444947123528, 0.026198463514447212, 0.03235536068677902, 0.007185027468949556, 0.01081349328160286, 0.051626089960336685, 0.007057543378323317, 0.042327746748924255, 0.01850598119199276, 0.006952994968742132, 0.012550849467515945, 0.037855181843042374, 0.014787377789616585, 0.007130765821784735, 0.01895672269165516, 0.010758972726762295, 0.023540524765849113, 0.01625620760023594, 0.007915407419204712, 0.03652311861515045, 0.014562276192009449, 0.019251452758908272, 0.010911819525063038, 0.034396715462207794, 0.06592902541160583, 0.0], [0.14836539328098297, 0.014506885781884193, 0.007646290585398674, 0.01103874109685421, 0.026302488520741463, 0.013194814324378967, 0.0271848663687706, 0.017392192035913467, 0.016122113913297653, 0.03288079425692558, 0.014050286263227463, 0.007167341653257608, 0.0161200650036335, 0.014647024683654308, 0.018450897186994553, 0.013102118857204914, 0.015283250249922276, 0.014542998746037483, 0.05961218848824501, 0.02238389290869236, 0.016796976327896118, 0.10928261280059814, 0.07263998687267303, 0.08393712341785431, 0.025249002501368523, 0.03774845972657204, 0.01622692123055458, 0.02495388500392437, 0.04216580465435982, 0.004525812342762947, 0.01449135784059763, 0.019145706668496132, 0.02284165285527706]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09646996110677719, 0.9035300612449646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043252408504486084, 0.08177752792835236, 0.8749701380729675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09995391219854355, 0.025312697514891624, 0.020108038559556007, 0.8546252846717834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024889372289180756, 0.0032073582988232374, 0.0018421611748635769, 0.022361520677804947, 0.9476996660232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10732375085353851, 0.017841670662164688, 0.01955334283411503, 0.0433332584798336, 0.10211500525474548, 0.7098329663276672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006426359061151743, 0.0004479784402064979, 0.00014756589371245354, 0.0004693674563895911, 0.0014411886222660542, 0.003859696676954627, 0.98720782995224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010354575933888555, 0.00019901820633094758, 0.00016020381008274853, 6.9372785219457e-05, 0.00038674141978845, 0.005171585362404585, 0.8964057564735413, 0.09657192975282669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012883340241387486, 0.0003233459428884089, 0.0002652723924256861, 0.000254906655754894, 0.00020129882614128292, 0.00010049015691038221, 0.000570089730899781, 0.00040913073462434113, 0.9965871572494507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00018741605163086206, 1.619651447981596e-05, 4.2281039895897266e-06, 0.000287588540231809, 1.1125704986625351e-05, 9.805656191019807e-06, 0.0001556719362270087, 7.632956840097904e-05, 0.0034869059454649687, 0.9957647323608398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015741519629955292, 0.0006393613293766975, 0.00045715257874689996, 0.000991252833046019, 0.002114036353304982, 0.01808975078165531, 0.0471203587949276, 0.0701090469956398, 0.061528366059064865, 0.2769039571285248, 0.5063051581382751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000616659817751497, 0.0005207082722336054, 4.61151976196561e-05, 0.001461300882510841, 0.0005623759934678674, 4.447595347301103e-05, 0.0003653968160506338, 0.0002860168751794845, 0.004506120923906565, 0.005816523917019367, 0.0007244533626362681, 0.9850499033927917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010478582698851824, 3.062820542254485e-05, 0.00017345028754789382, 5.423134643933736e-05, 6.388442125171423e-05, 1.1261148756602779e-05, 1.7169008060591295e-05, 1.3931321518612094e-05, 0.002076044213026762, 0.0002692685811780393, 0.00015268517017830163, 0.0036844429560005665, 0.992405116558075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01074626948684454, 0.0002535430248826742, 0.00015322912076953799, 0.0002928700705524534, 0.0005376794142648578, 0.0044235410168766975, 0.009884323924779892, 0.012843027710914612, 0.012738605961203575, 0.05966855585575104, 0.10772984474897385, 0.02474566549062729, 0.07808699458837509, 0.6778957843780518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041218040860258043, 2.6218713173875585e-05, 1.7755939552444033e-05, 0.00019181919924449176, 3.2979523894027807e-06, 3.912678039341699e-06, 1.043809788825456e-05, 4.906844878860284e-06, 0.0005868562147952616, 0.003038158407434821, 3.693128383019939e-05, 0.000772431492805481, 0.009622619487345219, 0.00016094441525638103, 0.9851114153862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010886562085943297, 3.58454167326272e-06, 5.191652689973125e-06, 3.083834599237889e-05, 1.8408745745546184e-05, 7.954757847983274e-07, 3.3532007819303544e-06, 6.574371127499035e-06, 0.0007270929636433721, 0.0018232447328045964, 7.853259376133792e-06, 0.00030627453816123307, 0.006975044962018728, 3.4850869269575924e-05, 0.02829272672533989, 0.9616552591323853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006073995493352413, 8.815208275336772e-05, 4.583783811540343e-05, 8.250495739048347e-05, 0.00012720450467895716, 0.000931252259761095, 0.001669999212026596, 0.0019381919410079718, 0.002101697726175189, 0.010131681337952614, 0.016047311946749687, 0.0038353849668055773, 0.01224216353148222, 0.10037080943584442, 0.07853130996227264, 0.10997357964515686, 0.6558089256286621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0021862986031919718, 1.1892928341694642e-05, 1.6735943063395098e-05, 2.0815448806388304e-05, 2.1162531993468292e-05, 0.0007714927778579295, 0.0008652108372189105, 0.0005560302524827421, 0.0001565589918754995, 0.001949993660673499, 0.010891206562519073, 0.0003954299900215119, 0.0015144739300012589, 0.06916320323944092, 0.0043081059120595455, 0.0040351650677621365, 0.4939699172973633, 0.4091663658618927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.979800799745135e-05, 4.972397960045782e-07, 9.165694869750496e-09, 1.3230416584519844e-07, 5.601832597790235e-08, 1.1903853902595074e-08, 6.15311137153185e-07, 4.068542835966582e-08, 4.517441993812099e-06, 1.4017764442542102e-05, 1.6456900198136282e-07, 1.0863833495022845e-06, 7.444068614859134e-06, 1.00566455785156e-06, 2.75950224022381e-05, 0.00031378038693219423, 6.20114269622718e-06, 8.213378350774292e-06, 0.9995948672294617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.497162758023478e-06, 8.692028927725914e-07, 1.405140778842906e-06, 3.770490479837463e-07, 3.3291667023149785e-07, 6.104986027821724e-08, 2.5430054506614397e-08, 1.1067781713336444e-07, 3.670877413242124e-05, 5.70481461181771e-07, 6.172359121592308e-07, 0.00015627981338184327, 0.00014738000754732639, 3.0103849439910846e-06, 6.130666588433087e-05, 0.0017769956029951572, 1.8545992134022526e-05, 3.4263168345205486e-05, 0.9233516454696655, 0.0744030550122261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003649005200713873, 3.749436655198224e-05, 1.7470789316575974e-05, 2.8449230740079656e-05, 3.312428088975139e-05, 0.00019569203141145408, 0.0002647591754794121, 0.00024690391728654504, 0.00028033152921125293, 0.0013949201675131917, 0.0017910292372107506, 0.00042467910679988563, 0.0014623706229031086, 0.009717757813632488, 0.008053941652178764, 0.013200568035244942, 0.06315954774618149, 0.07152795046567917, 0.0752311423420906, 0.024205075576901436, 0.7250778079032898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006410889327526093, 3.925702003471088e-06, 1.160736360361625e-06, 1.5375468365164124e-06, 9.072643365470867e-07, 8.058198545768391e-06, 1.3223934729467146e-05, 4.619919764081715e-06, 3.678829671116546e-05, 4.5651795517187566e-05, 7.577823998872191e-05, 2.2741691282135434e-05, 5.66846392757725e-05, 0.00047375119174830616, 0.0003640763752628118, 0.0004240018897689879, 0.0037573284935206175, 0.004363135434687138, 0.007395218592137098, 0.005022624973207712, 0.05575622245669365, 0.9215315580368042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005377682973630726, 8.122552230815927e-07, 2.301856056874385e-06, 1.4700384554089396e-06, 1.8703644855122548e-06, 6.024482104294293e-07, 4.127829015487805e-06, 1.670573169576528e-06, 2.0471920834097546e-06, 7.430032565025613e-05, 3.5942225622420665e-06, 7.171494871727191e-06, 3.0528204661095515e-05, 1.892773616418708e-05, 0.0002543875016272068, 0.0001949636498466134, 0.00012626526586245745, 0.0001823053607949987, 0.0037352179642766714, 0.0006727115251123905, 0.001579830888658762, 0.0111776702105999, 0.9813894629478455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.512831118423492e-05, 4.870875045526191e-07, 1.2458966693884577e-06, 2.081133487763509e-07, 1.924289705357296e-07, 3.704030859807972e-08, 4.5552562255579687e-07, 5.5045557445509985e-08, 1.5320376860472606e-06, 5.083318683318794e-06, 2.1401018557298812e-07, 1.459531858927221e-06, 1.4768386790819932e-05, 1.0635033049766207e-06, 2.9461503800121136e-05, 5.728815813199617e-05, 6.6156867433164734e-06, 7.844239007681608e-06, 0.00015063839964568615, 0.00022636978246737272, 7.973593892529607e-05, 0.00013040857447776943, 0.010868418030440807, 0.988331139087677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004166322760283947, 2.250370243928046e-06, 5.270539531920804e-06, 2.754915476543829e-05, 3.963050767197274e-05, 7.514737717428943e-06, 8.100926606857684e-06, 1.1581333637877833e-05, 1.3205944014771376e-05, 6.750717875547707e-05, 2.52127465500962e-05, 1.4860675037198234e-05, 7.521689258283004e-05, 0.00011457454093033448, 0.00025745294988155365, 0.00036668573739007115, 0.000690473010763526, 0.001451847841963172, 0.0032460184302181005, 0.0006353411008603871, 0.008745581842958927, 0.015190837904810905, 0.01815015822649002, 0.13303302228450775, 0.8174035549163818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.673928454692941e-05, 8.245334015555272e-08, 3.25739257789337e-08, 2.8737451529536884e-08, 1.621771161808283e-07, 1.5275413156601303e-09, 2.327868919849152e-08, 5.576728856482305e-09, 1.2825790918213897e-07, 1.3429512080165296e-07, 6.160572496582972e-09, 2.523255204778252e-07, 3.205756911484059e-06, 2.627727724302531e-08, 7.619962616445264e-07, 7.901951903477311e-06, 1.3940480414476042e-07, 1.9552575736270228e-07, 0.00032022554660215974, 8.173685728252167e-07, 1.5630020016033086e-06, 3.763166887438274e-06, 0.0007450510165654123, 0.0037152289878576994, 3.934420965379104e-05, 0.995144248008728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023842287191655487, 5.040105861553457e-06, 1.3208615428084158e-06, 8.599827197031118e-06, 5.166058144823182e-06, 1.347093672166011e-07, 6.710815796395764e-07, 2.6997003033102374e-07, 6.345736892399145e-06, 4.417839227244258e-05, 2.744501159668289e-07, 2.0171210053376853e-05, 1.6526657418580726e-05, 8.122790404740954e-07, 0.00010771032248158008, 0.0001239745324710384, 3.5075918276561424e-06, 8.505855475959834e-06, 6.980274338275194e-05, 0.0002681368787307292, 2.8792945158784278e-05, 0.00011957927927142009, 0.0001296167611144483, 0.007425944320857525, 0.0007109728758223355, 0.005815024022012949, 0.984840452671051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004089947324246168, 6.095360163271835e-07, 1.9963877093687188e-06, 9.31031445361441e-06, 3.76905404664285e-06, 1.987650648516137e-06, 4.576547496526473e-07, 1.0690704357330105e-06, 3.087171535298694e-06, 9.211415999743622e-06, 4.724365680885967e-06, 1.2070033790223533e-06, 5.095616415928816e-06, 1.804708517738618e-05, 4.8578654968878254e-05, 4.169379099039361e-05, 0.0001053749438142404, 0.0002246684889541939, 0.00011528604954946786, 0.000249289907515049, 0.001367311691865325, 0.0016190300229936838, 0.0013275165110826492, 0.0034917828161269426, 0.063056580722332, 0.0064690615981817245, 0.09512634575366974, 0.8262878656387329, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00031804636819288135, 1.4181788401401718e-06, 3.185494676927192e-07, 2.7823080017697066e-06, 5.388588397181593e-05, 4.300594369510691e-08, 5.38626068191661e-07, 8.497841008647811e-08, 5.999692120894906e-07, 4.110318513994571e-06, 7.099385612718834e-08, 8.454292128590168e-07, 2.526610387576511e-06, 2.1983822762194904e-07, 6.098234734963626e-06, 2.112996662617661e-05, 9.41176608648675e-07, 9.950348385245888e-07, 3.041351737920195e-05, 2.976983751068474e-06, 8.453844202449545e-06, 2.6006940970546566e-05, 0.00023055786732584238, 0.00133833521977067, 0.00021758176444564015, 0.0070143816992640495, 0.017923962324857712, 0.0005302666686475277, 0.9722622632980347, 0.0, 0.0, 0.0, 0.0], [1.85052627443838e-07, 5.565671479246248e-09, 7.262683787701008e-10, 7.745983410245572e-09, 1.507948255152769e-08, 8.228506209739805e-10, 1.7915451344663325e-09, 1.7345613834152118e-09, 1.0962514451762218e-08, 5.003294134553471e-08, 3.9228162940219136e-09, 1.0013924622853665e-07, 2.3337792143252045e-08, 1.6555224746639396e-08, 5.171339623188942e-08, 1.6145995118677092e-07, 9.827901692460728e-08, 2.7074545982941345e-07, 5.4119718697620556e-06, 2.5083886612264905e-07, 1.1806000657088589e-06, 2.8004258183500497e-06, 4.6103677959763445e-06, 0.00022679210815113038, 5.794253229396418e-05, 0.00045195568236522377, 0.00011976478708675131, 0.00023980809783097357, 0.0018740056548267603, 0.9970145225524902, 0.0, 0.0, 0.0], [4.347457434050739e-05, 2.968866283481475e-06, 3.9193648149193905e-07, 9.117064223573834e-07, 4.364485164387588e-07, 4.686581345225704e-09, 9.240376641628245e-08, 1.241937130913584e-08, 7.188949524561394e-08, 6.304548492153117e-07, 6.1088996083924485e-09, 1.9987159305401292e-07, 1.4578700984202442e-06, 1.4727314479046072e-08, 1.7957290765480138e-07, 2.6422632799949497e-05, 5.112665846240816e-08, 4.710682333097793e-08, 0.001576117821969092, 2.1989408196532167e-06, 3.3339884453198465e-07, 2.1814769297634484e-06, 0.0001624042197363451, 0.0017777644097805023, 1.174922817881452e-05, 0.00361609342508018, 6.199476774781942e-05, 3.516822835081257e-05, 0.001148871029727161, 0.016085602343082428, 0.975442111492157, 0.0, 0.0], [0.0011562927393242717, 6.199030394782312e-06, 6.137777290859958e-07, 3.102660230069887e-06, 8.228400361076638e-07, 4.36601119702118e-08, 9.36325577072239e-08, 2.7735437058140633e-08, 5.10950087573292e-07, 1.235528543475084e-06, 3.825297056891941e-08, 1.1272275060036918e-06, 1.9008951994692325e-06, 8.714073373994324e-08, 5.398172561399406e-06, 7.393416581180645e-06, 3.1288666946238664e-07, 3.0146313179102435e-07, 0.00013595313066616654, 1.334382250206545e-05, 2.3996453819563612e-06, 3.871273293043487e-05, 0.000821963301859796, 0.0006131274858489633, 2.151845910702832e-05, 0.004140724893659353, 0.0008760862983763218, 0.00011684626952046528, 0.0021590692922472954, 0.027525300160050392, 0.04434972628951073, 0.9179997444152832, 0.0], [0.003194288117811084, 4.681659993366338e-05, 3.499122249195352e-05, 2.7043040972785093e-05, 1.4000300325278658e-05, 1.7085118088289164e-05, 8.05188847152749e-06, 3.909828592441045e-06, 1.0716920769482385e-05, 1.7930802641785704e-05, 1.420748776581604e-05, 2.6911264285445213e-05, 2.641200444486458e-05, 3.110023681074381e-05, 1.119859553000424e-05, 5.4854859627084807e-05, 0.00011474482016637921, 0.00010493677837075666, 0.00028063036734238267, 0.0002083906001644209, 0.0009329262538813055, 0.0018990013049915433, 0.0011267600348219275, 0.0019257264211773872, 0.003917159512639046, 0.007499458268284798, 0.0106959268450737, 0.023199858143925667, 0.030398178845643997, 0.1272934377193451, 0.04325320944190025, 0.17668065428733826, 0.5669295191764832]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25308629870414734, 0.746913731098175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3067159950733185, 0.3290637731552124, 0.3642202317714691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07416974753141403, 0.16189667582511902, 0.05432592332363129, 0.7096076607704163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16688227653503418, 0.03901785612106323, 0.03822461515665054, 0.2139836996793747, 0.5418915748596191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19483636319637299, 0.21119250357151031, 0.05150557681918144, 0.0870383009314537, 0.22999541461467743, 0.22543179988861084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1390012949705124, 0.02974863536655903, 0.038606978952884674, 0.0513327457010746, 0.19284239411354065, 0.08012380450963974, 0.4683440625667572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08969773352146149, 0.04080597683787346, 0.03473307564854622, 0.08414527773857117, 0.09911049902439117, 0.07059452682733536, 0.1361657828092575, 0.4447471499443054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05986515060067177, 0.020190436393022537, 0.018785325810313225, 0.10584725439548492, 0.057948801666498184, 0.027517713606357574, 0.056663159281015396, 0.0822676345705986, 0.5709145665168762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010379279963672161, 0.004698257893323898, 0.004143994301557541, 0.00729141291230917, 0.0062567018903791904, 0.003318049944937229, 0.00917502585798502, 0.018754417076706886, 0.03393152728676796, 0.9020513892173767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07270108908414841, 0.0477648489177227, 0.010500337928533554, 0.016159430146217346, 0.046178217977285385, 0.0524945929646492, 0.05184568092226982, 0.2118951827287674, 0.03515822812914848, 0.17267192900180817, 0.2826305031776428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015126866288483143, 0.004731182474642992, 0.0023226290941238403, 0.006575728300958872, 0.01836242899298668, 0.003339661518111825, 0.008784201927483082, 0.0074097225442528725, 0.0062897950410842896, 0.07638928294181824, 0.01200344879180193, 0.8386649489402771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.032331958413124084, 0.010628974065184593, 0.0026151672936975956, 0.0011762939393520355, 0.0030932859517633915, 0.00150555360596627, 0.007079716771841049, 0.0028344711754471064, 0.005003888159990311, 0.01203258614987135, 0.003987773787230253, 0.05187242105603218, 0.8658378720283508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05045584216713905, 0.026538822799921036, 0.00578326964750886, 0.008087297901511192, 0.02179938182234764, 0.025670362636446953, 0.022779010236263275, 0.09139908850193024, 0.015017385594546795, 0.07093920558691025, 0.1244862824678421, 0.12668342888355255, 0.061021383851766586, 0.34933921694755554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05474121496081352, 0.05296844244003296, 0.003988128155469894, 0.012351611629128456, 0.004415619652718306, 0.0035962776746600866, 0.011385687626898289, 0.009828068315982819, 0.014749730937182903, 0.07078820466995239, 0.011209179647266865, 0.05164057016372681, 0.19734404981136322, 0.02712928131222725, 0.47386401891708374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007163074798882008, 0.0049638510681688786, 0.0027692278381437063, 0.0019424451747909188, 0.010544744320213795, 0.0014144877204671502, 0.0036636609584093094, 0.0031499452888965607, 0.005481296218931675, 0.021614039316773415, 0.003922193311154842, 0.07935071736574173, 0.2247791737318039, 0.009166947565972805, 0.027402691543102264, 0.5926714539527893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03461108356714249, 0.015296352095901966, 0.003095123218372464, 0.003899096045643091, 0.00998940784484148, 0.011446877382695675, 0.00918935053050518, 0.03356511518359184, 0.005761212669312954, 0.02558104321360588, 0.043846867978572845, 0.04521365463733673, 0.02055342122912407, 0.11962329596281052, 0.15673254430294037, 0.13173453509807587, 0.329861044883728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01725386083126068, 0.004397521261125803, 0.004968687426298857, 0.007064309436827898, 0.006634890101850033, 0.006910952273756266, 0.011386901140213013, 0.01617850922048092, 0.02031775936484337, 0.02039678953588009, 0.023422086611390114, 0.01890912465751171, 0.0402420312166214, 0.06200674548745155, 0.11645364761352539, 0.07975100725889206, 0.16864454746246338, 0.37506067752838135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002459116280078888, 0.00024919791030697525, 3.400466084713116e-05, 0.0002113294176524505, 0.00020066798606421798, 0.0001258924457943067, 0.00036506823380477726, 0.0003735981590580195, 0.00013798549480270594, 0.0004702214209828526, 0.00027151801623404026, 0.0034170830622315407, 0.0006049814983271062, 0.000545460672583431, 0.0008937675156630576, 0.0015852147480472922, 0.0012150746770203114, 0.002821272239089012, 0.9840186238288879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015282434469554573, 0.038923557847738266, 0.00047151927719824016, 0.00037318107206374407, 3.271787500125356e-05, 1.0635613762133289e-05, 3.82458756575943e-06, 1.324468212260399e-05, 6.418918201234192e-05, 2.7344345653546043e-05, 2.8319931516307406e-05, 0.0022295680828392506, 0.0013866389635950327, 7.163511327235028e-05, 0.0001402555499225855, 0.008246437646448612, 0.00019678636454045773, 0.00020546688756439835, 0.8976381421089172, 0.049783773720264435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026458127424120903, 0.010410883463919163, 0.0021332567557692528, 0.0024560156743973494, 0.005542594939470291, 0.0059545706026256084, 0.004195829387754202, 0.01345154270529747, 0.0023519517853856087, 0.009471972472965717, 0.015433414839208126, 0.014804963022470474, 0.006865771487355232, 0.03787313401699066, 0.04744938760995865, 0.04547279700636864, 0.10199162364006042, 0.08666397631168365, 0.06470181792974472, 0.1016075387597084, 0.3947088420391083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021157873794436455, 0.0035484314430505037, 0.001744112349115312, 0.003509305650368333, 0.004201894160360098, 0.002577780745923519, 0.004015854559838772, 0.004599004052579403, 0.003955155611038208, 0.006455838680267334, 0.005907890852540731, 0.0037331595085561275, 0.009013407863676548, 0.013927984982728958, 0.02989581972360611, 0.020082319155335426, 0.03804437816143036, 0.06883100420236588, 0.0815289169549942, 0.03834022581577301, 0.1516025811433792, 0.48332706093788147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014211704256013036, 0.0004069017886649817, 0.0002714426373131573, 0.0014869263395667076, 0.0006475158152170479, 0.0002567155461292714, 0.00027297664200887084, 0.000505985866766423, 0.00017537525855004787, 0.0012059614527970552, 0.0005902897100895643, 0.00043073983397334814, 0.00036999661824665964, 0.0013322844170033932, 0.0007594277849420905, 0.002518310211598873, 0.0035999822430312634, 0.0047567239962518215, 0.011892943643033504, 0.0034102187491953373, 0.013851115480065346, 0.05907334387302399, 0.8907637596130371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005058860406279564, 0.000882354099303484, 0.0015358275268226862, 0.0016909866826608777, 0.0013438730966299772, 0.0004949701833538711, 0.0006572249112650752, 0.000552159093786031, 0.000581209606025368, 0.0020545588340610266, 0.0008380856597796082, 0.0010067486437037587, 0.001130085438489914, 0.001613991684280336, 0.00502287270501256, 0.014576870016753674, 0.0037143270019441843, 0.00468147499486804, 0.00791381485760212, 0.00677838921546936, 0.012291360646486282, 0.02773299440741539, 0.10214638710021973, 0.7957004904747009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004004694055765867, 0.00045769705320708454, 0.001564521575346589, 0.0031372022349387407, 0.0019937437027692795, 0.00037892634281888604, 0.0004957785131409764, 0.0005698020104318857, 0.0010052066063508391, 0.0023432234302163124, 0.000577214581426233, 0.0016756134573370218, 0.0030787361320108175, 0.0012285254197195172, 0.0052783251740038395, 0.006328051909804344, 0.003151729702949524, 0.005319307092577219, 0.02138310857117176, 0.006147702690213919, 0.012332224287092686, 0.07402162253856659, 0.1211402490735054, 0.5611117482185364, 0.16127502918243408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001128658070228994, 4.988930231775157e-05, 4.129138324060477e-05, 9.24963824218139e-05, 5.51363846170716e-05, 3.8617366953985766e-05, 5.59204381715972e-05, 0.0001489632559241727, 5.509230959432898e-06, 6.817452958784997e-05, 3.6204492062097415e-05, 4.623966015060432e-05, 0.0010655040387064219, 5.919886825722642e-05, 7.787268259562552e-05, 0.00038421296630986035, 0.00011692449334077537, 0.00022428261581808329, 0.0005083996220491827, 0.000156281515955925, 0.0003233152092434466, 0.0007086835685186088, 0.0009207433904521167, 0.000855972757562995, 0.004414445720613003, 0.9884170889854431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002429968910291791, 0.003659638110548258, 0.0006344973226077855, 0.0006202646181918681, 0.002987676067277789, 0.0003476364363450557, 0.0005059160757809877, 0.0004114967305213213, 0.00021321575331967324, 0.000650934292934835, 0.00039556898991577327, 0.16986437141895294, 0.0021888979244977236, 0.0006812371429987252, 0.0008683764608576894, 0.008905136957764626, 0.001463850261643529, 0.0013394583947956562, 0.006495130248367786, 0.007638707756996155, 0.00461939349770546, 0.0031617884524166584, 0.014200889505445957, 0.046396613121032715, 0.022786034271121025, 0.21939241886138916, 0.4771409332752228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01561034470796585, 0.0009648078703321517, 0.0010281841969117522, 0.0071485210210084915, 0.005316658411175013, 0.0005432688631117344, 0.0007839894969947636, 0.00047082992387004197, 0.0022980384528636932, 0.005463100969791412, 0.0005483075510710478, 0.0008661506581120193, 0.0009035564726218581, 0.0009251972078345716, 0.008375938981771469, 0.0014478116063401103, 0.002061491133645177, 0.0036933845840394497, 0.017008868977427483, 0.006138672586530447, 0.0070418999530375, 0.041287098079919815, 0.06922487914562225, 0.2661718428134918, 0.05024212598800659, 0.1144513413310051, 0.13764901459217072, 0.23233464360237122, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02189529873430729, 0.0013514538295567036, 0.0013727964833378792, 0.005157724488526583, 0.010932797566056252, 0.0004452221328392625, 0.0016178287332877517, 0.0005713265854865313, 0.0007700271671637893, 0.0030935369431972504, 0.00036163401091471314, 0.000932903029024601, 0.001903239986859262, 0.0005254385177977383, 0.0007036192109808326, 0.0015780625399202108, 0.0010200467659160495, 0.0009346716105937958, 0.005167576018720865, 0.0007855423027649522, 0.0028796831611543894, 0.006337146274745464, 0.049514152109622955, 0.021886909380555153, 0.030046822503209114, 0.06941599398851395, 0.02995389513671398, 0.06111619994044304, 0.6677284836769104, 0.0, 0.0, 0.0, 0.0], [0.000294666038826108, 8.085126319201663e-05, 0.00011992641520919278, 0.0001715401012916118, 0.00038990125176496804, 8.630267984699458e-05, 5.25372706761118e-05, 6.616386963287368e-05, 0.0001137840372393839, 6.200086500030011e-05, 0.00011238036677241325, 0.0005867322906851768, 9.78500975179486e-05, 0.00021334874327294528, 0.00040444257319904864, 0.00047262446605600417, 0.0004730735963676125, 0.0005199530860409141, 0.0008571154903620481, 0.00022720213746652007, 0.0015976798022165895, 0.0014780652709305286, 0.0016501453937962651, 0.0093396520242095, 0.012792675755918026, 0.012606967240571976, 0.021659621968865395, 0.02886747568845749, 0.0778479129076004, 0.826757550239563, 0.0, 0.0, 0.0], [0.0006396541139110923, 0.0001992026373045519, 0.0003378460824023932, 0.0003228614223189652, 0.0003883978060912341, 2.2511421775561757e-05, 0.00011559668928384781, 1.968370816030074e-05, 8.749762491788715e-05, 0.00016675748338457197, 2.1353202100726776e-05, 0.0001825768267735839, 0.002879622858017683, 3.2708350772736594e-05, 6.355984805850312e-05, 0.0009078503935597837, 6.314194615697488e-05, 4.954513497068547e-05, 0.005010182503610849, 0.00021555769490078092, 0.00018923310562968254, 0.00023579836124554276, 0.0021191718988120556, 0.003475247649475932, 0.0004957503406330943, 0.012673024088144302, 0.0026274609845131636, 0.001192636787891388, 0.02801147848367691, 0.14214563369750977, 0.7951083779335022, 0.0, 0.0], [0.005492149852216244, 0.0014179612044245005, 6.310038588708267e-05, 0.0009282372775487602, 0.0004675877280533314, 9.701230737846345e-05, 5.6787015637382865e-05, 6.82406680425629e-05, 4.054810415254906e-05, 0.00021011468197684735, 6.534699787152931e-05, 0.00011957802053075284, 9.082323231268674e-05, 9.077344293473288e-05, 0.0001382746995659545, 0.0004122828249819577, 0.0001690058852545917, 0.00013570708688348532, 0.002428322099149227, 0.00020654787658713758, 0.0004959602956660092, 0.00016561975644435734, 0.0018254045862704515, 0.0016808181535452604, 0.0010187349980697036, 0.015071484260261059, 0.003408379852771759, 0.003384194802492857, 0.018865535035729408, 0.010037437081336975, 0.008259563706815243, 0.923088550567627, 0.0], [0.009386108256876469, 0.0017380565404891968, 0.0018091691890731454, 0.0014350239653140306, 0.0016812817193567753, 0.001979129621759057, 0.0014143431326374412, 0.002112783258780837, 0.0012016947148367763, 0.0010467652464285493, 0.0012532471446320415, 0.0012125696521252394, 0.0006952418480068445, 0.001685018534772098, 0.0012904965551570058, 0.0014949407195672393, 0.0030524604953825474, 0.006176413036882877, 0.003993148449808359, 0.0029945187270641327, 0.008827602490782738, 0.009542388841509819, 0.010477345436811447, 0.02145143412053585, 0.062213554978370667, 0.026861034333705902, 0.03390644118189812, 0.11987607181072235, 0.050274692475795746, 0.0267968587577343, 0.031165683642029762, 0.10728629678487778, 0.4436681568622589]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520479083061218, 0.8947951793670654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03907211124897003, 0.0020172216463834047, 0.9589106440544128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015578649006783962, 0.0008392537129111588, 0.0006979772006161511, 0.9828841090202332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008856466971337795, 9.934306035574991e-06, 1.117485408030916e-05, 0.00030247055110521615, 0.9908198714256287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3544497787952423, 0.0305892676115036, 0.05988960340619087, 0.022903524339199066, 0.0474759005010128, 0.48469194769859314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.044769056141376495, 0.0015664668753743172, 0.000377385294996202, 0.00025073293363675475, 0.00040889691445045173, 0.0002606563502922654, 0.952366828918457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09058346599340439, 0.001147073577158153, 0.006027341354638338, 0.000546847702935338, 0.0017094208160415292, 0.00378508516587317, 0.0026845417451113462, 0.8935161828994751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0060107288882136345, 2.428904736007098e-05, 0.00031266716541722417, 1.8682918380363844e-05, 0.0002979242999572307, 9.904515536618419e-06, 6.619554824283114e-06, 7.912206569926639e-07, 0.9933184385299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00454681646078825, 0.00020019362273160368, 0.00029920271481387317, 0.001336391200311482, 0.0003267655265517533, 8.741358215047512e-07, 1.7415721231373027e-05, 2.7834167326545867e-07, 0.00029665272450074553, 0.9929754734039307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12262554466724396, 0.02392657846212387, 0.03827652707695961, 0.01617196388542652, 0.030366240069270134, 0.293759286403656, 0.10661354660987854, 0.0705995187163353, 0.04190010577440262, 0.017833100631833076, 0.2379276007413864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008121050195768476, 0.00011546615860424936, 0.00013500881323125213, 5.539281846722588e-05, 0.0001317410496994853, 1.0027167718362762e-06, 1.3799076441500802e-06, 1.6001598623915925e-07, 1.8972953057527775e-06, 5.419655622063146e-07, 4.7530869551337673e-07, 0.9987448453903198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013333058450371027, 0.00010533058230066672, 0.0007669612532481551, 0.0009021882433444262, 3.5708394534594845e-06, 8.120483130369394e-07, 1.4038103302027594e-07, 9.56129397877703e-08, 1.686508653619967e-06, 2.9789038308081217e-05, 4.381344922421704e-07, 1.1965810244873865e-06, 0.9968544840812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08159800618886948, 0.02138885296881199, 0.028877170756459236, 0.012675784528255463, 0.024931570515036583, 0.22996489703655243, 0.10401233285665512, 0.06472098082304001, 0.03460093215107918, 0.015198717825114727, 0.1856415718793869, 0.020528046414256096, 0.005003849510103464, 0.1708572655916214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013488875702023506, 8.921202970668674e-05, 0.0006859967252239585, 0.0006963209598325193, 2.1248602934065275e-05, 3.7633867577824276e-07, 6.226732125469425e-07, 4.307212293497287e-07, 7.091874067555182e-06, 0.0013103687670081854, 1.6113736478473584e-07, 9.548743946652394e-07, 0.00016453592979814857, 1.1531915333762299e-07, 0.9956737160682678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010867511155083776, 0.00040724786231294274, 0.00010700341954361647, 0.0006782711134292185, 0.00011028484004782513, 1.3184238412122795e-07, 2.660271150034532e-07, 4.619564037966484e-07, 8.409730980929453e-06, 0.0007784883491694927, 5.109449574547398e-08, 8.792079029262823e-07, 4.9342852435074747e-05, 3.4893165690164096e-08, 0.000114411988761276, 0.9966580867767334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05868089199066162, 0.018785733729600906, 0.024067318066954613, 0.011013144627213478, 0.02145637758076191, 0.1911056935787201, 0.09902714937925339, 0.060658663511276245, 0.03016272373497486, 0.014801906421780586, 0.15370333194732666, 0.016615159809589386, 0.0043853819370269775, 0.14085334539413452, 0.01501499954611063, 0.0053902072831988335, 0.13427799940109253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07323037832975388, 0.028374576941132545, 0.021058261394500732, 0.007611886598169804, 0.010053582489490509, 0.06553955376148224, 0.1455976665019989, 0.08620847761631012, 0.010241267271339893, 0.007425738964229822, 0.04526272416114807, 0.006621459499001503, 0.0011621781159192324, 0.039238568395376205, 0.008256878703832626, 0.0030656892340630293, 0.03612265735864639, 0.4049285054206848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.94449370005168e-05, 1.8382105508862878e-06, 3.7134324060161816e-08, 1.557524774398189e-05, 3.472372327451012e-06, 1.316507125537214e-09, 2.7038657535172206e-08, 1.718662012706318e-08, 9.2322629541286e-08, 1.3506365576176904e-05, 4.4787801245504966e-10, 2.0416692780855783e-09, 5.54200738633881e-08, 3.063855003038185e-10, 4.2177114778496616e-07, 7.065867521305336e-06, 2.4244301011222547e-10, 1.4397331105087119e-09, 0.9998784065246582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002934493590146303, 0.0005883852136321366, 0.004250307101756334, 0.004028463736176491, 0.00011592954979278147, 4.3316258597769774e-06, 6.773906079615699e-06, 7.076467591105029e-05, 0.0002495272201485932, 0.00031593351741321385, 2.082441824313719e-06, 4.4092124880990013e-05, 0.00030446931486949325, 1.4702575299452292e-06, 0.00019761342264246196, 0.0013599254889413714, 1.2478662938519847e-06, 6.875188319099834e-06, 0.000192611274542287, 0.9853246808052063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0405653640627861, 0.017898330464959145, 0.020600976422429085, 0.009821103885769844, 0.01788281835615635, 0.15654000639915466, 0.09208230674266815, 0.05628824234008789, 0.026661334559321404, 0.014471275731921196, 0.12537623941898346, 0.013986770063638687, 0.003927926998585463, 0.11453615128993988, 0.013395381160080433, 0.004846666939556599, 0.10880254209041595, 0.04953394830226898, 0.005186409689486027, 0.004420874174684286, 0.10317535698413849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024536365643143654, 0.003124342067167163, 0.0009699314832687378, 4.63154683529865e-05, 0.00013434789434541017, 0.0006453946698457003, 0.011668852530419827, 0.0003271346795372665, 0.00045730522833764553, 2.397611751803197e-05, 0.00034454200067557395, 4.996428106096573e-05, 2.575740472821053e-05, 0.00028217773069627583, 6.525329808937386e-06, 4.981813617632724e-06, 0.00023554045765195042, 0.00026645135949365795, 2.5311175704700872e-05, 2.9761118639726192e-05, 0.0001880926574813202, 0.9566068649291992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002075995085760951, 0.00014591761282645166, 5.289893306326121e-05, 4.2180658056167886e-05, 4.7387107770191506e-05, 4.1423234620197036e-07, 0.00012964275083504617, 2.4250975911854766e-05, 1.8034011191048194e-06, 1.4839239383945824e-06, 1.4489953059637628e-07, 4.199920567771187e-06, 4.106825457483865e-08, 1.0260462346423083e-07, 8.285448984679533e-07, 5.7818925824904e-07, 7.695144432773304e-08, 6.669597496511415e-08, 6.472609675256535e-05, 1.5700858284617425e-06, 5.641820521873342e-08, 4.403023922350258e-06, 0.9974013566970825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005159099819138646, 0.00011814619938377291, 3.270557863288559e-05, 0.00021188679966144264, 4.563520269584842e-05, 2.9248784016999707e-07, 3.057933781747124e-06, 7.607346219629108e-08, 0.0001375367137370631, 0.0005283530335873365, 1.1576003089430742e-07, 4.028573584946571e-06, 2.07929269890883e-06, 8.805391615851477e-08, 0.00010051658318843693, 4.431615161593072e-05, 6.963698950812613e-08, 9.373022180625412e-08, 3.3377655199728906e-05, 1.5888872439973056e-05, 5.6106753021367695e-08, 7.05262834799214e-08, 9.389279512106441e-06, 0.9981963038444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06915231794118881, 0.01403210312128067, 0.005599101539701223, 0.001257685711607337, 0.0008468003943562508, 0.009601176716387272, 0.008965776301920414, 0.05247695371508598, 0.0002502836287021637, 0.0009063855977728963, 0.005419904366135597, 0.0007309209904633462, 0.00019187953148502856, 0.004396581556648016, 0.005964718759059906, 0.000355853873770684, 0.003877017879858613, 0.009727219119668007, 0.001102349255234003, 0.00036442908458411694, 0.0034139580093324184, 0.0030523547902703285, 0.00569825479760766, 0.00029557320522144437, 0.7923203706741333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001046158722601831, 1.955721563717816e-05, 1.7359042203679564e-06, 3.1030554964672774e-05, 2.7308031349093653e-05, 1.0180717602281675e-08, 4.815781835532107e-07, 1.7494281223662256e-07, 7.3124517996348e-08, 7.983091450114443e-07, 3.464323272694969e-09, 4.906740741716931e-06, 1.0718973442180868e-07, 2.35255281921809e-09, 2.3834166995584383e-07, 1.3731386161452974e-06, 1.8288706105096253e-09, 6.247633965728028e-09, 9.208356459566858e-06, 1.6384317405027105e-06, 1.2523946324449753e-09, 8.27128976421676e-10, 8.456793693767395e-06, 3.1186914384306874e-06, 9.241437837204103e-09, 0.9988435506820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010544945253059268, 0.00021373217168729752, 0.0002815719344653189, 0.0011373362503945827, 0.00014783968799747527, 2.0068493995495373e-06, 4.831355909118429e-06, 3.482335159787908e-06, 5.100344878883334e-06, 0.000124204860185273, 9.301510885961761e-07, 1.058263296727091e-05, 1.168826474895468e-05, 7.077505301822384e-07, 0.0034115957096219063, 0.00019905276712961495, 5.995612468723266e-07, 4.6430378120021487e-07, 1.9585138943511993e-05, 0.00011087791790487245, 4.7500537903033546e-07, 3.2808816285978537e-07, 4.535354491963517e-06, 5.1617142162285745e-05, 3.2474736144649796e-07, 1.3071360626781825e-05, 0.9931889772415161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024200769141316414, 0.0028201285749673843, 0.004319298546761274, 0.0009108301601372659, 0.0017753951251506805, 0.003809913992881775, 0.00295332376845181, 0.016714781522750854, 0.0013931747525930405, 0.005003180354833603, 0.0022760885767638683, 0.0005876413779333234, 0.0009901630692183971, 0.0018066930351778865, 0.003131238743662834, 0.00023389386478811502, 0.0016082720831036568, 0.009910299442708492, 0.0028539523482322693, 0.00020495163334999233, 0.001371264923363924, 0.0069190021604299545, 0.0010336581617593765, 0.00014528397878166288, 0.017489781603217125, 0.00046553139691241086, 0.0003024085017386824, 0.884769082069397, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005256083677522838, 3.528644811012782e-06, 1.7037668840202969e-06, 9.408171172253788e-05, 0.6647970080375671, 1.653147734259619e-07, 9.51111303493235e-07, 8.886892146620085e-07, 1.701669862086419e-05, 3.7421832530526444e-05, 6.832259913380767e-08, 9.810918527364265e-06, 7.548730707185314e-08, 4.963256827750229e-08, 2.0393908926052973e-06, 7.686546268814709e-06, 4.0668474809990585e-08, 2.6744341852236175e-08, 3.343185017001815e-05, 4.341083013059688e-07, 3.007991011827471e-08, 3.206054088877863e-08, 4.900574822386261e-06, 3.060945573452045e-06, 1.4603210196639793e-08, 2.2145519324112684e-05, 9.211162250721827e-06, 3.164275241829273e-08, 0.3344285786151886, 0.0, 0.0, 0.0, 0.0], [0.004677004646509886, 0.0002802134840749204, 8.346102549694479e-05, 3.157015271426644e-06, 4.065346672632586e-07, 1.3343500882001536e-07, 2.6423611416248605e-05, 1.1439977498639564e-07, 2.787237463053316e-07, 3.7496063214348396e-06, 4.652897445112103e-08, 1.7213982346220291e-06, 1.8165617632348585e-07, 3.148475968828279e-08, 1.8334249318741058e-07, 5.2147463236451586e-08, 2.5215808108214333e-08, 3.078440968806717e-08, 7.142043045860191e-08, 1.6640171907056356e-08, 1.7768222448921733e-08, 8.634525272555038e-08, 2.8009644665871747e-06, 8.454143767266942e-07, 3.098357126418705e-08, 2.927866091795295e-07, 5.67622805647261e-07, 5.055421414823513e-09, 2.9141034474378102e-08, 0.9949179887771606, 0.0, 0.0, 0.0], [5.636792411678471e-05, 0.0002002374967560172, 1.6319110045515117e-06, 1.508931291027693e-06, 1.7779768313630484e-05, 5.95644145118257e-10, 6.940375897102058e-06, 5.034010541749012e-09, 2.1682893702745787e-07, 1.7164256860269234e-06, 1.9326265587871205e-10, 1.8911425314627195e-08, 9.538840117784275e-08, 1.2946883842790413e-10, 8.07715050399338e-09, 4.386615546536632e-05, 9.768683778554887e-11, 5.256080015669795e-10, 6.93216934450902e-05, 7.505880716962565e-08, 7.069290985928234e-11, 3.988046870517792e-08, 1.0610276149236597e-05, 2.2120727862784406e-06, 8.688617048058234e-10, 9.92847799352603e-06, 5.390105251024124e-09, 1.1354458345769203e-10, 3.0600433547078865e-06, 3.8945626101849484e-07, 0.9995738863945007, 0.0, 0.0], [0.00035569691681303084, 1.9489438273012638e-05, 9.16096723813098e-06, 1.3085226783005055e-05, 2.3808808691683225e-05, 2.9718906446873916e-08, 4.160590469837189e-05, 1.7756474335328676e-07, 6.896235049680399e-07, 1.0506209946470335e-06, 1.2230741752716767e-08, 4.290535798645578e-06, 3.295820931725757e-07, 9.211071905212975e-09, 1.7466363715357147e-06, 4.682776307163294e-06, 7.442711336125285e-09, 9.67378266381047e-09, 3.9665061194682494e-05, 7.324877628889226e-07, 5.5436903956262995e-09, 1.0396686178637538e-07, 1.4401575754163787e-05, 8.873323167790659e-06, 5.9894045278952035e-09, 1.5627754692104645e-05, 2.9811192234774353e-06, 6.874329550043967e-09, 4.85464624944143e-06, 7.072258540574694e-06, 6.210673745954409e-06, 0.999423623085022, 0.0], [0.05455268546938896, 0.016429057344794273, 0.016008341684937477, 0.006986880209296942, 0.024884143844246864, 0.07376933097839355, 0.07933786511421204, 0.05594552680850029, 0.02726820483803749, 0.013368777930736542, 0.05590308457612991, 0.007223025895655155, 0.00542657682672143, 0.05012328177690506, 0.008279064670205116, 0.003060964634642005, 0.04682298004627228, 0.047518473118543625, 0.0028449436649680138, 0.007037976291030645, 0.04282715544104576, 0.051381904631853104, 0.02728237397968769, 0.02637534588575363, 0.02615920826792717, 0.011997980996966362, 0.00622012373059988, 0.03648781031370163, 0.011124699376523495, 0.005218563601374626, 0.0025592006277292967, 0.00260402774438262, 0.1469704508781433]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9192657470703125, 0.08073429018259048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4543737471103668, 0.42650431394577026, 0.11912190169095993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5267522931098938, 0.2232162207365036, 0.12420625239610672, 0.12582522630691528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39034879207611084, 0.1709941178560257, 0.06872711330652237, 0.1837182193994522, 0.1862117499113083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19744212925434113, 0.2543684244155884, 0.14488466084003448, 0.18925856053829193, 0.20821942389011383, 0.005826788023114204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19473569095134735, 0.13241830468177795, 0.14391931891441345, 0.1512073427438736, 0.30024465918540955, 0.020584633573889732, 0.05688999220728874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1269666701555252, 0.21597382426261902, 0.1608932912349701, 0.1969883143901825, 0.18844623863697052, 0.01354492548853159, 0.07520709931850433, 0.021979713812470436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2912123203277588, 0.05954229459166527, 0.11079412698745728, 0.09717854857444763, 0.22345606982707977, 0.016262583434581757, 0.08719441294670105, 0.02476227656006813, 0.0895974338054657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22981958091259003, 0.03802677243947983, 0.160138338804245, 0.11780405044555664, 0.1618119329214096, 0.03552818298339844, 0.07561115175485611, 0.020756028592586517, 0.10670632869005203, 0.05379769206047058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13314427435398102, 0.1885865181684494, 0.10808100551366806, 0.15994969010353088, 0.17739208042621613, 0.003598014824092388, 0.02506208047270775, 0.012862924486398697, 0.07453098148107529, 0.11275243759155273, 0.0040399846620857716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16746403276920319, 0.1435522586107254, 0.06118571758270264, 0.17358073592185974, 0.10113828629255295, 0.01755346544086933, 0.032395292073488235, 0.007995491847395897, 0.05453447625041008, 0.07883203029632568, 0.017258210107684135, 0.1445099413394928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.269968181848526, 0.1302907019853592, 0.06605684757232666, 0.06156139820814133, 0.08437129855155945, 0.019846618175506592, 0.01631278730928898, 0.012965916655957699, 0.03231465071439743, 0.05254792049527168, 0.019868608564138412, 0.13695639371871948, 0.09693866223096848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09820345789194107, 0.1361864060163498, 0.08005785197019577, 0.12152864038944244, 0.1357937753200531, 0.0024323563557118177, 0.01778949797153473, 0.009086485020816326, 0.05637528374791145, 0.08521631360054016, 0.002753336215391755, 0.1520378738641739, 0.09946723282337189, 0.0030714021995663643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1701289266347885, 0.08885714411735535, 0.09089688956737518, 0.08085784316062927, 0.11427337676286697, 0.01090148277580738, 0.014788413420319557, 0.0054973699152469635, 0.05151257663965225, 0.05330682918429375, 0.010595811530947685, 0.094422847032547, 0.1309812068939209, 0.011153683997690678, 0.07182563841342926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.103658527135849, 0.035885393619537354, 0.08803563565015793, 0.06087934598326683, 0.08348328620195389, 0.03080575540661812, 0.029615938663482666, 0.01091869454830885, 0.04049993306398392, 0.042886052280664444, 0.032192960381507874, 0.1500813215970993, 0.12658780813217163, 0.034902192652225494, 0.05825435742735863, 0.0713128000497818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0704709142446518, 0.09600995481014252, 0.05621582269668579, 0.0869988277554512, 0.09934128820896149, 0.0016298769041895866, 0.012408620677888393, 0.006380434148013592, 0.04101403430104256, 0.06348709017038345, 0.0018482183804735541, 0.11387644708156586, 0.07328981161117554, 0.002071293769404292, 0.07246166467666626, 0.20012786984443665, 0.002367776818573475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05659443512558937, 0.08906206488609314, 0.0470324382185936, 0.09457874298095703, 0.08793889731168747, 0.0019721637945622206, 0.017767688259482384, 0.005990442354232073, 0.06014857441186905, 0.08834964036941528, 0.00226376811042428, 0.10461529344320297, 0.06079370528459549, 0.0025566238909959793, 0.0781862661242485, 0.19496020674705505, 0.0029299946036189795, 0.00425906153395772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.159706249833107, 0.02609645202755928, 0.04515179246664047, 0.03497578576207161, 0.08030679076910019, 0.05469035357236862, 0.04078543931245804, 0.026513004675507545, 0.02725193277001381, 0.03919816389679909, 0.05351431667804718, 0.0484292097389698, 0.0626426637172699, 0.05558210611343384, 0.05559666454792023, 0.04792959988117218, 0.056763261556625366, 0.048923008143901825, 0.035943202674388885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08663123100996017, 0.09557437896728516, 0.036738112568855286, 0.06946706771850586, 0.05681459978222847, 0.008190212771296501, 0.022195827215909958, 0.007642822340130806, 0.03146829083561897, 0.0755520761013031, 0.008965260349214077, 0.05263481289148331, 0.04491105303168297, 0.009935050271451473, 0.04481375962495804, 0.15198466181755066, 0.010933401994407177, 0.007993675768375397, 0.16402560472488403, 0.013528086245059967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04783450812101364, 0.06669353693723679, 0.03798919916152954, 0.06040370464324951, 0.06899043917655945, 0.0010267281904816628, 0.008172678761184216, 0.004158171825110912, 0.028268275782465935, 0.04407239332795143, 0.001158645492978394, 0.07832913845777512, 0.05082901194691658, 0.0013004981447011232, 0.049042992293834686, 0.14145001769065857, 0.001493433490395546, 0.0025566830299794674, 0.17534086108207703, 0.12910203635692596, 0.00178705551661551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04114089161157608, 0.04766074940562248, 0.03587000444531441, 0.06666102260351181, 0.07969272881746292, 0.002365077380090952, 0.020340193063020706, 0.004854495637118816, 0.0643620491027832, 0.06737151741981506, 0.002707370324060321, 0.05596054717898369, 0.05648665502667427, 0.0030767235439270735, 0.05354388803243637, 0.15165932476520538, 0.0035397172905504704, 0.004673933144658804, 0.16402719914913177, 0.05968151241540909, 0.004154941998422146, 0.01016951259225607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0662880688905716, 0.04092540219426155, 0.027322683483362198, 0.04505367577075958, 0.06575217097997665, 0.015657559037208557, 0.027881884947419167, 0.013711252249777317, 0.03174295276403427, 0.05280745401978493, 0.0154477683827281, 0.03218112140893936, 0.032901063561439514, 0.016298862174153328, 0.0266366396099329, 0.09772852808237076, 0.017114199697971344, 0.0169194545596838, 0.09847065061330795, 0.04787909612059593, 0.018412543460726738, 0.015331599861383438, 0.17753544449806213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09801427274942398, 0.026328805834054947, 0.035868145525455475, 0.05713057890534401, 0.06943873316049576, 0.012128954753279686, 0.02090909704566002, 0.008747954852879047, 0.02699965424835682, 0.03726676106452942, 0.011716341599822044, 0.08499536663293839, 0.055013369768857956, 0.012196714989840984, 0.03563910350203514, 0.08789663016796112, 0.012970102950930595, 0.01085102278739214, 0.06408384442329407, 0.059639208018779755, 0.014492184855043888, 0.006093737203627825, 0.09761442989110947, 0.05396495759487152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02769325114786625, 0.04073771834373474, 0.031223557889461517, 0.058790385723114014, 0.05601825937628746, 0.0015714784385636449, 0.011908046901226044, 0.0033397905062884092, 0.05176553130149841, 0.052912428975105286, 0.0018259822390973568, 0.06030036509037018, 0.02835717611014843, 0.0020878096111118793, 0.05086477845907211, 0.07898838073015213, 0.002398707438260317, 0.002904824912548065, 0.11135735362768173, 0.0458601638674736, 0.0028849185910075903, 0.011431250721216202, 0.12340560555458069, 0.134884774684906, 0.006487554870545864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1539076864719391, 0.02378677949309349, 0.05320247262716293, 0.039638862013816833, 0.05711062625050545, 0.015628933906555176, 0.020206082612276077, 0.009252366609871387, 0.021311869844794273, 0.029029954224824905, 0.014741906896233559, 0.06123839318752289, 0.10112591832876205, 0.015157829038798809, 0.043354034423828125, 0.040907200425863266, 0.015732653439044952, 0.0200734231621027, 0.05374931916594505, 0.03468617796897888, 0.016989389434456825, 0.006368498783558607, 0.04042018577456474, 0.031060410663485527, 0.01393715851008892, 0.06738189607858658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555092662572861, 0.035057421773672104, 0.05885257571935654, 0.03497909754514694, 0.05178742855787277, 0.002511989790946245, 0.004151222296059132, 0.002085917629301548, 0.014081125147640705, 0.024491360411047935, 0.0023760043550282717, 0.09535115957260132, 0.07766134291887283, 0.0024908811319619417, 0.04572679102420807, 0.05774117261171341, 0.0026603781152516603, 0.0033477596007287502, 0.04799826815724373, 0.026788821443915367, 0.002958715660497546, 0.0046557895839214325, 0.03607099503278732, 0.021599188446998596, 0.004788635764271021, 0.2205219715833664, 0.033713068813085556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02070670947432518, 0.03719405457377434, 0.019723718985915184, 0.038942232728004456, 0.031826991587877274, 0.001225367421284318, 0.008815756998956203, 0.0024052916560322046, 0.03457954153418541, 0.04729803651571274, 0.0013953748857602477, 0.051482055336236954, 0.020486745983362198, 0.0015608385438099504, 0.03826117515563965, 0.048637550324201584, 0.0017825310351327062, 0.0025446065701544285, 0.06541350483894348, 0.04188564047217369, 0.0020960597321391106, 0.00940138939768076, 0.08460033684968948, 0.09019992500543594, 0.005403275601565838, 0.22932560741901398, 0.05692273750901222, 0.0058829220943152905, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08582810312509537, 0.03967176005244255, 0.014841828495264053, 0.05653619021177292, 0.05960613489151001, 0.006987513974308968, 0.010110093280673027, 0.0028877246659249067, 0.015322854742407799, 0.025928771123290062, 0.006830441765487194, 0.03354894742369652, 0.02109353616833687, 0.007213154342025518, 0.019323399290442467, 0.05298227816820145, 0.0076586101204156876, 0.005157846491783857, 0.06523177772760391, 0.018170014023780823, 0.00853469967842102, 0.00436816830188036, 0.02691243775188923, 0.04962793365120888, 0.004404325503855944, 0.1938866376876831, 0.039332251995801926, 0.005363549571484327, 0.11263898760080338, 0.0, 0.0, 0.0, 0.0], [0.07040347158908844, 0.05926160886883736, 0.015334844589233398, 0.024139031767845154, 0.01572885736823082, 0.019492093473672867, 0.017311513423919678, 0.017303066328167915, 0.020563244819641113, 0.0451558418571949, 0.021815842017531395, 0.07079727947711945, 0.030063936486840248, 0.02354060485959053, 0.02068449556827545, 0.02116367220878601, 0.02644512802362442, 0.02354004792869091, 0.0566372349858284, 0.03369481489062309, 0.030707266181707382, 0.015993356704711914, 0.015474079176783562, 0.0308036170899868, 0.03180557116866112, 0.07969609647989273, 0.034374866634607315, 0.03453715890645981, 0.030624378472566605, 0.06290693581104279, 0.0, 0.0, 0.0], [0.05338499695062637, 0.02962152473628521, 0.021030085161328316, 0.02369571663439274, 0.03343641385436058, 0.018393808975815773, 0.024060705676674843, 0.022810006514191628, 0.01397237554192543, 0.028813567012548447, 0.01905973069369793, 0.015371969901025295, 0.02533530443906784, 0.019971946254372597, 0.014075735583901405, 0.038844525814056396, 0.0213462021201849, 0.01932143047451973, 0.05632655322551727, 0.021360022947192192, 0.023394567891955376, 0.023136626929044724, 0.06416381150484085, 0.06724690645933151, 0.034695085138082504, 0.0434902124106884, 0.03032725304365158, 0.03285713121294975, 0.05327509716153145, 0.0659981369972229, 0.0411825031042099, 0.0, 0.0], [0.1817709058523178, 0.019533157348632812, 0.02800293266773224, 0.029110191389918327, 0.04134834185242653, 0.018019482493400574, 0.01047173049300909, 0.008382905274629593, 0.01533579733222723, 0.02183944173157215, 0.016893349587917328, 0.03806137666106224, 0.03643864765763283, 0.017464272677898407, 0.026129068806767464, 0.04011504724621773, 0.018317213281989098, 0.012488218955695629, 0.05136965215206146, 0.019443843513727188, 0.019889751449227333, 0.003576452611014247, 0.02623296156525612, 0.018429184332489967, 0.011723744682967663, 0.0327298603951931, 0.0348082110285759, 0.012035038322210312, 0.0603029765188694, 0.007873311638832092, 0.04227292537689209, 0.07958997040987015, 0.0], [0.015003394335508347, 0.020334865897893906, 0.00781344622373581, 0.016553577035665512, 0.016466116532683372, 0.00023809634149074554, 0.001959895947948098, 0.0006898260908201337, 0.006483221892267466, 0.010734067298471928, 0.00024435276282019913, 0.014634685590863228, 0.009247618727385998, 0.0002605921181384474, 0.00933991651982069, 0.04272660240530968, 0.0002886394795496017, 0.00038116765790618956, 0.054749395698308945, 0.09452769160270691, 0.00034211305319331586, 0.001727019203826785, 0.04745935648679733, 0.026613809168338776, 0.001023865886963904, 0.16537979245185852, 0.014187122695147991, 0.0013092353474348783, 0.04770655930042267, 0.011198504827916622, 0.22050754725933075, 0.13942614197731018, 0.00044186270679347217]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9333657622337341, 0.06663419306278229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32452353835105896, 0.5923718214035034, 0.0831046998500824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14159756898880005, 0.514380931854248, 0.281441330909729, 0.0625801533460617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2526226043701172, 0.058340635150671005, 0.10458876937627792, 0.44111600518226624, 0.14333193004131317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18051566183567047, 0.09828891605138779, 0.10873974114656448, 0.12262696772813797, 0.0999554917216301, 0.389873206615448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17192292213439941, 0.02332093007862568, 0.12332713603973389, 0.060764994472265244, 0.059717271476984024, 0.34759172797203064, 0.21335503458976746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0962703675031662, 0.04683610796928406, 0.028257345780730247, 0.0323924645781517, 0.05865047499537468, 0.1582932472229004, 0.309965044260025, 0.26933494210243225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09948239475488663, 0.06464176625013351, 0.028671851381659508, 0.07305676490068436, 0.02978716604411602, 0.13960029184818268, 0.20754703879356384, 0.2658021152019501, 0.0914105772972107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0563204400241375, 0.02988586761057377, 0.013419928960502148, 0.002407551510259509, 0.01324548665434122, 0.04564541578292847, 0.055225614458322525, 0.10027080029249191, 0.65799880027771, 0.025580089539289474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04266996681690216, 0.010426472872495651, 0.010652237571775913, 0.013446652330458164, 0.009353149682283401, 0.040159739553928375, 0.07105167210102081, 0.13737662136554718, 0.10423272103071213, 0.2173663079738617, 0.3432644307613373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029683874920010567, 0.0025616397615522146, 0.004407488275319338, 0.0342487096786499, 0.01423873845487833, 0.02800186350941658, 0.022288037464022636, 0.0710596889257431, 0.040262315422296524, 0.5543042421340942, 0.17333048582077026, 0.025612978264689445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04039590060710907, 0.008631564676761627, 0.005494224838912487, 0.0038641421124339104, 0.023363133892416954, 0.027206972241401672, 0.025677314028143883, 0.050485141575336456, 0.051056135445833206, 0.05041782557964325, 0.14164325594902039, 0.5115286707878113, 0.06023568660020828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028706423938274384, 0.004808459896594286, 0.004723663441836834, 0.005382598377764225, 0.003456050530076027, 0.014470165595412254, 0.024037370458245277, 0.041626233607530594, 0.03567297011613846, 0.07060731947422028, 0.10830995440483093, 0.05811617895960808, 0.20621220767498016, 0.3938705027103424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.053426481783390045, 0.011923293583095074, 0.015572247095406055, 0.002112323883920908, 0.005851037334650755, 0.022170905023813248, 0.03818466141819954, 0.027411548420786858, 0.05464285612106323, 0.049108296632766724, 0.12328370660543442, 0.05287177115678787, 0.07545655220746994, 0.37015315890312195, 0.09783114492893219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008346715942025185, 0.00027852662606164813, 0.0011786009417846799, 0.0021395485382527113, 0.002476172288879752, 0.002918292535468936, 0.004576897248625755, 0.003965593408793211, 0.004973020404577255, 0.011347766034305096, 0.01301405020058155, 0.005545963998883963, 0.020895594730973244, 0.03838542848825455, 0.8750316500663757, 0.004926194902509451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021700313314795494, 0.0026786664966493845, 0.002383930142968893, 0.0028156291227787733, 0.0015562332700937986, 0.006139401346445084, 0.00903982762247324, 0.013740862719714642, 0.01241221372038126, 0.024686506018042564, 0.0340690016746521, 0.01756146177649498, 0.060829512774944305, 0.12004056572914124, 0.1151680275797844, 0.1266368180513382, 0.42854106426239014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01968141458928585, 0.002866192953661084, 0.002752865431830287, 0.0023641991429030895, 0.0022205759305506945, 0.004776965826749802, 0.005015394650399685, 0.00702077429741621, 0.00660299975425005, 0.01582489348948002, 0.02177910879254341, 0.022375911474227905, 0.03905551880598068, 0.07342644780874252, 0.07227573543787003, 0.081036277115345, 0.255632221698761, 0.36529257893562317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.034438688308000565, 0.0024295083712786436, 0.002703877631574869, 0.0010108919814229012, 0.0028212438337504864, 0.009310656227171421, 0.007474055513739586, 0.01052639540284872, 0.019342603161931038, 0.006583380978554487, 0.030525246635079384, 0.008166545070707798, 0.0239456407725811, 0.08047981560230255, 0.044289324432611465, 0.04886510595679283, 0.2326633334159851, 0.3870973289012909, 0.047326426953077316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036976826377213, 0.006450964603573084, 0.0004921728977933526, 0.00030695952591486275, 0.00012400795822031796, 0.0010727369226515293, 0.0008858799119479954, 0.0013806350762024522, 0.0008200182928703725, 0.00027311910525895655, 0.0027830637991428375, 0.0352943055331707, 0.003561372170224786, 0.007148310542106628, 0.0016474073054268956, 0.01673164963722229, 0.019172819331288338, 0.022339249029755592, 0.8733667135238647, 0.0024509630165994167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013628778979182243, 0.001438442850485444, 0.0012188641121611, 0.0012915852712467313, 0.00061180186457932, 0.002140036318451166, 0.0027469585184007883, 0.0033360447268933058, 0.0030918731354177, 0.005988912656903267, 0.007237215992063284, 0.0035477415658533573, 0.012891949154436588, 0.022229144349694252, 0.02082422748208046, 0.026295311748981476, 0.0764816626906395, 0.16261444985866547, 0.12638655304908752, 0.10034430772066116, 0.40565410256385803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02143297903239727, 0.0007291637011803687, 0.0010889694094657898, 0.000855961290653795, 0.0010556625202298164, 0.0023542463313788176, 0.0018633330473676324, 0.0024869877379387617, 0.004011376295238733, 0.003645629156380892, 0.006636610720306635, 0.0024591670371592045, 0.008106634020805359, 0.019501397386193275, 0.013945501297712326, 0.016831588000059128, 0.06727860122919083, 0.10203740000724792, 0.07506179064512253, 0.037855006754398346, 0.34741583466529846, 0.26334622502326965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018374426290392876, 0.0016340140718966722, 0.00026486633578315377, 0.0006277088541537523, 0.000721289892680943, 0.002294712932780385, 0.001437578583136201, 0.002433568937703967, 0.0010225047590211034, 0.0021730982698500156, 0.005665964912623167, 0.000585707020945847, 0.004730309825390577, 0.015789613127708435, 0.009121062234044075, 0.006447880994528532, 0.049651894718408585, 0.07221103459596634, 0.04530423879623413, 0.022536233067512512, 0.23380528390407562, 0.28100937604904175, 0.2221575230360031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01601027324795723, 0.00041907679405994713, 0.001679316977970302, 0.002033163793385029, 0.0011126060271635652, 0.002304120222106576, 0.001641487586311996, 0.0020452288445085287, 0.0008826436242088675, 0.0035318138543516397, 0.004660746548324823, 0.0011461277026683092, 0.004025280475616455, 0.011729457415640354, 0.0069060008972883224, 0.005978974513709545, 0.03413613513112068, 0.05391989275813103, 0.0753692016005516, 0.0155441639944911, 0.15307292342185974, 0.21672505140304565, 0.23267340660095215, 0.15245291590690613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415491700172424, 0.001088098855689168, 0.0013027024688199162, 0.0012335632927715778, 0.0010325233452022076, 0.001360527123324573, 0.0011352722067385912, 0.0009713192703202367, 0.0017580221174284816, 0.00235499395057559, 0.0022677972447127104, 0.00261700339615345, 0.0032849626149982214, 0.005564448423683643, 0.007287739310413599, 0.006582655478268862, 0.016911108046770096, 0.023348158225417137, 0.033363744616508484, 0.012060855515301228, 0.08410532772541046, 0.10776971280574799, 0.12741316854953766, 0.2500956952571869, 0.28867506980895996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031117746606469154, 0.0015063052996993065, 0.0010839324677363038, 0.002421521581709385, 0.0013826880604028702, 0.0037937192246317863, 0.001633930136449635, 0.0031195185147225857, 0.001281262724660337, 0.0020685249473899603, 0.004760123789310455, 0.000875731639098376, 0.008592118509113789, 0.009353655390441418, 0.011993253603577614, 0.005962998606264591, 0.022028207778930664, 0.03411330282688141, 0.009586768224835396, 0.01368181873112917, 0.08417051285505295, 0.08917820453643799, 0.10806843638420105, 0.1556076556444168, 0.37236860394477844, 0.020249484106898308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014838483184576035, 0.0005757312173955142, 0.004743658006191254, 0.0004567732394207269, 0.0007412273553200066, 0.001499997335486114, 0.0008866077405400574, 0.0008452086476609111, 0.00010359243606217206, 0.0009065145277418196, 0.0018096768762916327, 0.060291096568107605, 0.0015377566451206803, 0.0033079423010349274, 0.0013713663211092353, 0.002082675229758024, 0.008643998764455318, 0.009088859893381596, 0.007760950364172459, 0.005808327812701464, 0.03386513516306877, 0.03987188637256622, 0.05374554172158241, 0.036947716027498245, 0.12259431928396225, 0.5718703866004944, 0.013804467394948006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018570011481642723, 0.0012143151834607124, 0.0012880479916930199, 0.001061256742104888, 0.0007490045391023159, 0.0010485616512596607, 0.0008687858935445547, 0.0005973857478238642, 0.001293826848268509, 0.0014042495749890804, 0.0011055085342377424, 0.0005003454862162471, 0.0020262603648006916, 0.0021463115699589252, 0.0028737892862409353, 0.002641368191689253, 0.005802982021123171, 0.008191343396902084, 0.008339074440300465, 0.005543301813304424, 0.026558704674243927, 0.03308917209506035, 0.032507386058568954, 0.09199851751327515, 0.10410475730895996, 0.16861772537231445, 0.20895437896251678, 0.26690375804901123, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01665443368256092, 0.0007248650072142482, 0.0008980660350061953, 0.0031616869382560253, 0.000552282901480794, 0.0016607235884293914, 0.0007486110553145409, 0.000965278537478298, 0.0003842799924314022, 0.0022577764466404915, 0.001554562826640904, 0.0007036998285911977, 0.0014688157243654132, 0.002799881622195244, 0.003013978013768792, 0.005369037855416536, 0.006552340462803841, 0.0087015675380826, 0.007138852030038834, 0.006516315974295139, 0.026185553520917892, 0.03929200768470764, 0.0315500870347023, 0.024343017488718033, 0.10670767724514008, 0.15159791707992554, 0.13674205541610718, 0.3201397657394409, 0.09161485731601715, 0.0, 0.0, 0.0, 0.0], [0.03722681477665901, 0.0007442726637236774, 0.0019180321833118796, 0.001429060590453446, 0.0025597321800887585, 0.003292827168479562, 0.0009007241460494697, 0.0015445082681253552, 0.00035572113119997084, 0.0004492724547162652, 0.002668810775503516, 0.001404664828442037, 0.0017281010514125228, 0.0045427302829921246, 0.0012941033346578479, 0.004677655175328255, 0.009138206951320171, 0.008992929011583328, 0.0053436546586453915, 0.0020318408496677876, 0.030930889770388603, 0.021215278655290604, 0.03639976307749748, 0.05679461359977722, 0.11195952445268631, 0.01145811378955841, 0.033532921224832535, 0.2658853828907013, 0.24695426225662231, 0.09262567013502121, 0.0, 0.0, 0.0], [0.04408875107765198, 0.001108295051380992, 0.0033875894732773304, 0.004853184800595045, 0.00286432565189898, 0.004500850103795528, 0.0014518090756610036, 0.002192496554926038, 0.0007902357610873878, 0.00067173718707636, 0.0035771543625742197, 0.0005131773068569601, 0.012861714698374271, 0.005116848740726709, 0.003014254616573453, 0.005887460894882679, 0.010453439317643642, 0.013818331994116306, 0.008691055700182915, 0.01122928224503994, 0.0314008966088295, 0.023181643337011337, 0.030444404110312462, 0.03520679473876953, 0.09999871999025345, 0.006090163718909025, 0.14714206755161285, 0.16393037140369415, 0.12749527394771576, 0.19357769191265106, 0.00045999124995432794, 0.0, 0.0], [0.037174042314291, 0.005006890743970871, 0.0016112308949232101, 0.002830145414918661, 0.0005118501139804721, 0.0027071216609328985, 0.002097028773277998, 0.00123287970200181, 0.000631089264061302, 0.0017632469534873962, 0.0017868775175884366, 0.00025283286231569946, 0.0010720753343775868, 0.0026448324788361788, 0.0015661552315577865, 0.003808405948802829, 0.005276743788272142, 0.006930260919034481, 0.01331080961972475, 0.0035816470626741648, 0.01830451190471649, 0.026684744283556938, 0.01997152715921402, 0.032155733555555344, 0.07432043552398682, 0.023922253400087357, 0.0876147523522377, 0.180075541138649, 0.027492599561810493, 0.05972246453166008, 0.19122695922851562, 0.16271227598190308, 0.0], [0.008116930723190308, 0.0008723045466467738, 0.00037072799750603735, 0.00047348550288006663, 0.0001783298939699307, 0.00039947027107700706, 0.00029511720640584826, 0.00018311945314053446, 0.00016714561206754297, 0.00023702502949163318, 0.0002533356018830091, 0.00012855012028012425, 0.00020213167590554804, 0.00039944855961948633, 0.0001651179773034528, 0.0004622866108547896, 0.0008780233329162002, 0.0011140464339405298, 0.002070876769721508, 0.001963673857972026, 0.0035278573632240295, 0.0044752187095582485, 0.004463488236069679, 0.007312532514333725, 0.014446237124502659, 0.035030465573072433, 0.020014138892292976, 0.04388580471277237, 0.019436774775385857, 0.11325738579034805, 0.07277626544237137, 0.1619681417942047, 0.4804745018482208]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473748207092285, 0.05262520909309387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8785883784294128, 0.055394671857357025, 0.06601690500974655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7270771265029907, 0.1370987445116043, 0.04866088181734085, 0.08716321736574173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46517470479011536, 0.1342930793762207, 0.1535816490650177, 0.17472541332244873, 0.0722251683473587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17035970091819763, 0.01184193603694439, 0.023650843650102615, 0.021745799109339714, 0.025856317952275276, 0.7465453743934631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14214573800563812, 0.04383271187543869, 0.05021180212497711, 0.045165032148361206, 0.05872129276394844, 0.5111534595489502, 0.14876998960971832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0847334936261177, 0.020369814708828926, 0.03746160492300987, 0.03195909783244133, 0.03419601544737816, 0.4350069463253021, 0.11894058436155319, 0.23733240365982056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3423079550266266, 0.03593634441494942, 0.07259216159582138, 0.10352758318185806, 0.08196531236171722, 0.07694562524557114, 0.14196321368217468, 0.09896712005138397, 0.045794595032930374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37114864587783813, 0.06278739869594574, 0.05806947126984596, 0.05566275492310524, 0.1312483847141266, 0.07535628229379654, 0.10726623982191086, 0.07924024015665054, 0.030107326805591583, 0.029113229364156723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06430105119943619, 0.0051691047847270966, 0.011012976989150047, 0.009054877795279026, 0.011748060584068298, 0.31885024905204773, 0.036849457770586014, 0.08319543302059174, 0.012068151496350765, 0.014676221646368504, 0.4330745041370392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2377791851758957, 0.038129985332489014, 0.019743356853723526, 0.0750802680850029, 0.14420801401138306, 0.06244922801852226, 0.07018379867076874, 0.06523606181144714, 0.04883221909403801, 0.034600332379341125, 0.06439770013093948, 0.13935981690883636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2901448607444763, 0.04085763543844223, 0.06965624541044235, 0.06467737257480621, 0.11515604704618454, 0.07279438525438309, 0.05406038090586662, 0.04095994681119919, 0.03646121919155121, 0.03709697350859642, 0.0811215415596962, 0.06249446049332619, 0.034518949687480927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.041916050016880035, 0.0033880695700645447, 0.007082356605678797, 0.005899202078580856, 0.0075861928053200245, 0.20389801263809204, 0.023296765983104706, 0.05173070356249809, 0.007816814817488194, 0.009731389582157135, 0.2776019871234894, 0.008386761881411076, 0.016172707080841064, 0.33549296855926514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1512935608625412, 0.04240791127085686, 0.04383380711078644, 0.09706763923168182, 0.14943549036979675, 0.04439878091216087, 0.06174503266811371, 0.04199514910578728, 0.018608786165714264, 0.03141247481107712, 0.05092647671699524, 0.06660281866788864, 0.0941622331738472, 0.05761294066905975, 0.04849696531891823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29958033561706543, 0.07432074844837189, 0.030061950907111168, 0.01673647202551365, 0.03856483846902847, 0.05106871575117111, 0.09408656507730484, 0.05606794357299805, 0.05458232760429382, 0.04522043466567993, 0.05638071522116661, 0.015378028154373169, 0.04082851484417915, 0.060846924781799316, 0.030811065807938576, 0.03546446934342384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03043997287750244, 0.0024933915119618177, 0.005298201460391283, 0.0042233895510435104, 0.005517447367310524, 0.14508461952209473, 0.016034146770834923, 0.03598647564649582, 0.005758052691817284, 0.007398172747343779, 0.1961348056793213, 0.006090886425226927, 0.01146512757986784, 0.23737993836402893, 0.008031774312257767, 0.005861479323357344, 0.276802122592926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015668921172618866, 0.0019133483292534947, 0.0067479307763278484, 0.005610874854028225, 0.006710357498377562, 0.10858529061079025, 0.013436982408165932, 0.030674776062369347, 0.008698036894202232, 0.005958769004791975, 0.15696418285369873, 0.006401263643056154, 0.014357196167111397, 0.192204549908638, 0.009938811883330345, 0.008154559880495071, 0.22861388325691223, 0.17936018109321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2751207649707794, 0.04635609686374664, 0.025782722979784012, 0.020371075719594955, 0.04519127681851387, 0.04741503670811653, 0.058008305728435516, 0.05449457839131355, 0.02185584232211113, 0.028674187138676643, 0.050547998398542404, 0.03578943386673927, 0.014343983493745327, 0.05505191534757614, 0.019970901310443878, 0.02507063001394272, 0.059836745262145996, 0.10591268539428711, 0.010205714032053947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12210460752248764, 0.02900637313723564, 0.027926085516810417, 0.030763661488890648, 0.06431963294744492, 0.05075865238904953, 0.05746712535619736, 0.03854453191161156, 0.02881445176899433, 0.036410342901945114, 0.055306967347860336, 0.02755570411682129, 0.05062386021018028, 0.06039686128497124, 0.03790904954075813, 0.034162577241659164, 0.06550319492816925, 0.08224614709615707, 0.0890314057469368, 0.01114883366972208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01992272399365902, 0.0015991271939128637, 0.0035362679045647383, 0.0027606089133769274, 0.003674752777442336, 0.091985784471035, 0.009868190623819828, 0.021762730553746223, 0.00367462495341897, 0.004800301976501942, 0.1232718676328659, 0.003948226571083069, 0.007727706339210272, 0.14901937544345856, 0.00509450351819396, 0.0038495417684316635, 0.17433802783489227, 0.1450376659631729, 0.0031391775701195, 0.0039015659131109715, 0.2170872688293457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025169124826788902, 0.002589145442470908, 0.007904473692178726, 0.0028181758243590593, 0.00831749476492405, 0.06284766644239426, 0.01609737239778042, 0.024833571165800095, 0.007658039219677448, 0.01131708174943924, 0.08451007306575775, 0.012135404162108898, 0.022048382088541985, 0.1001725122332573, 0.015103285200893879, 0.020152252167463303, 0.11906807869672775, 0.1414896845817566, 0.006576648447662592, 0.007074056658893824, 0.14850658178329468, 0.15361085534095764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08679646253585815, 0.01581868901848793, 0.009913154877722263, 0.005941123701632023, 0.011749119497835636, 0.04402251914143562, 0.04941156879067421, 0.04721160605549812, 0.022448519244790077, 0.02814418449997902, 0.05249372869729996, 0.01366489753127098, 0.038044534623622894, 0.05856488645076752, 0.016008734703063965, 0.028531739488244057, 0.06752396374940872, 0.10004056245088577, 0.026074500754475594, 0.01816527172923088, 0.08061446994543076, 0.14588378369808197, 0.03293200582265854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1220332682132721, 0.02679692767560482, 0.03471274673938751, 0.01660086400806904, 0.05098598822951317, 0.03362342715263367, 0.033762890845537186, 0.03289439156651497, 0.022763602435588837, 0.034695446491241455, 0.03710823133587837, 0.027503039687871933, 0.030508041381835938, 0.04070495069026947, 0.019409820437431335, 0.033388081938028336, 0.046037912368774414, 0.0814194306731224, 0.0257929228246212, 0.017713354900479317, 0.05326376482844353, 0.06955213844776154, 0.07340097427368164, 0.03532778471708298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012632702477276325, 0.003196730511263013, 0.008999623358249664, 0.0037871047388762236, 0.005590218584984541, 0.060187481343746185, 0.01017302367836237, 0.026063401252031326, 0.00828032661229372, 0.0059984405525028706, 0.08480246365070343, 0.007755734492093325, 0.014807665720582008, 0.10079342126846313, 0.011636026203632355, 0.007885096594691277, 0.12061365693807602, 0.1281987577676773, 0.006487110164016485, 0.0032305701170116663, 0.15047506988048553, 0.10557683557271957, 0.015480611473321915, 0.01902633160352707, 0.07832161337137222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11176053434610367, 0.018635563552379608, 0.05622369796037674, 0.04677280783653259, 0.03736496716737747, 0.022993411868810654, 0.03136526420712471, 0.026408886536955833, 0.043359216302633286, 0.056635573506355286, 0.021786419674754143, 0.02382214367389679, 0.030641673132777214, 0.023289266973733902, 0.05430493503808975, 0.06881178170442581, 0.024489399045705795, 0.047770895063877106, 0.03627176955342293, 0.022222531959414482, 0.026998940855264664, 0.021766118705272675, 0.03442491218447685, 0.028240282088518143, 0.058919213712215424, 0.024719828739762306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10639803111553192, 0.03710789978504181, 0.08273961395025253, 0.01785685494542122, 0.020950015634298325, 0.018305256962776184, 0.022620100528001785, 0.01819227822124958, 0.021851178258657455, 0.012518538162112236, 0.019214101135730743, 0.030340097844600677, 0.07187619060277939, 0.02078801766037941, 0.03963522985577583, 0.06151585653424263, 0.023179300129413605, 0.0439804270863533, 0.04619224742054939, 0.02066798321902752, 0.027080880478024483, 0.043865546584129333, 0.03276737406849861, 0.04369065538048744, 0.05080845579504967, 0.04029493406414986, 0.025563016533851624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015084543265402317, 0.0038223827723413706, 0.005877263378351927, 0.0049718520604074, 0.005370153579860926, 0.052236463874578476, 0.016127683222293854, 0.031829919666051865, 0.008211133070290089, 0.011473821476101875, 0.0670468732714653, 0.01052838284522295, 0.010598230175673962, 0.07938900589942932, 0.007211722433567047, 0.006271460559219122, 0.09142370522022247, 0.10866516083478928, 0.003973819315433502, 0.005621668417006731, 0.10983321070671082, 0.09237752109766006, 0.022960500791668892, 0.019314924255013466, 0.08864139020442963, 0.018464695662260056, 0.011022255755960941, 0.09165029972791672, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0985412448644638, 0.03967058286070824, 0.050521429628133774, 0.047943923622369766, 0.01953187584877014, 0.015683406963944435, 0.025074731558561325, 0.014997915364801884, 0.027723433449864388, 0.016418183222413063, 0.016389023512601852, 0.026316558942198753, 0.034359272569417953, 0.01775798201560974, 0.023362670093774796, 0.03763511776924133, 0.01940559782087803, 0.034421682357788086, 0.049022991210222244, 0.030190547928214073, 0.022159064188599586, 0.03754067048430443, 0.038793157786130905, 0.04032415524125099, 0.04231265187263489, 0.06829200685024261, 0.025314142927527428, 0.043300725519657135, 0.03699523210525513, 0.0, 0.0, 0.0, 0.0], [0.10688817501068115, 0.036595746874809265, 0.005083095747977495, 0.010160420089960098, 0.013297361321747303, 0.041752055287361145, 0.026246795430779457, 0.03012855164706707, 0.013482409529387951, 0.018223192542791367, 0.0458262637257576, 0.025558775290846825, 0.015618819743394852, 0.05039897561073303, 0.011657019145786762, 0.01165912114083767, 0.05515516176819801, 0.05091661214828491, 0.019206790253520012, 0.013998426496982574, 0.06383468955755234, 0.029088884592056274, 0.0167104359716177, 0.02609526552259922, 0.05484984815120697, 0.03806673362851143, 0.03896070644259453, 0.05375230684876442, 0.02367916889488697, 0.05310812592506409, 0.0, 0.0, 0.0], [0.10871610045433044, 0.06286413967609406, 0.023045089095830917, 0.012493218295276165, 0.009688262827694416, 0.023720758035779, 0.025617318227887154, 0.028282880783081055, 0.01952310837805271, 0.015187141485512257, 0.024615760892629623, 0.01885579526424408, 0.01307191327214241, 0.025697477161884308, 0.010639780201017857, 0.0073364293202757835, 0.028488250449299812, 0.040875110775232315, 0.023693948984146118, 0.028460824862122536, 0.031781189143657684, 0.033992111682891846, 0.01690450683236122, 0.04699757695198059, 0.05480917915701866, 0.06048166751861572, 0.02113783173263073, 0.05147768557071686, 0.015304342843592167, 0.07868862897157669, 0.03755196928977966, 0.0, 0.0], [0.16510626673698425, 0.01330734882503748, 0.022820334881544113, 0.032224949449300766, 0.028327804058790207, 0.011912107467651367, 0.021759115159511566, 0.012591331265866756, 0.025371311232447624, 0.015923485159873962, 0.011745055206120014, 0.021340150386095047, 0.02265850454568863, 0.012097018770873547, 0.05877393111586571, 0.04114291071891785, 0.012866124510765076, 0.021896693855524063, 0.027385754510760307, 0.015412721782922745, 0.014822262339293957, 0.013198778964579105, 0.029060140252113342, 0.04031304642558098, 0.02303694374859333, 0.05035790055990219, 0.046500734984874725, 0.03221072256565094, 0.04574139416217804, 0.011448165401816368, 0.051484815776348114, 0.047162190079689026, 0.0], [0.01986272819340229, 0.0006941382307559252, 0.0017670636298134923, 0.0019038196187466383, 0.002311579417437315, 0.05924391373991966, 0.0051649510860443115, 0.008714544586837292, 0.002490669023245573, 0.0030579620506614447, 0.07585161924362183, 0.0023905520793050528, 0.0031773524824529886, 0.08945116400718689, 0.003065296681597829, 0.00162091467063874, 0.10312024503946304, 0.06259163469076157, 0.002058295998722315, 0.00223221885971725, 0.12742047011852264, 0.024703852832317352, 0.0035101929679512978, 0.004994178656488657, 0.02831711620092392, 0.005874200724065304, 0.0062153334729373455, 0.036865606904029846, 0.005438112188130617, 0.004061865154653788, 0.004735518712550402, 0.004534381441771984, 0.292558491230011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9726406335830688, 0.02735934779047966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8850566744804382, 0.08160645514726639, 0.033336855471134186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7844979166984558, 0.09045999497175217, 0.107209712266922, 0.017832357436418533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6679065227508545, 0.10135097056627274, 0.10997920483350754, 0.06990877538919449, 0.050854504108428955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.586279034614563, 0.06960930675268173, 0.06798024475574493, 0.06058965623378754, 0.08339772373437881, 0.13214407861232758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5015711188316345, 0.06227879598736763, 0.07209987193346024, 0.05590920150279999, 0.0814688578248024, 0.12033162266016006, 0.10634063929319382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4001609683036804, 0.05525398999452591, 0.0634767934679985, 0.054137878119945526, 0.07119624316692352, 0.11230525374412537, 0.12489722669124603, 0.11857161670923233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4018532633781433, 0.08579414337873459, 0.05644882470369339, 0.0718112513422966, 0.08318915218114853, 0.07845643907785416, 0.09191885590553284, 0.07768876850605011, 0.05283927544951439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38271600008010864, 0.07976950705051422, 0.062077511101961136, 0.06360232830047607, 0.08211028575897217, 0.07804947346448898, 0.08597435057163239, 0.07506490498781204, 0.06327839940786362, 0.027357224375009537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34041672945022583, 0.04535195603966713, 0.046589113771915436, 0.04039172828197479, 0.0548904724419117, 0.08179007470607758, 0.08906514942646027, 0.09645892679691315, 0.05564970150589943, 0.06398673355579376, 0.08540943264961243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31186187267303467, 0.09539999067783356, 0.07292015105485916, 0.0697687417268753, 0.07777831703424454, 0.0673503428697586, 0.06161404773592949, 0.05481071397662163, 0.052520137280225754, 0.05022517219185829, 0.07299348711967468, 0.01275695115327835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36652839183807373, 0.06308671087026596, 0.039478451013565063, 0.04609527811408043, 0.05740760266780853, 0.06348332017660141, 0.0523846335709095, 0.055016208440065384, 0.04584016278386116, 0.06228690594434738, 0.06589913368225098, 0.05806361883878708, 0.024429528042674065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2856443226337433, 0.03804026171565056, 0.03942388668656349, 0.03423863649368286, 0.046394020318984985, 0.06771664321422577, 0.07328074425458908, 0.07855430990457535, 0.04789664223790169, 0.0559365376830101, 0.07124949991703033, 0.03568926081061363, 0.049560438841581345, 0.07637479901313782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2977541983127594, 0.05259548872709274, 0.04347939044237137, 0.058458633720874786, 0.04568732529878616, 0.05259402468800545, 0.0445619635283947, 0.0459747239947319, 0.06316150724887848, 0.07768755406141281, 0.05499148741364479, 0.034664712846279144, 0.05020102858543396, 0.05886140838265419, 0.019326550886034966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28853145241737366, 0.046169087290763855, 0.028233051300048828, 0.03824241831898689, 0.04330623149871826, 0.051749154925346375, 0.04318273067474365, 0.04393119737505913, 0.056163422763347626, 0.0677381381392479, 0.05490179732441902, 0.08139310032129288, 0.04325692355632782, 0.0590481199324131, 0.03989902138710022, 0.014254058711230755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23721367120742798, 0.03161582350730896, 0.03324564918875694, 0.02923194319009781, 0.038618169724941254, 0.05549165979027748, 0.05966496095061302, 0.06321782618761063, 0.04073699563741684, 0.04752673953771591, 0.058378253132104874, 0.030399689450860023, 0.042871586978435516, 0.06284616887569427, 0.05321291461586952, 0.047368962317705154, 0.06835901737213135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2098696082830429, 0.02729126065969467, 0.03115660510957241, 0.02661500684916973, 0.03165115788578987, 0.052732259035110474, 0.0527450367808342, 0.056359026581048965, 0.04076547548174858, 0.04278234392404556, 0.05619128420948982, 0.030678274109959602, 0.043989624828100204, 0.06091475486755371, 0.050136998295784, 0.041573166847229004, 0.06652863323688507, 0.07801952958106995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2385382503271103, 0.044145818799734116, 0.04643504321575165, 0.0345127247273922, 0.03572181239724159, 0.04369327798485756, 0.043049730360507965, 0.034988246858119965, 0.043718043714761734, 0.0395219624042511, 0.044578537344932556, 0.024599451571702957, 0.0625118762254715, 0.04753483459353447, 0.04375608637928963, 0.049959294497966766, 0.05090809613466263, 0.0526624359190464, 0.019164476543664932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17729149758815765, 0.042214617133140564, 0.030818702653050423, 0.030886121094226837, 0.03386852145195007, 0.045211855322122574, 0.04290100932121277, 0.03221559524536133, 0.04018865153193474, 0.04926897957921028, 0.0480162538588047, 0.03814245015382767, 0.051265161484479904, 0.05206841230392456, 0.04744114354252815, 0.03924531862139702, 0.056304775178432465, 0.054629381746053696, 0.05991861969232559, 0.028102951124310493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19048276543617249, 0.025203479453921318, 0.02678745426237583, 0.02367268316447735, 0.031104059889912605, 0.04345342516899109, 0.04649331420660019, 0.048206448554992676, 0.03323278948664665, 0.03892750293016434, 0.045491497963666916, 0.02444274164736271, 0.03570158779621124, 0.04907766729593277, 0.043035656213760376, 0.039055634289979935, 0.053717467933893204, 0.06658954173326492, 0.043208252638578415, 0.03176471218466759, 0.06035124510526657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1497536599636078, 0.02347457781434059, 0.02550838701426983, 0.028942441567778587, 0.035171616822481155, 0.0388018861413002, 0.04594280570745468, 0.03962727263569832, 0.037087779492139816, 0.03872300684452057, 0.04190722480416298, 0.021688057109713554, 0.04328257590532303, 0.04592541232705116, 0.038939524441957474, 0.040076106786727905, 0.050600212067365646, 0.060830481350421906, 0.04372159764170647, 0.030235230922698975, 0.057286132127046585, 0.062474027276039124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1751340627670288, 0.027519280090928078, 0.0295140128582716, 0.02071533165872097, 0.026873530820012093, 0.03454612195491791, 0.03853078931570053, 0.033037807792425156, 0.041815564036369324, 0.040100302547216415, 0.03696897253394127, 0.030468925833702087, 0.039953965693712234, 0.04023701697587967, 0.044826194643974304, 0.03708263486623764, 0.04420146346092224, 0.04931036755442619, 0.04125743359327316, 0.02861069329082966, 0.04997343569993973, 0.05269286409020424, 0.03662918135523796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13285990059375763, 0.040708042681217194, 0.04111677408218384, 0.03484427556395531, 0.04087606444954872, 0.027567218989133835, 0.028293676674365997, 0.022520435974001884, 0.03875419497489929, 0.04037802666425705, 0.0290894266217947, 0.029609210789203644, 0.056701187044382095, 0.031181855127215385, 0.037661176174879074, 0.05688635632395744, 0.03396708518266678, 0.03781304135918617, 0.04951411485671997, 0.03194558247923851, 0.03759903833270073, 0.04326638579368591, 0.04305671527981758, 0.03379024937748909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14709363877773285, 0.01821870729327202, 0.022143611684441566, 0.021621394902467728, 0.02707292139530182, 0.033854179084300995, 0.03787612169981003, 0.03801963850855827, 0.027932513505220413, 0.030901825055480003, 0.03606925904750824, 0.019023139029741287, 0.0346580371260643, 0.039169859141111374, 0.0337555892765522, 0.02613660879433155, 0.042978327721357346, 0.05313740670681, 0.03463508188724518, 0.02014029584825039, 0.04878360405564308, 0.04990803450345993, 0.046243924647569656, 0.047156691551208496, 0.06346960365772247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17602789402008057, 0.014882143586874008, 0.026751168072223663, 0.024088069796562195, 0.035667534917593, 0.027094291523098946, 0.024984251707792282, 0.02147187478840351, 0.02635936625301838, 0.02384510450065136, 0.027567006647586823, 0.01686953939497471, 0.07777434587478638, 0.029109211638569832, 0.04799696430563927, 0.02900250069797039, 0.03132335841655731, 0.036155976355075836, 0.039595600217580795, 0.017008021473884583, 0.03483906388282776, 0.03443719819188118, 0.041492193937301636, 0.09124377369880676, 0.04052295908331871, 0.0038906042464077473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18501748144626617, 0.027786999940872192, 0.02509763464331627, 0.027019010856747627, 0.029199233278632164, 0.0303370151668787, 0.03222178295254707, 0.023015083745121956, 0.026792865246534348, 0.022793833166360855, 0.030674872919917107, 0.021220846101641655, 0.053888097405433655, 0.03259299322962761, 0.030737649649381638, 0.025725232437253, 0.034866053611040115, 0.037935808300971985, 0.02867201343178749, 0.026148973032832146, 0.03875335305929184, 0.041795048862695694, 0.03863157704472542, 0.05337154492735863, 0.039820704609155655, 0.02571162022650242, 0.010172730311751366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1244632825255394, 0.01676890254020691, 0.02010509930551052, 0.019267037510871887, 0.024457843974232674, 0.030203362926840782, 0.03127392753958702, 0.032546065747737885, 0.023186009377241135, 0.02350839227437973, 0.03173322230577469, 0.0170805174857378, 0.029082052409648895, 0.034282147884368896, 0.035791292786598206, 0.025820555165410042, 0.03753117471933365, 0.04618244990706444, 0.02950001135468483, 0.0179138146340847, 0.04274730756878853, 0.04243471473455429, 0.039002396166324615, 0.04141837731003761, 0.0594949834048748, 0.03595734387636185, 0.030984865501523018, 0.05726282671093941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14491020143032074, 0.02584398351609707, 0.031176967546343803, 0.019462747499346733, 0.012575741857290268, 0.02527458965778351, 0.02202068828046322, 0.021267293021082878, 0.03165540099143982, 0.02766416035592556, 0.026251599192619324, 0.022091036662459373, 0.03851795941591263, 0.02826686017215252, 0.028877614066004753, 0.036865342408418655, 0.030699966475367546, 0.03204502910375595, 0.034116294234991074, 0.02035541832447052, 0.03446314483880997, 0.03542865812778473, 0.030728407204151154, 0.04441896826028824, 0.03793593496084213, 0.057348690927028656, 0.038896989077329636, 0.04111207649111748, 0.01972820796072483, 0.0, 0.0, 0.0, 0.0], [0.13168425858020782, 0.02546011097729206, 0.02796240895986557, 0.0241098515689373, 0.016868827864527702, 0.03140677511692047, 0.02324734814465046, 0.022071702405810356, 0.027362484484910965, 0.02637045457959175, 0.03204537555575371, 0.028775818645954132, 0.04614204540848732, 0.03455977141857147, 0.03132107853889465, 0.02943771705031395, 0.03749069944024086, 0.035974208265542984, 0.0306710172444582, 0.026778314262628555, 0.041662365198135376, 0.032743990421295166, 0.030348775908350945, 0.03265197575092316, 0.03805649280548096, 0.03457561507821083, 0.022936128079891205, 0.036903250962495804, 0.025966178625822067, 0.01441489439457655, 0.0, 0.0, 0.0], [0.16563698649406433, 0.02280925028026104, 0.029107756912708282, 0.024944668635725975, 0.024352887645363808, 0.025031818076968193, 0.018486658111214638, 0.018573682755231857, 0.028443647548556328, 0.02919989824295044, 0.025318240746855736, 0.0322050042450428, 0.025753293186426163, 0.026890497654676437, 0.03127394616603851, 0.0330515019595623, 0.028835486620664597, 0.029910419136285782, 0.027558814734220505, 0.02462468296289444, 0.0320536307990551, 0.026493754237890244, 0.021709619089961052, 0.031640153378248215, 0.037074752151966095, 0.047994695603847504, 0.02793213538825512, 0.0347561240196228, 0.03804946690797806, 0.021535685285925865, 0.008750846609473228, 0.0, 0.0], [0.1679421216249466, 0.025983473286032677, 0.03222334384918213, 0.019469385966658592, 0.0237352903932333, 0.023115724325180054, 0.019973622635006905, 0.01655023731291294, 0.029796775430440903, 0.028494661673903465, 0.02310885675251484, 0.022087078541517258, 0.04216557741165161, 0.024390168488025665, 0.020749151706695557, 0.038735851645469666, 0.026269832625985146, 0.02728910744190216, 0.01961737498641014, 0.020242858678102493, 0.029203210026025772, 0.030413368716835976, 0.025762612000107765, 0.04084980860352516, 0.0333266407251358, 0.021795308217406273, 0.02631053701043129, 0.0310134869068861, 0.03689263015985489, 0.019377175718545914, 0.04355606064200401, 0.009558653458952904, 0.0], [0.11396825313568115, 0.0177528727799654, 0.016061948612332344, 0.015585058368742466, 0.01839613914489746, 0.02436707355082035, 0.02605387754738331, 0.023999108001589775, 0.021919477730989456, 0.026251090690493584, 0.024730542674660683, 0.01532302051782608, 0.02561456710100174, 0.026337873190641403, 0.024982869625091553, 0.02464260347187519, 0.028590325266122818, 0.032951485365629196, 0.027568642050027847, 0.01848755031824112, 0.03220852464437485, 0.031914710998535156, 0.03630726411938667, 0.034154027700424194, 0.03678559511899948, 0.03297771140933037, 0.026278894394636154, 0.03809887915849686, 0.029801951721310616, 0.018183251842856407, 0.036320675164461136, 0.03568094223737717, 0.057703107595443726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8058414459228516, 0.19415856897830963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6373866200447083, 0.09672050178050995, 0.2658928334712982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5870267748832703, 0.09922722727060318, 0.07913827151060104, 0.2346077412366867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4194740355014801, 0.06312595307826996, 0.08123064041137695, 0.08381499350070953, 0.35235440731048584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.530853271484375, 0.0959073081612587, 0.07779336720705032, 0.06661548465490341, 0.07293294370174408, 0.15589764714241028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3850307762622833, 0.0747809186577797, 0.06978145241737366, 0.047606535255908966, 0.05144914612174034, 0.08776704221963882, 0.2835841476917267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2962956726551056, 0.05328269675374031, 0.06944748014211655, 0.040975481271743774, 0.06660831719636917, 0.1021856963634491, 0.10869501531124115, 0.26250964403152466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30475008487701416, 0.06337984651327133, 0.057534221559762955, 0.04057719185948372, 0.07300137728452682, 0.07375827431678772, 0.07239886373281479, 0.05693604424595833, 0.25766411423683167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29880768060684204, 0.055528249591588974, 0.05443596839904785, 0.052853021770715714, 0.06568749248981476, 0.07554222643375397, 0.06968102604150772, 0.054113879799842834, 0.09120786935091019, 0.18214258551597595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2693301737308502, 0.06352430582046509, 0.059521205723285675, 0.05242469906806946, 0.060521580278873444, 0.12185832113027573, 0.07608653604984283, 0.09753072261810303, 0.042326074093580246, 0.050583261996507645, 0.10629310458898544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22074301540851593, 0.06960076093673706, 0.04872344806790352, 0.06675714254379272, 0.06954210251569748, 0.06483786553144455, 0.046523742377758026, 0.0393008328974247, 0.018016085028648376, 0.0358063168823719, 0.05302285775542259, 0.2671258747577667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15080071985721588, 0.04732475057244301, 0.12551112473011017, 0.062400829046964645, 0.05354630947113037, 0.055783942341804504, 0.045426107943058014, 0.03888600319623947, 0.03019980527460575, 0.033370550721883774, 0.04645954817533493, 0.023437920957803726, 0.2868523895740509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2044883370399475, 0.049720507115125656, 0.04838545247912407, 0.04385359212756157, 0.05115719884634018, 0.1007489338517189, 0.06420683115720749, 0.08302561193704605, 0.03880453109741211, 0.047957733273506165, 0.09582381695508957, 0.03239700570702553, 0.044411029666662216, 0.09501936286687851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16236743330955505, 0.028519175946712494, 0.047843098640441895, 0.04135480895638466, 0.040284886956214905, 0.052005358040332794, 0.04226505756378174, 0.038211677223443985, 0.05986882746219635, 0.06849396973848343, 0.04734281077980995, 0.019715163856744766, 0.06202229857444763, 0.04572192579507828, 0.24398350715637207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1312893033027649, 0.03962809219956398, 0.05951938405632973, 0.039663221687078476, 0.04406356066465378, 0.04348495230078697, 0.03726546838879585, 0.03240035101771355, 0.037205737084150314, 0.06481602042913437, 0.040474534034729004, 0.025914235040545464, 0.06507600098848343, 0.03922511264681816, 0.07744196802377701, 0.22253206372261047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1581333875656128, 0.03911251947283745, 0.038564957678318024, 0.03587968647480011, 0.041877955198287964, 0.08161000907421112, 0.05245806276798248, 0.0681268572807312, 0.03444807231426239, 0.04342750832438469, 0.08275996893644333, 0.029333392158150673, 0.04157378897070885, 0.08478686213493347, 0.04881599172949791, 0.032352838665246964, 0.08673813194036484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13890594244003296, 0.03169633448123932, 0.03251554071903229, 0.03538899123668671, 0.038000330328941345, 0.06974425911903381, 0.05942453071475029, 0.06768239289522171, 0.027843808755278587, 0.03905466943979263, 0.07273104786872864, 0.030109865590929985, 0.041630931198596954, 0.07565010339021683, 0.040188323706388474, 0.027483617886900902, 0.0779590830206871, 0.09399020671844482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09691289812326431, 0.03068731538951397, 0.03081795573234558, 0.04473433271050453, 0.04171941801905632, 0.03603677451610565, 0.04101703688502312, 0.03210475668311119, 0.043440643697977066, 0.04885552451014519, 0.03457902371883392, 0.01602509804069996, 0.04994167014956474, 0.0346352718770504, 0.06065686047077179, 0.034977879375219345, 0.034543439745903015, 0.03782794997096062, 0.25048622488975525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1205921545624733, 0.04121065139770508, 0.05098516121506691, 0.052891504019498825, 0.02886129915714264, 0.0470619834959507, 0.02921283431351185, 0.03817001357674599, 0.021046483889222145, 0.029787814244627953, 0.04406720772385597, 0.02650335058569908, 0.04127003625035286, 0.044307366013526917, 0.030801555141806602, 0.040649015456438065, 0.044745106250047684, 0.042122457176446915, 0.02844228409230709, 0.1972716599702835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11388306319713593, 0.028255397453904152, 0.028351284563541412, 0.02695867046713829, 0.031310856342315674, 0.05977548286318779, 0.0391821451485157, 0.050720393657684326, 0.02768402174115181, 0.03556423261761665, 0.06452133506536484, 0.024267083033919334, 0.03616494685411453, 0.06838169693946838, 0.04139300435781479, 0.029094640165567398, 0.0723005011677742, 0.07349380850791931, 0.03700020909309387, 0.0352863073348999, 0.07641096413135529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0845385268330574, 0.017416618764400482, 0.018949130550026894, 0.016560642048716545, 0.022296136245131493, 0.04174061119556427, 0.05894864350557327, 0.03893361985683441, 0.03021465241909027, 0.034642335027456284, 0.048319004476070404, 0.01635843887925148, 0.02567455545067787, 0.053096745163202286, 0.02054652012884617, 0.02046983316540718, 0.057046402245759964, 0.06604910641908646, 0.037746455520391464, 0.02141387388110161, 0.061299312859773636, 0.20773892104625702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1124844029545784, 0.024394849315285683, 0.024523140862584114, 0.02748955599963665, 0.026104673743247986, 0.037315063178539276, 0.06748528778553009, 0.03890376165509224, 0.01798143796622753, 0.028454391285777092, 0.037565309554338455, 0.01832607388496399, 0.020088661462068558, 0.03865170478820801, 0.023285649716854095, 0.02422661893069744, 0.03960611671209335, 0.04833188280463219, 0.04500092566013336, 0.017362141981720924, 0.04009140282869339, 0.0520828478038311, 0.19024406373500824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08183359354734421, 0.01982845552265644, 0.0268733948469162, 0.029252564534544945, 0.02518443949520588, 0.03192773461341858, 0.029049795120954514, 0.024972515180706978, 0.03350626304745674, 0.040074292570352554, 0.033517319709062576, 0.016036001965403557, 0.03204454854130745, 0.03448064252734184, 0.02851710096001625, 0.03532731905579567, 0.03583228588104248, 0.040583960711956024, 0.029941115528345108, 0.02109791710972786, 0.03671329468488693, 0.03921257704496384, 0.03543240949511528, 0.23876051604747772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1014568880200386, 0.014237050898373127, 0.01698417030274868, 0.018636560067534447, 0.028536254540085793, 0.036538016051054, 0.029570505023002625, 0.041983187198638916, 0.014166050590574741, 0.030081404373049736, 0.04016640782356262, 0.020075039938092232, 0.030370131134986877, 0.043534424155950546, 0.03039301373064518, 0.02071734517812729, 0.046771105378866196, 0.05495104566216469, 0.028809182345867157, 0.02004370093345642, 0.05092544108629227, 0.040844663977622986, 0.041858017444610596, 0.038489799946546555, 0.15986062586307526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07937928289175034, 0.02067432925105095, 0.020799750462174416, 0.027988238260149956, 0.0456547737121582, 0.02656259760260582, 0.02539670467376709, 0.021243248134851456, 0.01776380091905594, 0.025200635194778442, 0.02757645957171917, 0.03060709498822689, 0.0343799963593483, 0.028568323701620102, 0.022726938128471375, 0.016051946207880974, 0.029712745919823647, 0.03276180475950241, 0.025702396407723427, 0.012878889217972755, 0.03062613122165203, 0.020369648933410645, 0.03741389885544777, 0.02785036899149418, 0.035718511790037155, 0.27639150619506836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09605434536933899, 0.023092899471521378, 0.02419964410364628, 0.02497413195669651, 0.03682965412735939, 0.030014393851161003, 0.02106921374797821, 0.018117519095540047, 0.022569263353943825, 0.028343219310045242, 0.03050512820482254, 0.0217076875269413, 0.028211776167154312, 0.03163941949605942, 0.039166104048490524, 0.03627365082502365, 0.03311570733785629, 0.03514396399259567, 0.025745239108800888, 0.015889009460806847, 0.034675464034080505, 0.026770083233714104, 0.027143444865942, 0.0404508039355278, 0.037603843957185745, 0.03232336416840553, 0.17837101221084595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07476935535669327, 0.011021514423191547, 0.010706552304327488, 0.015325448475778103, 0.01990356296300888, 0.03285866975784302, 0.02193605527281761, 0.029454151168465614, 0.016421502456068993, 0.022476570680737495, 0.03722343593835831, 0.01758023537695408, 0.021954135969281197, 0.04046212509274483, 0.031415414065122604, 0.010417778044939041, 0.04429738596081734, 0.05118126422166824, 0.02956554852426052, 0.015394329093396664, 0.0490642674267292, 0.03202192485332489, 0.030905108898878098, 0.04132052883505821, 0.06578274816274643, 0.0397840291261673, 0.020499691367149353, 0.1662566214799881, 0.0, 0.0, 0.0, 0.0, 0.0], [0.051242027431726456, 0.011390028521418571, 0.020265799015760422, 0.02452964335680008, 0.1273244023323059, 0.02008390799164772, 0.01769273541867733, 0.020381977781653404, 0.01854860968887806, 0.023206060752272606, 0.02102605812251568, 0.020521242171525955, 0.025210728868842125, 0.021994248032569885, 0.017190467566251755, 0.020805906504392624, 0.023035308346152306, 0.026458049193024635, 0.03108612820506096, 0.011454472318291664, 0.024357983842492104, 0.022524937987327576, 0.02460077963769436, 0.024588007479906082, 0.028380827978253365, 0.04660610482096672, 0.0436270646750927, 0.020300468429923058, 0.2115660011768341, 0.0, 0.0, 0.0, 0.0], [0.07929296046495438, 0.023537397384643555, 0.022847285494208336, 0.01993604004383087, 0.015462889336049557, 0.025110291317105293, 0.021429046988487244, 0.015073489397764206, 0.009924097917973995, 0.015724750235676765, 0.027188710868358612, 0.02074727974832058, 0.03497636318206787, 0.02910234034061432, 0.021219026297330856, 0.018147621303796768, 0.031058205291628838, 0.033809494227170944, 0.020137567073106766, 0.01232312060892582, 0.0336926244199276, 0.024336133152246475, 0.03108452633023262, 0.033777009695768356, 0.04355442151427269, 0.03296354040503502, 0.03314929082989693, 0.025364909321069717, 0.022163690999150276, 0.22286593914031982, 0.0, 0.0, 0.0], [0.10059653222560883, 0.03096376173198223, 0.02557850070297718, 0.02022406831383705, 0.027132980525493622, 0.029490763321518898, 0.04074482247233391, 0.021403614431619644, 0.01639261096715927, 0.022520696744322777, 0.02755517140030861, 0.013599208556115627, 0.027306709438562393, 0.02780657820403576, 0.011214186437427998, 0.023586541414260864, 0.028399184346199036, 0.03066891059279442, 0.021664202213287354, 0.017032314091920853, 0.029051588848233223, 0.02654992789030075, 0.03297554329037666, 0.026790326461195946, 0.032060641795396805, 0.027298329398036003, 0.017307184636592865, 0.018768828362226486, 0.028226526454091072, 0.017085116356611252, 0.18000461161136627, 0.0, 0.0], [0.08361607044935226, 0.01658189482986927, 0.015823302790522575, 0.022005166858434677, 0.024062559008598328, 0.021028297021985054, 0.022811293601989746, 0.014412387274205685, 0.01557209249585867, 0.015104830265045166, 0.020917734131217003, 0.021798165515065193, 0.02598598785698414, 0.022013209760189056, 0.022025059908628464, 0.018091218546032906, 0.02311510592699051, 0.025451799854636192, 0.02594352327287197, 0.011241883039474487, 0.024466173723340034, 0.022869890555739403, 0.031613439321517944, 0.029542673379182816, 0.02381790801882744, 0.029349016025662422, 0.025922643020749092, 0.017268182709813118, 0.031844597309827805, 0.012037740088999271, 0.027524925768375397, 0.2561413049697876, 0.0], [0.05258439481258392, 0.012508383952081203, 0.01273767277598381, 0.012144193053245544, 0.014467823319137096, 0.024812445044517517, 0.017109140753746033, 0.02516256831586361, 0.016298970207571983, 0.015160084702074528, 0.029820043593645096, 0.014290270395576954, 0.02409478835761547, 0.03374277427792549, 0.02163226157426834, 0.018924100324511528, 0.03819216787815094, 0.04115182161331177, 0.024165773764252663, 0.02063564583659172, 0.0441853329539299, 0.037937089800834656, 0.02963634766638279, 0.03152840957045555, 0.04542307183146477, 0.03596360608935356, 0.030482539907097816, 0.04609917104244232, 0.03206765279173851, 0.01766294427216053, 0.03169601410627365, 0.044629111886024475, 0.10305343568325043]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707714438438416, 0.22922857105731964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813623547554016, 0.10978527367115021, 0.10885230451822281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5350388884544373, 0.11194944381713867, 0.15013688802719116, 0.2028747797012329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4180358350276947, 0.1603638082742691, 0.10740305483341217, 0.10625775903463364, 0.2079394906759262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4349866509437561, 0.09579858183860779, 0.08251798152923584, 0.10028502345085144, 0.15332910418510437, 0.13308264315128326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44621357321739197, 0.05624213442206383, 0.05040299892425537, 0.0708429366350174, 0.09360905736684799, 0.11472618579864502, 0.16796311736106873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3609195053577423, 0.07294465601444244, 0.05191004276275635, 0.07159050554037094, 0.09321670234203339, 0.09543662518262863, 0.14539922773838043, 0.1085827648639679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3171406686306, 0.07683128118515015, 0.05552283674478531, 0.06445366144180298, 0.08586593717336655, 0.10643252730369568, 0.1452113538980484, 0.09439335763454437, 0.05414833128452301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19288600981235504, 0.11343876272439957, 0.045305073261260986, 0.08361203968524933, 0.05763271823525429, 0.11914195120334625, 0.11441226303577423, 0.1236451268196106, 0.07640954852104187, 0.07351642102003098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25174087285995483, 0.06019413471221924, 0.0493021197617054, 0.0592232383787632, 0.08453337848186493, 0.07307680696249008, 0.12308555096387863, 0.08293970674276352, 0.06380271911621094, 0.07185836136341095, 0.08024314045906067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24793608486652374, 0.04855770990252495, 0.061716966331005096, 0.06616782397031784, 0.0878860279917717, 0.059203822165727615, 0.09128592908382416, 0.06866813451051712, 0.060628682374954224, 0.08399354666471481, 0.06569419056177139, 0.05826116353273392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15039604902267456, 0.07072300463914871, 0.0361880324780941, 0.03812884911894798, 0.054965790361166, 0.09552796930074692, 0.1278020292520523, 0.09101752936840057, 0.04133947193622589, 0.06619424372911453, 0.11493084579706192, 0.0352681465446949, 0.07751806825399399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21730750799179077, 0.0522487610578537, 0.04279685392975807, 0.05130990222096443, 0.07021073251962662, 0.06084864214062691, 0.10094171017408371, 0.06729137152433395, 0.05347270891070366, 0.058032434433698654, 0.063866026699543, 0.041436828672885895, 0.05429812893271446, 0.06593840569257736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14158987998962402, 0.08735615015029907, 0.041096281260252, 0.07771319150924683, 0.06641592085361481, 0.06084611266851425, 0.07890867441892624, 0.0646718293428421, 0.04156756028532982, 0.05314023420214653, 0.06033195182681084, 0.049903448671102524, 0.06147689372301102, 0.06152055040001869, 0.05346129834651947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277396976947784, 0.05140269547700882, 0.034800734370946884, 0.04410992190241814, 0.049271050840616226, 0.08066020160913467, 0.09371131658554077, 0.07634276151657104, 0.034600723534822464, 0.05556501820683479, 0.09000374376773834, 0.027950912714004517, 0.05808688700199127, 0.09759873896837234, 0.0585305355489254, 0.03459075838327408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19136784970760345, 0.045888014137744904, 0.037184182554483414, 0.044788483530282974, 0.058455418795347214, 0.05162312090396881, 0.08451799303293228, 0.056617286056280136, 0.044779226183891296, 0.04681586101651192, 0.051775235682725906, 0.03474309667944908, 0.04365592449903488, 0.05257754027843475, 0.045719120651483536, 0.05523937568068504, 0.0542522594332695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1780986487865448, 0.03651316463947296, 0.03537803143262863, 0.046600595116615295, 0.05606750771403313, 0.05542529746890068, 0.06580902636051178, 0.05869590863585472, 0.044602103531360626, 0.03845332935452461, 0.05522070452570915, 0.028129279613494873, 0.038876309990882874, 0.05635206028819084, 0.043072041124105453, 0.04859212040901184, 0.05801304802298546, 0.05610081925988197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277125775814056, 0.04416342452168465, 0.01679084822535515, 0.03922899067401886, 0.030570242553949356, 0.08429384231567383, 0.058298345655202866, 0.07985575497150421, 0.02774021402001381, 0.02460792474448681, 0.08568026125431061, 0.012135532684624195, 0.02122362144291401, 0.08979950100183487, 0.024395622313022614, 0.018000073730945587, 0.09797869622707367, 0.08564858883619308, 0.04681727662682533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15648673474788666, 0.043593354523181915, 0.029469121247529984, 0.023382792249321938, 0.03989394009113312, 0.06601442396640778, 0.07239895313978195, 0.049598753452301025, 0.02572007291018963, 0.028729896992444992, 0.07268751412630081, 0.020104363560676575, 0.03894994035363197, 0.07793483883142471, 0.0318501777946949, 0.02957259863615036, 0.08162932842969894, 0.049830298870801926, 0.04757082462310791, 0.01458201464265585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16675153374671936, 0.04021674394607544, 0.03194626420736313, 0.039155539125204086, 0.04867977276444435, 0.04351935535669327, 0.07027735561132431, 0.046769797801971436, 0.03737049549818039, 0.03785952925682068, 0.04185350984334946, 0.029438771307468414, 0.034967005252838135, 0.041871532797813416, 0.0366596058011055, 0.04418947547674179, 0.04244701564311981, 0.04308999702334404, 0.055408235639333725, 0.024029968306422234, 0.04349851980805397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21311703324317932, 0.03452148661017418, 0.026512037962675095, 0.037284646183252335, 0.042002297937870026, 0.05378074571490288, 0.06410719454288483, 0.040195900946855545, 0.029513953253626823, 0.030562080442905426, 0.0481405146420002, 0.01964573934674263, 0.02385598234832287, 0.047123588621616364, 0.02780524455010891, 0.02563280239701271, 0.04690324515104294, 0.04211500659584999, 0.04245338588953018, 0.016209961846470833, 0.04720157012343407, 0.041315577924251556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16099102795124054, 0.03149213269352913, 0.02550601400434971, 0.03203628957271576, 0.03811938688158989, 0.05386461690068245, 0.05289202183485031, 0.06297369301319122, 0.03872941806912422, 0.030703026801347733, 0.0486149899661541, 0.01696413941681385, 0.02098487690091133, 0.04743489995598793, 0.026178572326898575, 0.032817017287015915, 0.04874100163578987, 0.03702305257320404, 0.05028444528579712, 0.014425930567085743, 0.04926920682191849, 0.027485143393278122, 0.05246911942958832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13924194872379303, 0.04732194542884827, 0.022920062765479088, 0.037826746702194214, 0.037331584841012955, 0.056281957775354385, 0.06773107498884201, 0.06383747607469559, 0.02882455848157406, 0.028368620201945305, 0.05008406937122345, 0.014775174669921398, 0.02105889841914177, 0.04819710925221443, 0.017685115337371826, 0.015456218272447586, 0.04842803254723549, 0.037099506705999374, 0.042473237961530685, 0.018426815047860146, 0.04861332103610039, 0.022673942148685455, 0.05998959764838219, 0.025352945551276207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1956235021352768, 0.03233328089118004, 0.02287409082055092, 0.038390759378671646, 0.034498799592256546, 0.046169038861989975, 0.05553752928972244, 0.03960668295621872, 0.023098409175872803, 0.024249296635389328, 0.040433064103126526, 0.016078544780611992, 0.021624943241477013, 0.039030544459819794, 0.026520879939198494, 0.028113430365920067, 0.0382363423705101, 0.035426124930381775, 0.041745759546756744, 0.02109714038670063, 0.037679556757211685, 0.03728693723678589, 0.044239211827516556, 0.022921498864889145, 0.0371847003698349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0581965334713459, 0.038897402584552765, 0.026005243882536888, 0.023567883297801018, 0.0229799821972847, 0.053841497749090195, 0.058061063289642334, 0.06858772039413452, 0.03745981678366661, 0.02915911003947258, 0.05474673584103584, 0.013592935167253017, 0.027647055685520172, 0.055754028260707855, 0.030779872089624405, 0.01613735966384411, 0.05745430663228035, 0.039687298238277435, 0.034065522253513336, 0.013110967352986336, 0.059776563197374344, 0.01604376919567585, 0.029699301347136497, 0.020566528663039207, 0.08347287029027939, 0.030708611011505127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15561482310295105, 0.030323175713419914, 0.021067578345537186, 0.03860041871666908, 0.025089260190725327, 0.0471951998770237, 0.04255650192499161, 0.051662564277648926, 0.030368106439709663, 0.020133640617132187, 0.042556967586278915, 0.018511775881052017, 0.01867172122001648, 0.041430287063121796, 0.022022128105163574, 0.02106102928519249, 0.04166619852185249, 0.027249207720160484, 0.0404815748333931, 0.015536418184638023, 0.04219621792435646, 0.01700734719634056, 0.06220948323607445, 0.015703149139881134, 0.054431866854429245, 0.04092409089207649, 0.01572924666106701, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15218870341777802, 0.03232048079371452, 0.026277616620063782, 0.03215136006474495, 0.0370805524289608, 0.038433339446783066, 0.042185209691524506, 0.034409213811159134, 0.02929617464542389, 0.024752279743552208, 0.034612320363521576, 0.021795077249407768, 0.023419683799147606, 0.03386643901467323, 0.028580613434314728, 0.034403249621391296, 0.03315696865320206, 0.026710394769906998, 0.042135659605264664, 0.019021356478333473, 0.032785799354314804, 0.026839982718229294, 0.03304454684257507, 0.023302637040615082, 0.03390035778284073, 0.039449259638786316, 0.02133426070213318, 0.042546436190605164, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10210391879081726, 0.04830532521009445, 0.027957910671830177, 0.02813485451042652, 0.04368893429636955, 0.03765960410237312, 0.04012181982398033, 0.03589580953121185, 0.02449178136885166, 0.019768044352531433, 0.03467409312725067, 0.015431455336511135, 0.03261655941605568, 0.03414337709546089, 0.027461392804980278, 0.020323220640420914, 0.03445842117071152, 0.015827571973204613, 0.03070584498345852, 0.02036093734204769, 0.03558045253157616, 0.0347902737557888, 0.035181500017642975, 0.028572579845786095, 0.04333386942744255, 0.03896386921405792, 0.017587706446647644, 0.045533761382102966, 0.046325117349624634, 0.0, 0.0, 0.0, 0.0], [0.1184174120426178, 0.026689790189266205, 0.02854764647781849, 0.03516456484794617, 0.03519095852971077, 0.030704865232110023, 0.04254690557718277, 0.023103507235646248, 0.02546311914920807, 0.029678557068109512, 0.02839520573616028, 0.019178250804543495, 0.023833584040403366, 0.027640027925372124, 0.033817537128925323, 0.03964013233780861, 0.027574436739087105, 0.0218561589717865, 0.03966763615608215, 0.03941831737756729, 0.02711562067270279, 0.030498048290610313, 0.03493283689022064, 0.0323205292224884, 0.027840537950396538, 0.03877579793334007, 0.021124791353940964, 0.03861141949892044, 0.032771822065114975, 0.019479986280202866, 0.0, 0.0, 0.0], [0.05433791130781174, 0.019247837364673615, 0.011686466634273529, 0.014118615537881851, 0.013909785076975822, 0.05736802518367767, 0.034546397626399994, 0.04665059968829155, 0.013026446104049683, 0.013271305710077286, 0.05952776223421097, 0.009063140489161015, 0.017364205792546272, 0.06135563179850578, 0.01263465080410242, 0.015145532786846161, 0.06425536423921585, 0.046270616352558136, 0.019556373357772827, 0.012543448247015476, 0.06913558393716812, 0.03482367843389511, 0.03000597655773163, 0.012261816300451756, 0.07985590398311615, 0.01899644359946251, 0.0107229333370924, 0.08654540777206421, 0.017174087464809418, 0.02214416116476059, 0.02245398610830307, 0.0, 0.0], [0.05849645286798477, 0.03437737002968788, 0.013603088445961475, 0.024170437827706337, 0.019005868583917618, 0.0654640644788742, 0.03062298148870468, 0.03573206812143326, 0.01885945349931717, 0.012241478078067303, 0.0628218948841095, 0.01183574739843607, 0.009552357718348503, 0.06431794911623001, 0.02158958464860916, 0.010912963189184666, 0.06665915250778198, 0.02399745211005211, 0.026596732437610626, 0.006153553258627653, 0.06984329968690872, 0.037238676100969315, 0.030046721920371056, 0.021686799824237823, 0.043640609830617905, 0.02120962180197239, 0.013490457087755203, 0.04632722586393356, 0.02043450064957142, 0.013362267054617405, 0.018568987026810646, 0.04714023321866989, 0.0], [0.1352868527173996, 0.02973336912691593, 0.026111328974366188, 0.03753575310111046, 0.0388815701007843, 0.033166784793138504, 0.0482439287006855, 0.030468301847577095, 0.02603822760283947, 0.02412371151149273, 0.02789274975657463, 0.022709935903549194, 0.024185296148061752, 0.026114555075764656, 0.023209676146507263, 0.025175288319587708, 0.02461479790508747, 0.02112315408885479, 0.029685046523809433, 0.018167469650506973, 0.02306438237428665, 0.02059805952012539, 0.03441142290830612, 0.021083403378725052, 0.022538838908076286, 0.03228156268596649, 0.013987254351377487, 0.024144921451807022, 0.027002310380339622, 0.012929447926580906, 0.03616538643836975, 0.026840228587388992, 0.03248501941561699]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print(\"Layer 0 Head Attention Patterns:\")\n",
        "cv.attention.attention_patterns(tokens=gpt2_str_tokens, attention=attention_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8lf2ZmJTq-V"
      },
      "source": [
        "## Hooks: Intervening on Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kJTeZ7sTq-V"
      },
      "source": [
        "One of the great things about interpreting neural networks is that we have *full control* over our system. From a computational perspective, we know exactly what operations are going on inside (even if we don't know what they mean!). And we can make precise, surgical edits and see how the model's behaviour and other internals change. This is an extremely powerful tool, because it can let us eg set up careful counterfactuals and causal intervention to easily understand model behaviour.\n",
        "\n",
        "Accordingly, being able to do this is a pretty core operation, and this is one of the main things TransformerLens supports! The key feature here is **hook points**. Every activation inside the transformer is surrounded by a hook point, which allows us to edit or intervene on it.\n",
        "\n",
        "We do this by adding a **hook function** to that activation. The hook function maps `current_activation_value, hook_point` to `new_activation_value`. As the model is run, it computes that activation as normal, and then the hook function is applied to compute a replacement, and that is substituted in for the activation. The hook function can be an arbitrary Python function, so long as it returns a tensor of the correct shape.\n",
        "\n",
        "<details><summary>Relationship to PyTorch hooks</summary>\n",
        "\n",
        "[PyTorch hooks](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) are a great and underrated, yet incredibly janky, feature. They can act on a layer, and edit the input or output of that layer, or the gradient when applying autodiff. The key difference is that **Hook points** act on *activations* not layers. This means that you can intervene within a layer on each activation, and don't need to care about the precise layer structure of the transformer. And it's immediately clear exactly how the hook's effect is applied. This adjustment was shamelessly inspired by [Garcon's use of ProbePoints](https://transformer-circuits.pub/2021/garcon/index.html).\n",
        "\n",
        "They also come with a range of other quality of life improvements, like the model having a `model.reset_hooks()` method to remove all hooks, or helper methods to temporarily add hooks for a single forward pass - it is *incredibly* easy to shoot yourself in the foot with standard PyTorch hooks!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgXH_fzcTq-V"
      },
      "source": [
        "As a basic example, let's [ablate](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=fh-HJyz1CgUVrXuoiban6bYx) head 7 in layer 0 on the text above.\n",
        "\n",
        "We define a `head_ablation_hook` function. This takes the value tensor for attention layer 0, and sets the component with `head_index==7` to zero and returns it (Note - we return by convention, but since we're editing the activation in-place, we don't strictly *need* to).\n",
        "\n",
        "We then use the `run_with_hooks` helper function to run the model and *temporarily* add in the hook for just this run. We enter in the hook as a tuple of the activation name (also the hook point name - found with `utils.get_act_name`) and the hook function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zS-_sSMmTq-V",
        "outputId": "19fdd8dd-7456-4ad9-eb44-384d7c9ab644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the value tensor: torch.Size([1, 33, 12, 64])\n",
            "Original Loss: 3.999\n",
            "Ablated Loss: 5.453\n"
          ]
        }
      ],
      "source": [
        "layer_to_ablate = 0\n",
        "head_index_to_ablate = 8\n",
        "\n",
        "# We define a head ablation hook\n",
        "# The type annotations are NOT necessary, they're just a useful guide to the reader\n",
        "#\n",
        "def head_ablation_hook(\n",
        "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
        "    hook: HookPoint\n",
        ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
        "    print(f\"Shape of the value tensor: {value.shape}\")\n",
        "    value[:, :, head_index_to_ablate, :] = 0.\n",
        "    return value\n",
        "\n",
        "original_loss = model(gpt2_tokens, return_type=\"loss\")\n",
        "ablated_loss = model.run_with_hooks(\n",
        "    gpt2_tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"v\", layer_to_ablate),\n",
        "        head_ablation_hook\n",
        "        )]\n",
        "    )\n",
        "print(f\"Original Loss: {original_loss.item():.3f}\")\n",
        "print(f\"Ablated Loss: {ablated_loss.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEAA2nRaTq-V"
      },
      "source": [
        "**Gotcha:** Hooks are global state - they're added in as part of the model, and stay there until removed. `run_with_hooks` tries to create an abstraction where these are local state, by removing all hooks at the end of the function. But you can easily shoot yourself in the foot if there's, eg, an error in one of your hooks so the function never finishes. If you start getting bugs, try `model.reset_hooks()` to clean things up. Further, if you *do* add hooks of your own that you want to keep, which you can do with `add_perma_hook` on the relevant HookPoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SGglBLATq-V"
      },
      "source": [
        "### Activation Patching on the Indirect Object Identification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnsQdPVGTq-V"
      },
      "source": [
        "For a somewhat more involved example, let's use hooks to apply **[activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** on the **[Indirect Object Identification](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=iWsV3s5Kdd2ca3zNgXr5UPHa)** (IOI) task.\n",
        "\n",
        "The IOI task is the task of identifying that a sentence like \"After John and Mary went to the store, Mary gave a bottle of milk to\" continues with \" John\" rather than \" Mary\" (ie, finding the indirect object), and Redwood Research have [an excellent paper studying the underlying circuit in GPT-2 Small](https://arxiv.org/abs/2211.00593).\n",
        "\n",
        "**[Activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** is a technique from [Kevin Meng and David Bau's excellent ROME paper](https://rome.baulab.info/). The goal is to identify which model activations are important for completing a task. We do this by setting up a **clean prompt** and a **corrupted prompt** and a **metric** for performance on the task. We then pick a specific model activation, run the model on the corrupted prompt, but then *intervene* on that activation and patch in its value when run on the clean prompt. We then apply the metric, and see how much this patch has recovered the clean performance.\n",
        "(See [a more detailed demonstration of activation patching here](https://colab.research.google.com/github.com/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skdx44hrTq-V"
      },
      "source": [
        "Here, our clean prompt is \"After John and Mary went to the store, **Mary** gave a bottle of milk to\", our corrupted prompt is \"After John and Mary went to the store, **John** gave a bottle of milk to\", and our metric is the difference between the correct logit ( John) and the incorrect logit ( Mary) on the final token.\n",
        "\n",
        "We see that the logit difference is significantly positive on the clean prompt, and significantly negative on the corrupted prompt, showing that the model is capable of doing the task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ARJwrjkqTq-V",
        "outputId": "b43b5412-f888-4b14-b1bc-31365702a941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean logit difference: 4.276\n",
            "Corrupted logit difference: -2.738\n"
          ]
        }
      ],
      "source": [
        "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
        "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "def logits_to_logit_diff(logits, correct_answer=\" John\", incorrect_answer=\" Mary\"):\n",
        "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
        "    # If the string is not a single token, it raises an error.\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    incorrect_index = model.to_single_token(incorrect_answer)\n",
        "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
        "\n",
        "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
        "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "# We don't need to cache on the corrupted prompt.\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
        "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1UVYSItTq-V"
      },
      "source": [
        "We now setup the hook function to do activation patching. Here, we'll patch in the [residual stream](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=DHp9vZ0h9lA9OCrzG2Y3rrzH) at the start of a specific layer and at a specific position. This will let us see how much the model is using the residual stream at that layer and position to represent the key information for the task.\n",
        "\n",
        "We want to iterate over all layers and positions, so we write the hook to take in an position parameter. Hook functions must have the input signature (activation, hook), but we can use `functools.partial` to set the position parameter before passing it to `run_with_hooks`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8jE2ELiTq-W",
        "outputId": "934b0bd7-55ff-4f61-b6aa-f52f8b86abb4",
        "colab": {
          "referenced_widgets": [
            "980e183587f54a03bb4ead134831c94d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "980e183587f54a03bb4ead134831c94d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We define a residual stream patching hook\n",
        "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
        "# The type annotations are a guide to the reader and are not necessary\n",
        "def residual_stream_patching_hook(\n",
        "    resid_pre: Float[torch.Tensor, \"batch pos d_model\"],\n",
        "    hook: HookPoint,\n",
        "    position: int\n",
        ") -> Float[torch.Tensor, \"batch pos d_model\"]:\n",
        "    # Each HookPoint has a name attribute giving the name of the hook.\n",
        "    clean_resid_pre = clean_cache[hook.name]\n",
        "    resid_pre[:, position, :] = clean_resid_pre[:, position, :]\n",
        "    return resid_pre\n",
        "\n",
        "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "num_positions = len(clean_tokens[0])\n",
        "ioi_patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
        "\n",
        "for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
        "    for position in range(num_positions):\n",
        "        # Use functools.partial to create a temporary hook function with the position fixed\n",
        "        temp_hook_fn = partial(residual_stream_patching_hook, position=position)\n",
        "        # Run the model with the patching hook\n",
        "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
        "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
        "        ])\n",
        "        # Calculate the logit difference\n",
        "        patched_logit_diff = logits_to_logit_diff(patched_logits).detach()\n",
        "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
        "        ioi_patching_result[layer, position] = (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Q_qQHTTq-W"
      },
      "source": [
        "We can now visualize the results, and see that this computation is extremely localised within the model. Initially, the second subject (Mary) token is all that matters (naturally, as it's the only different token), and all relevant information remains here until heads in layer 7 and 8 move this to the final token where it's used to predict the indirect object.\n",
        "(Note - the heads are in layer 7 and 8, not 8 and 9, because we patched in the residual stream at the *start* of each layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmMdJFjTTq-W",
        "outputId": "c11c0017-3fe1-4de9-8474-8f5d90b5e8b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\")) {                    Plotly.newPlot(                        \"1d04e6ee-31ed-4e10-b7a1-08f454ff13b2\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"After_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" store_8\",\",_9\",\" Mary_10\",\" gave_11\",\" a_12\",\" bottle_13\",\" of_14\",\" milk_15\",\" to_16\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9981480240821838,0.0016014170832931995,0.00014983542496338487,-0.00037064551725052297,-2.1482755983015522e-05,-0.000627894711215049,-0.0005147703341208398],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9980558156967163,0.0022839705925434828,0.0001830113324103877,-0.000504164956510067,-0.0002675826835911721,-5.1395454647718e-05,-0.0012810792541131377],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9967373609542847,0.004082539584487677,0.000974066206254065,4.3509378883754835e-05,-0.0001593531051184982,-0.0003361099516041577,-0.0019437815062701702],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9905893206596375,0.019987665116786957,0.001896193134598434,0.0010143123799934983,-6.716760253766552e-05,0.0009109776583500206,-0.0019008159870281816],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9616512656211853,0.08534800261259079,0.005204265471547842,0.0030527268536388874,0.00019687994790729135,0.001105954055674374,-0.002283698646351695],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9630993008613586,0.08437121659517288,0.004121969919651747,0.0007184486021287739,0.000102790909295436,0.0010028912220150232,-0.004215243272483349],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9359176158905029,0.11111806333065033,0.007705239113420248,0.000375812262063846,0.00036575071862898767,0.001326492172665894,0.018744928762316704],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7701548933982849,0.03741942718625069,0.0020680550951510668,-8.239589078584686e-05,0.00013460713671520352,0.001724603003822267,0.44990602135658264],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09650597721338272,0.025926152244210243,0.001972062513232231,0.0003298554802313447,0.00042503225267864764,0.0018855876987800002,0.8994725346565247],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.023322386667132378,0.018538258969783783,0.0015875485260039568,0.0005272792768664658,0.0002534421219024807,0.0008737227180972695,0.9612759947776794],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.008558566682040691,0.006340676452964544,0.0005816660122945905,-0.0003418205596972257,0.00011094891669927165,0.0006477459101006389,0.9495818614959717]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Position: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1d04e6ee-31ed-4e10-b7a1-08f454ff13b2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
        "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
        "imshow(ioi_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrKOtWHUTq-W"
      },
      "source": [
        "## Hooks: Accessing Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsGmZ7N_Tq-Z"
      },
      "source": [
        "Hooks can also be used to just **access** an activation - to run some function using that activation value, *without* changing the activation value. This can be achieved by just having the hook return nothing, and not editing the activation in place.\n",
        "\n",
        "This is useful for eg extracting activations for a specific task, or for doing some long-running calculation across many inputs, eg finding the text that most activates a specific neuron. (Note - everything this can do *could* be done with `run_with_cache` and post-processing, but this workflow can be more intuitive and memory efficient.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xiB7F0KTq-Z"
      },
      "source": [
        "To demonstrate this, let's look for **[induction heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)** in GPT-2 Small.\n",
        "\n",
        "Induction circuits are a very important circuit in generative language models, which are used to detect and continue repeated subsequences. They consist of two heads in separate layers that compose together, a **previous token head** which always attends to the previous token, and an **induction head** which attends to the token *after* an earlier copy of the current token.\n",
        "\n",
        "To see why this is important, let's say that the model is trying to predict the next token in a news article about Michael Jordan. The token \" Michael\", in general, could be followed by many surnames. But an induction head will look from that occurence of \" Michael\" to the token after previous occurences of \" Michael\", ie \" Jordan\" and can confidently predict that that will come next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp8U14V9Tq-Z"
      },
      "source": [
        "An interesting fact about induction heads is that they generalise to arbitrary sequences of repeated tokens. We can see this by generating sequences of 50 random tokens, repeated twice, and plotting the average loss at predicting the next token, by position. We see that the model goes from terrible to very good at the halfway point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64MRQEcMTq-Z",
        "outputId": "bf1906d6-e549-433e-a206-745a58451d83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"d3e84661-e12c-4a84-8655-2f33ba1284da\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d3e84661-e12c-4a84-8655-2f33ba1284da\")) {                    Plotly.newPlot(                        \"d3e84661-e12c-4a84-8655-2f33ba1284da\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98],\"xaxis\":\"x\",\"y\":[10.872052192687988,12.263540267944336,14.253204345703125,13.246556282043457,13.005993843078613,13.460993766784668,12.97065258026123,13.064518928527832,11.797075271606445,12.513029098510742,12.812576293945312,12.767385482788086,12.285192489624023,13.085138320922852,12.94897747039795,12.297746658325195,12.90766716003418,11.799567222595215,12.414271354675293,12.327254295349121,10.539899826049805,12.742929458618164,11.173940658569336,11.951539993286133,12.244311332702637,13.201930046081543,11.1293363571167,11.558095932006836,11.154999732971191,10.811470031738281,11.701059341430664,11.395160675048828,12.566507339477539,11.18510627746582,10.747629165649414,11.653327941894531,12.03685188293457,11.461939811706543,12.074749946594238,9.762995719909668,11.312043190002441,12.081087112426758,11.683740615844727,11.636404991149902,13.009252548217773,11.74526596069336,11.57121753692627,11.874940872192383,11.46745777130127,10.957990646362305,1.9599711894989014,0.8824893236160278,0.8781511187553406,0.3232020437717438,0.4251673221588135,0.25897061824798584,0.4066997468471527,0.21202726662158966,0.16516722738742828,0.11655920743942261,0.2388218641281128,0.04333684220910072,0.14030048251152039,0.1186639666557312,0.18781667947769165,0.05167889595031738,0.07741443812847137,0.08716835081577301,0.07370562106370926,0.04441319778561592,0.06953944265842438,0.030275847762823105,0.03782800957560539,0.04936334118247032,0.07152687013149261,0.11301679909229279,0.03093745745718479,0.05099482089281082,0.034429892897605896,0.010404873639345169,0.10524864494800568,0.14771051704883575,0.013218658044934273,0.1266184151172638,0.0512910857796669,0.007522976957261562,0.11803790181875229,0.1785733997821808,0.13207308948040009,0.32432517409324646,0.19658631086349487,0.07713610678911209,0.03152012079954147,0.05610422044992447,0.029515912756323814,0.02569529041647911,0.0804244875907898,0.0179621372371912,0.07805689424276352],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss by position on random repeated tokens\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d3e84661-e12c-4a84-8655-2f33ba1284da');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 10\n",
        "seq_len = 50\n",
        "size = (batch_size, seq_len)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "random_tokens = input_tensor.to(model.cfg.device)\n",
        "repeated_tokens = einops.repeat(random_tokens, \"batch seq_len -> batch (2 seq_len)\")\n",
        "repeated_logits = model(repeated_tokens)\n",
        "correct_log_probs = model.loss_fn(repeated_logits, repeated_tokens, per_token=True)\n",
        "loss_by_position = einops.reduce(correct_log_probs, \"batch position -> position\", \"mean\")\n",
        "line(loss_by_position, xaxis=\"Position\", yaxis=\"Loss\", title=\"Loss by position on random repeated tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuqGLrT8Tq-Z"
      },
      "source": [
        "The induction heads will be attending from the second occurence of each token to the token *after* its first occurence, ie the token `50-1==49` places back. So by looking at the average attention paid 49 tokens back, we can identify induction heads! Let's define a hook to do this!\n",
        "\n",
        "<details><summary>Technical details</summary>\n",
        "\n",
        "* We attach the hook to the attention pattern activation. There's one big pattern activation per layer, stacked across all heads, so we need to do some tensor manipulation to get a per-head score.\n",
        "* Hook functions can access global state, so we make a big tensor to store the induction head score for each head, and then we just add the score for each head to the appropriate position in the tensor.\n",
        "* To get a single hook function that works for each layer, we use the `hook.layer()` method to get the layer index (internally this is just inferred from the hook names).\n",
        "* As we want to add this to *every* activation pattern hook point, rather than giving the string for an activation name, this time we give a **name filter**. This is a Boolean function on hook point names, and it adds the hook function to every hook point where the function evaluates as true.\n",
        "    * `run_with_hooks` allows us to enter a list of (act_name, hook_function) pairs to all be added at once, so we could also have done this by inputting a list with a hook for each layer.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaHV3qTsTq-Z",
        "outputId": "ac1f733e-2262-4517-bc69-8943a8aef9bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"190ab42e-4456-4833-a298-6f585a1583e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"190ab42e-4456-4833-a298-6f585a1583e4\")) {                    Plotly.newPlot(                        \"190ab42e-4456-4833-a298-6f585a1583e4\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009955878369510174,9.966958168661222e-05,0.010546973906457424,4.0583410054750857e-07,0.00022813043324276805,0.00019768899073824286,0.00977946724742651,0.0006674872129224241,0.00908320676535368,0.00915559846907854,0.006828702986240387,0.015242615714669228],[0.0011627675266936421,0.00045248764217831194,0.0021361575927585363,0.01417490839958191,0.004926139954477549,0.010640118271112442,0.015927109867334366,0.013070465996861458,0.012896527536213398,0.016126573085784912,0.006526595447212458,0.000517632404807955],[0.0044746194034814835,0.01877586357295513,0.003041735850274563,0.0019074507290497422,0.012237360700964928,0.002584304893389344,0.0039876471273601055,0.008248553611338139,0.004771647043526173,0.0017633740790188313,0.0006906316848471761,0.010382029227912426],[0.015542104840278625,0.007110548205673695,0.002217961009591818,0.012544052675366402,0.021509619429707527,0.011987114325165749,0.00174334819894284,0.0009274697513319552,0.005935505498200655,0.01233423687517643,0.009232483804225922,0.006464063189923763],[0.01664578728377819,0.014668889343738556,0.013992691412568092,0.008478098548948765,0.01899615488946438,0.012697082944214344,0.008333329111337662,0.0017152393702417612,0.01665916107594967,0.014090241864323616,0.018890956416726112,8.906972381872436e-11],[0.451614111661911,0.9170698523521423,0.01424565352499485,0.0065706996247172356,0.011130396276712418,0.9321417212486267,0.008963020518422127,0.018100803717970848,0.02871188521385193,0.029120853170752525,0.02137076109647751,0.01733485981822014],[0.008789685554802418,0.017398007214069366,0.01834423653781414,0.015153961256146431,0.02248268947005272,0.011032403446733952,0.03012258931994438,0.01068038959056139,0.009857730939984322,0.9169892072677612,0.036462243646383286,0.01406988874077797],[0.01107383705675602,0.17768746614456177,0.8614926934242249,0.019131189212203026,0.018100876361131668,0.016298996284604073,0.04784739762544632,0.08873092383146286,0.01723749376833439,0.019047973677515984,0.9243332743644714,0.06009266525506973],[0.015750497579574585,0.40704065561294556,0.014495478942990303,0.050178349018096924,0.017805716022849083,0.012079598382115364,0.15166832506656647,0.013180013746023178,0.032852329313755035,0.03178909420967102,0.06760691851377487,0.022921957075595856],[0.25689446926116943,0.19054049253463745,0.10555234551429749,0.012684683315455914,0.0927107185125351,0.026271803304553032,0.4618716239929199,0.029983991757035255,0.05182349309325218,0.4789004623889923,0.016641730442643166,0.03995012864470482],[0.339070200920105,0.5105082392692566,0.038450296968221664,0.14799615740776062,0.05797654390335083,0.01543364953249693,0.3008923828601837,0.47816023230552673,0.05431150645017624,0.015494456514716148,0.16141793131828308,0.2569926977157593],[0.017057929188013077,0.053864460438489914,0.03378748893737793,0.009234139695763588,0.03453892469406128,0.1011928990483284,0.04960957169532776,0.07048070430755615,0.009171898476779461,0.30352190136909485,0.40838193893432617,0.022866230458021164]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('190ab42e-4456-4833-a298-6f585a1583e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "905TZC8ITq-Z"
      },
      "source": [
        "Head 5 in Layer 5 scores extremely highly on this score, and we can feed in a shorter repeated random sequence, visualize the attention pattern for it and see this directly - including the \"induction stripe\" at `seq_len-1` tokens back.\n",
        "\n",
        "This time we put in a hook on the attention pattern activation to visualize the pattern of the relevant head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkAeEc5hTq-Z",
        "outputId": "705ce169-8733-4ebb-93f2-521cdd9be1bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-fcf89ad6-45d6\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-fcf89ad6-45d6\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\", \"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9737270474433899, 0.0262729711830616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9820428490638733, 0.017020266503095627, 0.0009368456667289138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9895542860031128, 0.00866580568253994, 0.0004119748482480645, 0.0013679902767762542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8543053865432739, 0.0780181884765625, 0.0008415378979407251, 0.00013599172234535217, 0.06669897586107254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9374335408210754, 0.033002182841300964, 0.0015577428275719285, 2.5352785542054335e-06, 0.0010925536043941975, 0.026911530643701553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.976921021938324, 0.0038436956238001585, 2.234029489045497e-05, 3.521895996527746e-05, 0.005183499306440353, 0.01217629387974739, 0.0018179028993472457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473506212234497, 0.013174930587410927, 0.0013492131838575006, 1.180242543341592e-05, 0.0009449435747228563, 0.011318957433104515, 0.018021011725068092, 0.007828536443412304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847127199172974, 0.0010781448800116777, 0.002173440996557474, 5.48224352314719e-06, 0.0004914223100058734, 0.0013570792507380247, 0.0001018581388052553, 0.00028538500191643834, 0.009794448502361774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9915198683738708, 0.0044833519496023655, 0.00012727153080049902, 0.0001670209167059511, 0.0016301727155223489, 0.0011521612759679556, 0.0003231288574170321, 0.00012646260438486934, 0.00039313812158070505, 7.735053804935887e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8908807635307312, 0.024311939254403114, 1.7341229977319017e-05, 4.1577197407605127e-05, 0.0008967601461336017, 0.07334909588098526, 0.0009482800960540771, 0.004280842375010252, 0.005168660078197718, 7.830293725419324e-06, 9.693214815342799e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.817081093788147, 0.13517087697982788, 0.011989914812147617, 1.1421690032875631e-05, 0.0003511958639137447, 0.00945067685097456, 0.01946328766644001, 0.0006557486485689878, 0.0005761014763265848, 2.9927012292318977e-05, 1.658979817875661e-05, 0.005203105043619871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9082697033882141, 0.006068143527954817, 0.013871830888092518, 0.0008237074362114072, 0.011908311396837234, 0.01554207131266594, 0.008354817517101765, 0.0020781648345291615, 0.0013173273764550686, 0.0021398114040493965, 0.003944162279367447, 0.0012376609956845641, 0.02444424293935299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9479592442512512, 0.0021026760805398226, 0.01193847507238388, 0.00012338522356003523, 3.537495786076761e-06, 0.00014498857490252703, 0.0005875465576536953, 2.5534713131492026e-05, 0.0013609088491648436, 0.0003395720850676298, 0.01007620245218277, 0.0157905463129282, 0.006346344482153654, 0.003201034851372242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9393549561500549, 0.006392289884388447, 0.0018427352188155055, 6.116198164818343e-06, 0.0003358719404786825, 0.0020515176001936197, 0.003801520448178053, 0.0012357976520434022, 0.0002194812404923141, 0.0003869338543154299, 5.012214751332067e-05, 0.008153197355568409, 0.026924636214971542, 0.002938011661171913, 0.0063067772425711155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9339620471000671, 0.0017828113632276654, 0.005864645820111036, 0.000199502072064206, 7.227147580124438e-05, 0.001453535514883697, 0.0025924306828528643, 0.0004859396431129426, 0.002229833509773016, 0.00015120525495149195, 0.012292936444282532, 0.005057854112237692, 0.012368598021566868, 0.003944497089833021, 0.0062751127406954765, 0.011266660876572132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8931334614753723, 0.0015468199271708727, 0.013001665472984314, 7.96635686128866e-06, 5.864337435923517e-05, 0.0008863371913321316, 0.0032020823564380407, 3.214758908143267e-05, 0.00018022512085735798, 1.1455734238552395e-05, 7.600105163874105e-05, 0.0004202726122457534, 0.001612616004422307, 0.028539085760712624, 0.010535502806305885, 0.025432026013731956, 0.021323613822460175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847024083137512, 0.00045824647531844676, 0.0001722048327792436, 6.160975090097054e-07, 4.7827966227487195e-06, 0.0005806126864627004, 0.00044618724496103823, 0.00041201553540304303, 0.0013038743054494262, 0.00031760730780661106, 6.99415395502001e-05, 0.0013941085198894143, 5.5830587371019647e-05, 0.0009110421524383128, 0.0001955802144948393, 0.000396028597606346, 0.0011691706022247672, 0.007409737445414066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8922598958015442, 0.010283716022968292, 0.007569305133074522, 0.015225780196487904, 0.000603529391810298, 0.0014377714833244681, 0.018397411331534386, 0.000181866911589168, 0.0021135706920176744, 3.8036650948924944e-05, 0.009962501004338264, 0.003998196218162775, 0.0012666822876781225, 0.002186268102377653, 0.003267065854743123, 0.0015871906653046608, 0.019133716821670532, 0.008779392577707767, 0.0017080693505704403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5637850761413574, 2.2041742340661585e-05, 0.00038083098479546607, 1.3938017673353897e-07, 4.306914647145277e-08, 0.0001288325438508764, 5.202714601182379e-05, 4.098215413250728e-06, 0.00043821678264066577, 1.0102498890773859e-05, 2.0490140741458163e-05, 0.00021747533173765987, 2.5249997634091415e-05, 2.1293963072821498e-05, 0.002207203535363078, 5.8927667851094157e-05, 0.002418374177068472, 0.0032775455620139837, 0.4260479211807251, 0.0008841017843224108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14634987711906433, 0.4510916769504547, 0.027205228805541992, 0.003008269937708974, 0.0007913715671747923, 0.08009303361177444, 0.005927639082074165, 0.0006846353644505143, 0.0021268511191010475, 0.0027747598942369223, 0.00023907265858724713, 0.002550537697970867, 0.005493414122611284, 0.015832215547561646, 0.0003449993673712015, 0.0005726668750867248, 0.0021751606836915016, 0.03904319554567337, 0.1698266863822937, 0.041207652539014816, 0.0026610144414007664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1588301807641983, 0.09413877129554749, 0.6926900744438171, 4.7764006012585014e-05, 8.085336048679892e-06, 0.009355566464364529, 0.0008445510757155716, 2.443790663164691e-06, 0.0001377410371787846, 1.1189789574928e-06, 4.677354354498675e-06, 0.0003472109674476087, 0.0026314801070839167, 0.0004504164680838585, 0.006463209632784128, 0.0005723321228288114, 0.001266839331947267, 0.006402328610420227, 0.0018093092367053032, 0.006555440369993448, 0.0003791518392972648, 0.01706133596599102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0507238395512104, 0.004356134217232466, 0.00013167195720598102, 0.93964684009552, 0.0005500880652107298, 0.002771187573671341, 1.4556246242136694e-05, 5.017395324102836e-06, 1.5498708307859488e-05, 7.02077898040443e-08, 8.694883035786916e-06, 3.654152897070162e-05, 3.6079711662750924e-06, 2.594179386505857e-05, 7.59087424739846e-06, 7.100912853275076e-07, 4.6297875087475404e-05, 7.143527909647673e-05, 0.00012089155643479899, 0.000561000662855804, 1.3380984455579892e-05, 0.0007342093158513308, 0.00015471279039047658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04466324299573898, 0.0028326697647571564, 7.648682367289439e-05, 0.00015513764810748398, 0.7502217888832092, 0.1919575184583664, 9.640491043683141e-05, 0.00016210104513447732, 0.00012769455497618765, 1.1226586138946004e-05, 8.733231879887171e-06, 0.0002813311293721199, 5.207761569181457e-05, 0.008386502042412758, 4.340233772381907e-06, 6.482672324636951e-05, 3.802950232056901e-05, 7.603670383105054e-05, 0.00012636416067834944, 9.22799008549191e-05, 4.0301836179423844e-07, 0.00011281618208158761, 2.522413069527829e-06, 0.00044938692008145154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0136062391102314, 0.006971819791942835, 3.188595292158425e-05, 1.8455398276273627e-06, 0.0023010680451989174, 0.9711790680885315, 0.0003632439475040883, 8.45976173877716e-05, 0.00010611514881020412, 4.505663468989951e-07, 2.987568166190613e-07, 0.0008592635276727378, 8.84485270944424e-05, 0.0003481197636574507, 9.285117812396493e-07, 3.160546111757867e-05, 1.2802072888007388e-05, 5.803379099234007e-05, 0.00010517534974496812, 6.438309355871752e-05, 1.8867468725147774e-06, 0.0009238768252544105, 4.681064638134558e-06, 8.993229130282998e-06, 0.002845223993062973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019611306488513947, 0.004386154469102621, 6.198722985573113e-05, 4.885768589701911e-08, 4.2524367017904297e-05, 0.0036122521851211786, 0.9598399996757507, 0.005622244905680418, 0.002344567561522126, 5.173993713469827e-07, 1.962153874046635e-06, 0.0016548263374716043, 0.0005915339570492506, 0.001169586437754333, 5.784231689176522e-06, 8.118995174299926e-05, 4.500300929066725e-05, 0.0001849783438956365, 5.086977398605086e-05, 0.000111328401544597, 6.848466000519693e-06, 3.85396160709206e-05, 4.853071914112661e-06, 1.2763491952227923e-07, 3.953082341467962e-06, 0.0005269552930258214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008729123510420322, 0.00017810783174354583, 2.8806312002416234e-07, 4.138274221077154e-07, 6.864992610644549e-05, 0.0009331199107691646, 0.0001488830748712644, 0.9844523668289185, 0.004786375444382429, 0.0001132896650233306, 7.25545532986871e-07, 7.424702926073223e-05, 1.4996358004282229e-05, 0.00019790712394751608, 2.995068371092202e-07, 4.872013960266486e-06, 5.296111794450553e-06, 4.536831511359196e-06, 0.00011268968228250742, 3.4171025617979467e-06, 8.272540071629919e-06, 1.237986271007685e-05, 3.665547154696469e-08, 9.025117719829723e-07, 1.6053079889388755e-05, 0.00011404424003558233, 1.8653661754797213e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04082169756293297, 0.003618433838710189, 4.8210502427536994e-05, 1.9615818303009291e-07, 5.380281072575599e-05, 0.0021802405826747417, 0.003327243495732546, 0.0018782124388962984, 0.9307870268821716, 0.004815405700355768, 1.4430276678467635e-05, 0.0028288080357015133, 0.0001046408069669269, 0.0029309175442904234, 0.0009514765115454793, 6.522196053992957e-05, 0.0002954130177386105, 0.00012317558866925538, 0.001551239751279354, 0.0005327718099579215, 0.00022083611111156642, 0.0004432721179910004, 1.939156027219724e-05, 5.825709763485065e-07, 1.663282819208689e-05, 0.0004773263353854418, 0.0011258200975134969, 0.000767689838539809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13800935447216034, 0.0003385838062968105, 0.00015972652181517333, 3.422568184419106e-08, 1.2696329577011056e-05, 0.00024196661252062768, 3.8219157431740314e-05, 3.751519398065284e-05, 0.004743278957903385, 0.8406777381896973, 0.0001887540565803647, 0.00015232608711812645, 1.2507432074926328e-05, 0.0002236285072285682, 0.00013282443978823721, 6.470834341598675e-05, 0.00013950421998742968, 9.763532580109313e-05, 0.0004387960070744157, 4.4860902562504634e-05, 6.358889368129894e-05, 0.00034255790524184704, 5.2226645493647084e-05, 5.293432536745968e-07, 4.435891696630279e-06, 6.54347168165259e-05, 2.914482593041612e-06, 3.872663910442498e-06, 0.013709748163819313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007798762992024422, 0.00022834629635326564, 4.6384946017496986e-07, 6.367677087837365e-07, 1.5816745872143656e-05, 4.7439083573408425e-05, 5.239070105744759e-06, 7.306558018171927e-06, 1.2522126780822873e-05, 3.3302333690699015e-07, 0.9909055233001709, 0.00045220478205010295, 5.365327069739578e-06, 7.535887561971322e-05, 8.799969691608567e-06, 7.89504611020675e-06, 0.00023918120132293552, 2.256896095786942e-06, 7.641861884621903e-05, 5.5141779739642516e-05, 4.378313406050438e-06, 2.181060699513182e-05, 4.4351477157533736e-08, 1.258427687389485e-06, 2.069825995931751e-06, 1.2951696589880157e-05, 3.9528120510112785e-07, 1.1202276937183342e-06, 7.9817673395155e-06, 2.9978505153849255e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042284343391656876, 0.011305336840450764, 7.640699664079875e-07, 2.2586050363315735e-06, 9.786370355868712e-05, 0.038269199430942535, 0.00023640785366296768, 0.0014555181842297316, 0.0029497782234102488, 1.2863498568549403e-06, 2.827169737429358e-05, 0.8946184515953064, 0.000523496069945395, 0.001179973711259663, 0.0009106355137191713, 0.00036046106833964586, 0.00020461619715206325, 2.910214607254602e-05, 0.0013425356009975076, 0.0003398243279661983, 0.00033255034941248596, 8.43034649733454e-05, 7.937682511283128e-08, 5.809831236547325e-06, 4.910861207463313e-06, 0.0023872887250036, 2.6967012672685087e-05, 0.00020931517065037042, 0.0007688838522881269, 5.801371116831433e-06, 3.4147673432016745e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006102928426116705, 0.016550440341234207, 4.6485070924973115e-05, 8.233602954987873e-08, 7.398419256787747e-06, 0.0005482262931764126, 0.000593138684052974, 1.573847112013027e-05, 3.5032899177167565e-05, 3.3504232987979776e-07, 1.8657554790024733e-07, 0.000460667914012447, 0.8416212201118469, 0.12311417609453201, 0.00635922746732831, 0.002699504140764475, 0.00016676213999744505, 0.0012130774557590485, 0.00013198891247157007, 8.468204759992659e-05, 4.615942543750862e-06, 6.99491283739917e-05, 4.916110356134595e-06, 3.4761166034513735e-07, 3.71195625348264e-07, 6.107363878982142e-05, 6.7285327531863e-05, 2.275831548104179e-06, 2.060149927274324e-05, 7.198155458354449e-07, 2.7881066344548344e-08, 1.652937862672843e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0404171422123909, 0.0013464416842907667, 0.0002881725085899234, 4.343583896115888e-06, 0.0006837462424300611, 0.0021492778323590755, 0.0012713986216112971, 0.00021145936625543982, 0.00014913539052940905, 2.368190689594485e-05, 9.255170880351216e-05, 7.46091318433173e-05, 0.0030381649266928434, 0.9153454899787903, 0.0020634918473660946, 0.002670771675184369, 0.0006971447728574276, 0.022915314882993698, 0.0016386568313464522, 0.00029437849298119545, 8.30199132906273e-06, 0.00011940939293708652, 3.610887142713182e-05, 1.2593977771757636e-05, 0.000383078760933131, 0.0011952179484069347, 0.00018445361638441682, 7.125888805603608e-05, 0.00012850709026679397, 6.062284592189826e-05, 4.517687557381578e-05, 6.895808724038943e-07, 0.0023790940176695585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03775651007890701, 0.0016132266027852893, 0.0003177846665494144, 8.171087984010228e-07, 4.6314994506246876e-07, 7.222019485197961e-05, 0.00012490902736317366, 4.997585165256169e-06, 0.0003066718054469675, 5.749355295847636e-06, 0.0002466128207743168, 0.003777747042477131, 0.0013358069118112326, 0.002113186754286289, 0.8997160792350769, 0.04417850449681282, 0.00033094992977567017, 0.001384939532727003, 0.0003935607383027673, 0.002321055391803384, 0.0004642207932192832, 0.00019271507335361093, 0.0005703868810087442, 5.92765218243585e-06, 2.4687210498086642e-08, 3.108325699940906e-06, 7.16592330718413e-06, 2.9240155186016636e-07, 7.98414257587865e-05, 1.2546398465929087e-05, 0.0001265132159460336, 0.00023837975459173322, 0.0008907333249226213, 0.0014062307309359312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08771783858537674, 0.007821416482329369, 5.662468174705282e-05, 1.4731131869893943e-08, 1.0490747627045494e-05, 0.0011058712843805552, 0.0004291172663215548, 5.523042636923492e-05, 3.919887603842653e-05, 2.7502044304128503e-06, 2.546168616390787e-06, 0.002755208173766732, 0.005722646601498127, 0.0011191918747499585, 0.0015876393299549818, 0.8757357597351074, 0.0010800447780638933, 0.003532156115397811, 0.0015019910642877221, 0.0006949505768716335, 4.3340980482753366e-05, 0.00023435073671862483, 6.934305019967724e-06, 2.7577918615406816e-08, 9.912458835970028e-07, 0.00019156669441144913, 2.9515418646042235e-05, 5.4682345762557816e-06, 2.4805774501146516e-06, 1.4659882481282693e-06, 7.256012395373546e-07, 8.567833720007911e-05, 0.004263886250555515, 0.0007048699189908803, 0.0034579611383378506, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018741462379693985, 0.00013177553773857653, 0.0001151907054008916, 8.336372729900177e-07, 3.8734546592422703e-07, 4.034390804008581e-05, 8.927338058128953e-05, 6.5760018514993135e-06, 6.646589463343844e-05, 2.0145337487065262e-07, 0.00012498503201641142, 0.00022737719700671732, 0.0003596782626118511, 4.087373235961422e-05, 8.65406691445969e-05, 0.00017062197730410844, 0.9720672369003296, 0.004511029925197363, 0.0017741514602676034, 0.00033421185798943043, 0.0006673701573163271, 8.272354534710757e-06, 8.590857760282233e-05, 4.4451999769989925e-07, 1.5395192676237457e-08, 3.916235073120333e-06, 1.856171184044797e-05, 1.744039764162153e-06, 2.306476017110981e-05, 6.561277245964448e-07, 5.5365380831062794e-05, 1.002774115477223e-05, 0.0001100561858038418, 2.098819095408544e-05, 6.0086229495937005e-05, 4.435600567376241e-05, 0.0, 0.0, 0.0, 0.0], [0.021614333614706993, 6.699936784571037e-05, 0.00023382958897855133, 1.946084609016907e-07, 1.0567928256932646e-06, 2.5699444449855946e-05, 0.0002104660088662058, 1.7352494978695177e-06, 6.270136509556323e-06, 8.374804139066327e-08, 2.3547661385237006e-06, 1.8064512914861552e-05, 0.00023376515309792012, 0.001895317924208939, 0.00020409416174516082, 0.0004746883932966739, 0.0029953729826956987, 0.9625540971755981, 0.00691427756100893, 0.00019762477313634008, 0.00011761223140638322, 1.78101454366697e-05, 8.19376073195599e-05, 8.319892685904051e-08, 6.341040403867737e-08, 1.503461476204393e-06, 1.595173125679139e-05, 1.2851933206547983e-07, 7.935282724247372e-07, 1.268652596309039e-07, 5.140130951986066e-07, 3.882859900272706e-08, 5.8853103837464005e-05, 0.0011026777792721987, 9.716644126456231e-05, 8.231291576521471e-05, 0.0007721150759607553, 0.0, 0.0, 0.0], [0.036683231592178345, 5.292119567457121e-06, 1.6796273030195152e-06, 3.2259253601729654e-10, 1.7678923214248243e-08, 9.71175995800877e-06, 6.970066351641435e-06, 3.922034920833539e-06, 1.5272406017174944e-05, 6.423094873753143e-07, 3.0026106401237485e-07, 2.1527788703679107e-05, 8.620285143479123e-07, 2.371107621002011e-05, 1.1333961538184667e-06, 4.370046099211322e-06, 2.1794727217638865e-05, 0.0007244806620292366, 0.9565503597259521, 7.606112922076136e-05, 0.005361164920032024, 3.4096636227332056e-05, 1.4788588487135712e-06, 1.9675812090724776e-09, 6.515209260982147e-09, 7.016106451374071e-07, 1.9081969071521598e-07, 3.605064478051645e-07, 3.97335998059134e-06, 1.5304269709304208e-06, 1.0370927583380762e-07, 7.635036922692962e-07, 1.8985110727953725e-07, 6.1644395827897824e-06, 2.6138322937185876e-06, 1.3529084981200867e-06, 1.0274129635945428e-05, 0.00042383253457956016, 0.0, 0.0], [0.039370130747556686, 0.0003585830272641033, 7.41930998628959e-05, 4.9509686505189165e-05, 4.653078576666303e-06, 4.69761471322272e-05, 0.0002299233601661399, 1.250448349310318e-06, 3.7233094190014526e-05, 8.911907656283802e-08, 7.931947038741782e-05, 0.00013509126438293606, 1.8374801584286615e-05, 0.0001029744089464657, 8.208496728911996e-05, 2.753642911557108e-05, 0.0005808327696286142, 0.001175031648017466, 0.00090598821407184, 0.9545682072639465, 7.417640154017136e-05, 0.0005086685996502638, 0.0001944841060321778, 8.633135439595208e-05, 8.952758889790857e-07, 1.429008443665225e-05, 3.4452030376996845e-05, 2.1258705373838893e-07, 1.695069659035653e-05, 4.816184286937641e-07, 3.1853684049565345e-05, 1.3589491572929546e-05, 2.5087774702114984e-05, 5.98193691985216e-05, 0.00011690238170558587, 1.1342107427481096e-05, 0.0002713192661758512, 0.0002638357982505113, 0.00042731984285637736, 0.0], [0.02540118619799614, 7.441657317031058e-07, 1.083011466107564e-05, 2.249714858848506e-09, 9.22188214680375e-10, 8.20854529592907e-06, 2.5448052838328294e-06, 1.0004332295920904e-07, 3.16087098326534e-05, 2.427833578622085e-07, 5.28918860709382e-07, 1.4262905096984468e-05, 1.5345697192969965e-06, 1.87780551641481e-06, 0.0002028696471825242, 2.141229060725891e-06, 0.00010114459291798994, 0.0009309824672527611, 0.10166086256504059, 5.5514923587907106e-05, 0.8627561926841736, 2.250216311949771e-06, 3.0665501981275156e-05, 5.196882923996782e-09, 3.199170095502524e-11, 8.736409284892943e-08, 1.2241630997777975e-07, 1.2374229418909977e-09, 1.2507468454714399e-05, 4.6357610017366824e-07, 1.629777557354828e-07, 2.719423264352372e-07, 1.1941983757424168e-07, 1.4462457897934655e-07, 5.527898247237317e-05, 3.5639260431707953e-07, 4.93334409839008e-05, 0.00016947872063610703, 0.008456651121377945, 3.8713624235242605e-05]]]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0xffff425c9fd0>"
            ]
          },
          "metadata": {
            "text/html": {
              "Content-Type": "text/html"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "induction_head_layer = 5\n",
        "induction_head_index = 5\n",
        "size = (1, 20)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "single_random_sequence = input_tensor.to(model.cfg.device)\n",
        "repeated_random_sequence = einops.repeat(single_random_sequence, \"batch seq_len -> batch (2 seq_len)\")\n",
        "def visualize_pattern_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    display(\n",
        "        cv.attention.attention_patterns(\n",
        "            tokens=model.to_str_tokens(repeated_random_sequence),\n",
        "            attention=pattern[0, induction_head_index, :, :][None, :, :] # Add a dummy axis, as CircuitsVis expects 3D patterns.\n",
        "        )\n",
        "    )\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_random_sequence,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"pattern\", induction_head_layer),\n",
        "        visualize_pattern_hook\n",
        "    )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSRHlteHTq-Z"
      },
      "source": [
        "## Available Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0hdpfKkTq-Z"
      },
      "source": [
        "TransformerLens comes with over 40 open source models available, all of which can be loaded into a consistent(-ish) architecture by just changing the name in `from_pretrained`. The open source models available are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=jHj79Pj58cgJKdq4t-ygK-4h), and a set of interpretability friendly models I've trained are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=NCJ6zH_Okw_mUYAwGnMKsj2m), including a set of toy language models (tiny one to four layer models) and a set of [SoLU models](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=FZ5W6GGcy6OitPEaO733JLqf) up to GPT-2 Medium size (300M parameters). You can see [a table of the official alias and hyper-parameters of available models here](https://github.com/neelnanda-io/TransformerLens/blob/main/transformer_lens/model_properties_table.md).\n",
        "\n",
        "**Note:** TransformerLens does not currently support multi-GPU models (which you want for models above eg 7B parameters), but this feature is coming soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8uI_eQZTq-Z"
      },
      "source": [
        "\n",
        "Notably, this means that analysis can be near immediately re-run on a different model by just changing the name - to see this, let's load in DistilGPT-2 (a distilled version of GPT-2, with half as many layers) and copy the code from above to see the induction heads in that model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT3JMauYTq-Z",
        "outputId": "a40fc36f-1b54-4dd1-e924-e02ce3bef4cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model distilgpt2 into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "distilgpt2 = HookedTransformer.from_pretrained(\"distilgpt2\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6dhr6i-Tq-a",
        "outputId": "ab7245e7-0e89-486e-bcbe-98e5f83a1705"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"378fa384-2cc7-4a1c-b871-c643c0e527e8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"378fa384-2cc7-4a1c-b871-c643c0e527e8\")) {                    Plotly.newPlot(                        \"378fa384-2cc7-4a1c-b871-c643c0e527e8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009922467172145844,0.00014764934894628823,0.011443736031651497,3.4372510526736733e-06,0.0006867930642329156,5.491139290825231e-06,0.008899171836674213,0.0014873683685436845,0.008349093608558178,0.00954477023333311,0.009120927192270756,0.01596890762448311],[0.003026863094419241,0.018020611256361008,0.003568781539797783,0.0006068727816455066,0.013361244462430477,0.002166191814467311,0.005081023555248976,0.01559095922857523,0.0044562919065356255,8.614760008640587e-05,0.003938235342502594,0.014764327555894852],[0.010219043120741844,0.00780068663880229,0.011151125654578209,0.0025892923586070538,0.019908905029296875,0.005215638317167759,0.00943383015692234,0.0015526963397860527,0.017547965049743652,0.011387993581593037,0.021231677383184433,1.451456820402222e-13],[0.007366393692791462,0.22952795028686523,0.8673726916313171,0.016448020935058594,0.01666181907057762,0.011658817529678345,0.01942884363234043,0.20720870792865753,0.014285862445831299,0.016440654173493385,0.9371501803398132,0.49821725487709045],[0.27513042092323303,0.23388457298278809,0.08511187136173248,0.010210886597633362,0.08357562869787216,0.02389742061495781,0.6404961943626404,0.025386787950992584,0.06823859363794327,0.651100218296051,0.015778401866555214,0.06186722218990326],[0.021418118849396706,0.07837661355733871,0.05457017943263054,0.01195995882153511,0.03577948361635208,0.17681372165679932,0.07745278626680374,0.10316655784845352,0.0073539442382752895,0.4502670466899872,0.19098441302776337,0.029486285522580147]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head in Distil GPT-2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('378fa384-2cc7-4a1c-b871-c643c0e527e8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "distilgpt2_induction_score_store = torch.zeros((distilgpt2.cfg.n_layers, distilgpt2.cfg.n_heads), device=distilgpt2.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    distilgpt2_induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "distilgpt2.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(distilgpt2_induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head in Distil GPT-2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zA-tpEkTq-a"
      },
      "source": [
        "\n",
        "### An overview of the important open source models in the library\n",
        "\n",
        "* **GPT-2** - the classic generative pre-trained models from OpenAI\n",
        "    * Sizes Small (85M), Medium (300M), Large (700M) and XL (1.5B).\n",
        "    * Trained on ~22B tokens of internet text. ([Open source replication](https://huggingface.co/datasets/openwebtext))\n",
        "* **GPT-Neo** - Eleuther's replication of GPT-2\n",
        "    * Sizes 125M, 1.3B, 2.7B\n",
        "    * Trained on 300B(ish?) tokens of [the Pile](https://pile.eleuther.ai/) a large and diverse dataset including a bunch of code (and weird stuff)\n",
        "* **[OPT](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)** - Meta AI's series of open source models\n",
        "    * Trained on 180B tokens of diverse text.\n",
        "    * 125M, 1.3B, 2.7B, 6.7B, 13B, 30B, 66B\n",
        "* **GPT-J** - Eleuther's 6B parameter model, trained on the Pile\n",
        "* **GPT-NeoX** - Eleuther's 20B parameter model, trained on the Pile\n",
        "* **StableLM** - Stability AI's 3B and 7B models, with and without chat and instruction fine-tuning\n",
        "* **Stanford CRFM models** - a replication of GPT-2 Small and GPT-2 Medium, trained on 5 different random seeds.\n",
        "    * Notably, 600 checkpoints were taken during training per model, and these are available in the library with eg `HookedTransformer.from_pretrained(\"stanford-gpt2-small-a\", checkpoint_index=265)`.\n",
        "- **BERT** - Google's bidirectional encoder-only transformer.\n",
        "    - Size Base (108M), trained on English Wikipedia and BooksCorpus.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtfHxbu2Tq-a"
      },
      "source": [
        "\n",
        "### An overview of some interpretability-friendly models I've trained and included\n",
        "\n",
        "(Feel free to [reach out](mailto:neelnanda27@gmail.com) if you want more details on any of these models)\n",
        "\n",
        "Each of these models has about ~200 checkpoints taken during training that can also be loaded from TransformerLens, with the `checkpoint_index` argument to `from_pretrained`.\n",
        "\n",
        "Note that all models are trained with a Beginning of Sequence token, and will likely break if given inputs without that!\n",
        "\n",
        "* **Toy Models**: Inspired by [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), I've trained 12 tiny language models, of 1-4L and each of width 512. I think that interpreting these is likely to be far more tractable than larger models, and both serve as good practice and will likely contain motifs and circuits that generalise to far larger models (like induction heads):\n",
        "    * Attention-Only models (ie without MLPs): attn-only-1l, attn-only-2l, attn-only-3l, attn-only-4l\n",
        "    * GELU models (ie with MLP, and the standard GELU activations): gelu-1l, gelu-2l, gelu-3l, gelu-4l\n",
        "    * SoLU models (ie with MLP, and [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), designed to make MLP neurons more interpretable): solu-1l, solu-2l, solu-3l, solu-4l\n",
        "    * All models are trained on 22B tokens of data, 80% from C4 (web text) and 20% from Python Code\n",
        "    * Models of the same layer size were trained with the same weight initialization and data shuffle, to more directly compare the effect of different activation functions.\n",
        "* **SoLU** models: A larger scan of models trained with [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), in the hopes that it makes the MLP neuron interpretability easier.\n",
        "    * A scan up to GPT-2 Medium size, trained on 30B tokens of the same data as toy models, 80% from C4 and 20% from Python code.\n",
        "        * solu-6l (40M), solu-8l (100M), solu-10l (200M), solu-12l (340M)\n",
        "    * An older scan up to GPT-2 Medium size, trained on 15B tokens of [the Pile](https://pile.eleuther.ai/)\n",
        "        * solu-1l-pile (13M), solu-2l-pile (13M), solu-4l-pile (13M), solu-6l-pile (40M), solu-8l-pile (100M), solu-10l-pile (200M), solu-12l-pile (340M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2e5P0zMTq-a"
      },
      "source": [
        "## Other Resources:\n",
        "\n",
        "* [Concrete Steps to Get Started in Mechanistic Interpretability](https://neelnanda.io/getting-started): A guide I wrote for how to get involved in mechanistic interpretability, and how to learn the basic skills\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer](https://neelnanda.io/glossary): An overview of concepts in the field and surrounding ideas in ML and transformers, with long digressions to give context and build intuitions.\n",
        "* [Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems), a doc I wrote giving a long list of open problems in mechanistic interpretability, and thoughts on how to get started on trying to work on them.\n",
        "    * There's a lot of low-hanging fruit in the field, and I expect that many people reading this could use TransformerLens to usefully make progress on some of these!\n",
        "* Other demos:\n",
        "    * **[Exploratory Analysis Demo](https://neelnanda.io/exploratory-analysis-demo)**, a demonstration of my standard toolkit for how to use TransformerLens to explore a mysterious behaviour in a language model.\n",
        "    * [Interpretability in the Wild](https://github.com/redwoodresearch/Easy-Transformer) a codebase from Arthur Conmy and Alex Variengien at Redwood research using this library to do a detailed and rigorous reverse engineering of the Indirect Object Identification circuit, to accompany their paper\n",
        "        * Note - this was based on an earlier version of this library, called EasyTransformer. It's pretty similar, but several breaking changes have been made since.\n",
        "    * A [recorded walkthrough](https://www.youtube.com/watch?v=yo4QvDn-vsU) of me doing research with TransformerLens on whether a tiny model can re-derive positional information, with [an accompanying Colab](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/No_Position_Experiment.ipynb)\n",
        "* [Neuroscope](https://neuroscope.io), a website showing the text in the dataset that most activates each neuron in some selected models. Good to explore to get a sense for what kind of features the model tends to represent, and as a \"wiki\" to get some info\n",
        "    * A tutorial on how to make an [Interactive Neuroscope](https://github.com/neelnanda-io/TransformerLens/blob/main/Hacky-Interactive-Lexoscope.ipynb), where you type in text and see the neuron activations over the text update live."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxckPTFtTq-a"
      },
      "source": [
        "## Transformer architecture\n",
        "\n",
        "HookedTransformer is a somewhat adapted GPT-2 architecture, but is computationally identical. The most significant changes are to the internal structure of the attention heads:\n",
        "* The weights (W_K, W_Q, W_V) mapping the residual stream to queries, keys and values are 3 separate matrices, rather than big concatenated one.\n",
        "* The weight matrices (W_K, W_Q, W_V, W_O) and activations (keys, queries, values, z (values mixed by attention pattern)) have separate head_index and d_head axes, rather than flattening them into one big axis.\n",
        "    * The activations all have shape `[batch, position, head_index, d_head]`\n",
        "    * W_K, W_Q, W_V have shape `[head_index, d_model, d_head]` and W_O has shape `[head_index, d_head, d_model]`\n",
        "\n",
        "The actual code is a bit of a mess, as there's a variety of Boolean flags to make it consistent with the various different model families in TransformerLens - to understand it and the internal structure, I instead recommend reading the code in [CleanTransformerDemo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4oFv-EgTq-a"
      },
      "source": [
        "### Parameter Names\n",
        "\n",
        "Here is a list of the parameters and shapes in the model. By convention, all weight matrices multiply on the right (ie `new_activation = old_activation @ weights + bias`).\n",
        "\n",
        "Reminder of the key hyper-params:\n",
        "* `n_layers`: 12. The number of transformer blocks in the model (a block contains an attention layer and an MLP layer)\n",
        "* `n_heads`: 12. The number of attention heads per attention layer\n",
        "* `d_model`: 768. The residual stream width.\n",
        "* `d_head`: 64. The internal dimension of an attention head activation.\n",
        "* `d_mlp`: 3072. The internal dimension of the MLP layers (ie the number of neurons).\n",
        "* `d_vocab`: 50267. The number of tokens in the vocabulary.\n",
        "* `n_ctx`: 1024. The maximum number of tokens in an input prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqmj2D-Tq-a"
      },
      "source": [
        "**Transformer Block parameters:**\n",
        "Replace 0 with the relevant layer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dwgO48MTq-a",
        "outputId": "710ff85b-9d8a-47dd-8227-ab796afa7126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if name.startswith(\"blocks.0.\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKbuuqiDTq-a"
      },
      "source": [
        "**Embedding & Unembedding parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_hMZVQzTq-a",
        "outputId": "863b3453-a3dc-44e4-ceda-334dca24385b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"blocks\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKvvizc-Tq-a"
      },
      "source": [
        "### Activation + Hook Names\n",
        "\n",
        "Lets get out a list of the activation/hook names in the model and their shapes. In practice, I recommend using the `utils.get_act_name` function to get the names, but this is a useful fallback, and necessary to eg write a name filter function.\n",
        "\n",
        "Let's do this by entering in a short, 10 token prompt, and add a hook function to each activations to print its name and shape. To avoid spam, let's just add this to activations in the first block or not in a block.\n",
        "\n",
        "Note 1: Each LayerNorm has a hook for the scale factor (ie the standard deviation of the input activations for each token position & batch element) and for the normalized output (ie the input activation with mean 0 and standard deviation 1, but *before* applying scaling or translating with learned weights). LayerNorm is applied every time a layer reads from the residual stream: `ln1` is the LayerNorm before the attention layer in a block, `ln2` the one before the MLP layer, and `ln_final` is the LayerNorm before the unembed.\n",
        "\n",
        "Note 2: *Every* activation apart from the attention pattern and attention scores has shape beginning with `[batch, position]`. The attention pattern and scores have shape `[batch, head_index, dest_position, source_position]` (the numbers are the same, unless we're using caching)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61gim5uUTq-a",
        "outputId": "c86bef8a-777f-4263-a6b0-1f7fa2747240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num tokens: 10\n",
            "hook_embed torch.Size([1, 10, 768])\n",
            "hook_pos_embed torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_pattern torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_z torch.Size([1, 10, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 10, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 10, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 10, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 10, 768])\n",
            "ln_final.hook_scale torch.Size([1, 10, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 10, 768])\n"
          ]
        }
      ],
      "source": [
        "test_prompt = \"The quick brown fox jumped over the lazy dog\"\n",
        "print(\"Num tokens:\", len(model.to_tokens(test_prompt)[0]))\n",
        "\n",
        "def print_name_shape_hook_function(activation, hook):\n",
        "    print(hook.name, activation.shape)\n",
        "\n",
        "not_in_late_block_filter = lambda name: name.startswith(\"blocks.0.\") or not name.startswith(\"blocks\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    test_prompt,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(not_in_late_block_filter, print_name_shape_hook_function)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRHC7oqDTq-a"
      },
      "source": [
        "### Folding LayerNorm (For the Curious)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_gpMY3KTq-a"
      },
      "source": [
        "(For the curious - this is an important technical detail that's worth understanding, especially if you have preconceptions about how transformers work, but not necessary to use TransformerLens)\n",
        "\n",
        "LayerNorm is a normalization technique used by transformers, analogous to BatchNorm but more friendly to massive parallelisation. No one *really* knows why it works, but it seems to improve model numerical stability. Unlike BatchNorm, LayerNorm actually changes the functional form of the model, which makes it a massive pain for interpretability!\n",
        "\n",
        "Folding LayerNorm is a technique to make it lower overhead to deal with, and the flags `center_writing_weights` and `fold_ln` in `HookedTransformer.from_pretrained` apply this automatically (they default to True). These simplify the internal structure without changing the weights.\n",
        "\n",
        "Intuitively, LayerNorm acts on each residual stream vector (ie for each batch element and token position) independently, sets their mean to 0 (centering) and standard deviation to 1 (normalizing) (*across* the residual stream dimension - very weird!), and then applies a learned elementwise scaling and translation to each vector.\n",
        "\n",
        "Mathematically, centering is a linear map, normalizing is *not* a linear map, and scaling and translation are linear maps.\n",
        "* **Centering:** LayerNorm is applied every time a layer reads from the residual stream, so the mean of any residual stream vector can never matter - `center_writing_weights` set every weight matrix writing to the residual to have zero mean.\n",
        "* **Normalizing:** Normalizing is not a linear map, and cannot be factored out. The `hook_scale` hook point lets you access and control for this.\n",
        "* **Scaling and Translation:** Scaling and translation are linear maps, and are always followed by another linear map. The composition of two linear maps is another linear map, so we can *fold* the scaling and translation weights into the weights of the subsequent layer, and simplify things without changing the underlying computation.\n",
        "\n",
        "[See the docs for more details](https://github.com/neelnanda-io/TransformerLens/blob/main/further_comments.md#what-is-layernorm-folding-fold_ln)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbcFo1wOTq-a"
      },
      "source": [
        "A fun consequence of LayerNorm folding is that it creates a bias across the unembed, a `d_vocab` length vector that is added to the output logits - GPT-2 is not trained with this, but it *is* trained with a final LayerNorm that contains a bias.\n",
        "\n",
        "Turns out, this LayerNorm bias learns structure of the data that we can only see after folding! In particular, it essentially learns **unigram statistics** - rare tokens get suppressed, common tokens get boosted, by pretty dramatic degrees! Let's list the top and bottom 20 - at the top we see common punctuation and words like \" the\" and \" and\", at the bottom we see weird-ass tokens like \" RandomRedditor\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM9N-QLETq-a"
      },
      "outputs": [],
      "source": [
        "unembed_bias = model.unembed.b_U\n",
        "bias_values, bias_indices = unembed_bias.sort(descending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhp4tNykTq-a",
        "outputId": "03cd856c-94aa-475c-beda-1f7f7048d733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 values\n",
            "7.03 ','\n",
            "6.98 ' the'\n",
            "6.68 ' and'\n",
            "6.49 '.'\n",
            "6.48 '\\n'\n",
            "6.47 ' a'\n",
            "6.41 ' in'\n",
            "6.25 ' to'\n",
            "6.16 ' of'\n",
            "6.04 '-'\n",
            "6.03 ' ('\n",
            "5.88 ' \"'\n",
            "5.80 ' for'\n",
            "5.72 ' that'\n",
            "5.64 ' on'\n",
            "5.59 ' is'\n",
            "5.52 ' as'\n",
            "5.49 ' at'\n",
            "5.45 ' with'\n",
            "5.44 ' or'\n",
            "...\n",
            "Bottom 20 values\n",
            "-3.82 ' サーティ'\n",
            "-3.83 '\\x18'\n",
            "-3.83 '\\x14'\n",
            "-3.83 ' RandomRedditor'\n",
            "-3.83 '龍�'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x1b'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x05'\n",
            "-3.83 '\\x00'\n",
            "-3.83 '\\x06'\n",
            "-3.83 '\\x07'\n",
            "-3.83 '\\x0c'\n",
            "-3.83 '\\x02'\n",
            "-3.83 'oreAndOnline'\n",
            "-3.84 '\\x11'\n",
            "-3.84 '�'\n",
            "-3.84 '\\x10'\n",
            "-3.84 '�'\n",
            "-3.84 '�'\n"
          ]
        }
      ],
      "source": [
        "top_k = 20\n",
        "print(f\"Top {top_k} values\")\n",
        "for i in range(top_k):\n",
        "    print(f\"{bias_values[i].item():.2f} {repr(model.to_string(bias_indices[i]))}\")\n",
        "\n",
        "print(\"...\")\n",
        "print(f\"Bottom {top_k} values\")\n",
        "for i in range(top_k, 0, -1):\n",
        "    print(f\"{bias_values[-i].item():.2f} {repr(model.to_string(bias_indices[-i]))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8c8THjdTq-b"
      },
      "source": [
        "This can have real consequences for interpretability - for example, this bias favours \" John\" over \" Mary\" by about 1.2, about 1/3 of the effect size of the Indirect Object Identification Circuit! All other things being the same, this makes the John token 3.6x times more likely than the Mary token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3seWR67hTq-b",
        "outputId": "d10f3134-488a-480e-a72f-a9e65ad69fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "John bias: 2.8995\n",
            "Mary bias: 1.6034\n",
            "Prob ratio bias: 3.6550x\n"
          ]
        }
      ],
      "source": [
        "john_bias = model.unembed.b_U[model.to_single_token(' John')]\n",
        "mary_bias = model.unembed.b_U[model.to_single_token(' Mary')]\n",
        "\n",
        "print(f\"John bias: {john_bias.item():.4f}\")\n",
        "print(f\"Mary bias: {mary_bias.item():.4f}\")\n",
        "print(f\"Prob ratio bias: {torch.exp(john_bias - mary_bias).item():.4f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXceBi40Tq-b"
      },
      "source": [
        "# Features\n",
        "\n",
        "An overview of some other important features of the library. I recommend checking out the [Exploratory Analysis Demo](https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/main/Exploratory_Analysis_Demo.ipynb) for some other important features not mentioned here, and for a demo of what using the library in practice looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF45BH3KTq-c"
      },
      "source": [
        "## Dealing with tokens\n",
        "\n",
        "**Tokenization** is one of the most annoying features of studying language models. We want language models to be able to take in arbitrary text as input, but the transformer architecture needs the inputs to be elements of a fixed, finite vocabulary. The solution to this is **tokens**, a fixed vocabulary of \"sub-words\", that any natural language can be broken down into with a **tokenizer**. This is invertible, and we can recover the original text, called **de-tokenization**.\n",
        "\n",
        "TransformerLens comes with a range of utility functions to deal with tokenization. Different models can have different tokenizers, so these are all methods on the model.\n",
        "\n",
        "get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnAXSUUeTq-c"
      },
      "source": [
        "The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n",
        "\n",
        "Some observations - there are a lot of arbitrary-ish details in here!\n",
        "* The tokenizer splits on spaces, so no token contains two words.\n",
        "* Tokens include the preceding space, and whether the first token is a capital letter. `how` and ` how` are different tokens!\n",
        "* Common words are single tokens, even if fairly long (` paragraph`) while uncommon words are split into multiple tokens (` token|ized`).\n",
        "* Tokens *mostly* split on punctuation characters (eg `*` and `.`), but eg `'s` is a single token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEF3kZKVTq-c",
        "outputId": "81837682-5ea1-426c-b994-ec225eab80e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', 'The', ' first', ' thing', ' you', ' need', ' to', ' figure', ' out', ' is', ' *', 'how', '*', ' things', ' are', ' token', 'ized', '.', ' `', 'model', '.', 'to', '_', 'str', '_', 't', 'ok', 'ens', '`', ' splits', ' a', ' string', ' into', ' the', ' tokens', ' *', 'as', ' a', ' list', ' of', ' sub', 'strings', '*,', ' and', ' so', ' lets', ' you', ' explore', ' what', ' the', ' text', ' looks', ' like', '.', ' To', ' demonstrate', ' this', ',', ' let', \"'s\", ' use', ' it', ' on', ' this', ' paragraph', '.']\n"
          ]
        }
      ],
      "source": [
        "example_text = \"The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\"\n",
        "example_text_str_tokens = model.to_str_tokens(example_text)\n",
        "print(example_text_str_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Yomf61Tq-c"
      },
      "source": [
        "The transformer needs to take in a sequence of integers, not strings, so we need to convert these tokens into integers. `model.to_tokens` does this, and returns a tensor of integers on the model's device (shape `[batch, position]`). It maps a string to a batch of size 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YkDWE1PTq-c",
        "outputId": "cada84e3-7197-4a5a-cc71-59c56afb5d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,   464,   717,  1517,   345,   761,   284,  3785,   503,   318,\n",
            "          1635,  4919,     9,  1243,   389, 11241,  1143,    13,  4600, 19849,\n",
            "            13,  1462,    62,  2536,    62,    83,   482,   641,    63, 30778,\n",
            "           257,  4731,   656,   262, 16326,  1635,   292,   257,  1351,   286,\n",
            "           850, 37336, 25666,   290,   523,  8781,   345,  7301,   644,   262,\n",
            "          2420,  3073,   588,    13,  1675, 10176,   428,    11,  1309,   338,\n",
            "           779,   340,   319,   428,  7322,    13]])\n"
          ]
        }
      ],
      "source": [
        "example_text_tokens = model.to_tokens(example_text)\n",
        "print(example_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-zHAljGTq-c"
      },
      "source": [
        "`to_tokens` can also take in a list of strings, and return a batch of size `len(strings)`. If the strings are different numbers of tokens, it adds a PAD token to the end of the shorter strings to make them the same length.\n",
        "\n",
        "(Note: In GPT-2, 50256 signifies both the beginning of sequence, end of sequence and padding token - see the `prepend_bos` section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00CxRey6Tq-c",
        "outputId": "e3c40140-4a69-4425-ced1-d13fd48f3d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,   464,  3797,  3332,   319,   262,  2603,    13, 50256, 50256],\n",
            "        [50256,   464,  3797,  3332,   319,   262,  2603,  1107,  1327,    13]])\n"
          ]
        }
      ],
      "source": [
        "example_multi_text = [\"The cat sat on the mat.\", \"The cat sat on the mat really hard.\"]\n",
        "example_multi_text_tokens = model.to_tokens(example_multi_text)\n",
        "print(example_multi_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JDohcXNTq-c"
      },
      "source": [
        "`model.to_single_token` is a convenience function that takes in a string corresponding to a *single* token and returns the corresponding integer. This is useful for eg looking up the logit corresponding to a single token.\n",
        "\n",
        "For example, let's input `The cat sat on the mat.` to GPT-2, and look at the log prob predicting that the next token is ` The`.\n",
        "\n",
        "<details><summary>Technical notes</summary>\n",
        "\n",
        "Note that if we input a string to the model, it's implicitly converted to a string with `to_tokens`.\n",
        "\n",
        "Note further that the log probs have shape `[batch, position, d_vocab]==[1, 8, 50257]`, with a vector of log probs predicting the next token for *every* token position. GPT-2 uses causal attention which means heads can only look backwards (equivalently, information can only move forwards in the model.), so the log probs at position k are only a function of the first k tokens, and it can't just cheat and look at the k+1 th token. This structure lets it generate text more efficiently, and lets it treat every *token* as a training example, rather than every *sequence*.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts60yLebTq-c",
        "outputId": "5ef9aab3-28d6-40ab-bc22-be5e53922de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability tensor shape [batch, position, d_vocab] == torch.Size([1, 8, 50257])\n",
            "| The| probability: 11.98%\n"
          ]
        }
      ],
      "source": [
        "cat_text = \"The cat sat on the mat.\"\n",
        "cat_logits = model(cat_text)\n",
        "cat_probs = cat_logits.softmax(dim=-1)\n",
        "print(f\"Probability tensor shape [batch, position, d_vocab] == {cat_probs.shape}\")\n",
        "\n",
        "capital_the_token_index = model.to_single_token(\" The\")\n",
        "print(f\"| The| probability: {cat_probs[0, -1, capital_the_token_index].item():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9_ScaNxTq-d"
      },
      "source": [
        "`model.to_string` is the inverse of `to_tokens` and maps a tensor of integers to a string or list of strings. It also works on integers and lists of integers.\n",
        "\n",
        "For example, let's look up token 256 (due to technical details of tokenization, this will be the most common pair of ASCII characters!), and also verify that our tokens above map back to a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytJMGAQ0Tq-d",
        "outputId": "331d3896-0b08-4dd4-b5d0-b6726dad6466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bdVBvacTq-d"
      },
      "source": [
        "A related annoyance of tokenization is that it's hard to figure out how many tokens a string will break into. `model.get_token_position(single_token, tokens)` returns the position of `single_token` in `tokens`. `tokens` can be either a string or a tensor of tokens.\n",
        "\n",
        "Note that position is zero-indexed, it's two (ie third) because there's a beginning of sequence token automatically prepended (see the next section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvx6focfTq-d",
        "outputId": "fb1307f0-3fae-4b42-fc81-4f9f027561ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With BOS: 2\n",
            "Without BOS: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"With BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\"))\n",
        "print(\"Without BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVeKqHsWTq-d"
      },
      "source": [
        "If there are multiple copies of the token, we can set `mode=\"first\"` to find the first occurence's position and `mode=\"last\"` to find the last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwXXRIMwTq-d",
        "outputId": "3c463933-1a42-4bcc-e81c-5e11cbf00261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First occurence 2\n",
            "Final occurence 13\n"
          ]
        }
      ],
      "source": [
        "print(\"First occurence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"first\"))\n",
        "print(\"Final occurence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"last\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGWCtsq-Tq-d"
      },
      "source": [
        "In general, tokenization is a pain, and full of gotchas. I highly recommend just playing around with different inputs and their tokenization and getting a feel for it. As another \"fun\" example, let's look at the tokenization of arithmetic expressions - tokens do *not* contain consistent numbers of digits. (This makes it even more impressive that GPT-3 can do arithmetic!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thNk8sWyTq-d",
        "outputId": "54a67006-2ff8-4beb-c7ea-def800852846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', '23', '42', '+', '2017', '=', '214', '45']\n",
            "['<|endoftext|>', '1000', '+', '1', '000000', '=', '9999', '99']\n"
          ]
        }
      ],
      "source": [
        "print(model.to_str_tokens(\"2342+2017=21445\"))\n",
        "print(model.to_str_tokens(\"1000+1000000=999999\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ2-jokXTq-d"
      },
      "source": [
        "I also *highly* recommend investigating prompts with easy tokenization when starting out - ideally key words should form a single token, be in the same position in different prompts, have the same total length, etc. Eg study Indirect Object Identification with common English names like ` Tim` rather than ` Ne|el`. Transformers need to spend some parameters in early layers converting multi-token words to a single feature, and then de-converting this in the late layers, and unless this is what you're explicitly investigating, this will make the behaviour you're investigating be messier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_eK-vcwTq-d"
      },
      "source": [
        "### Gotcha: `prepend_bos`\n",
        "\n",
        "Key Takeaway: **If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4JQBLhaTq-d"
      },
      "source": [
        "A weirdness you may have noticed in the above is that `to_tokens` and `to_str_tokens` added a weird `<|endoftext|>` to the start of each prompt. TransformerLens does this by default, and it can easily trip up new users. Notably, **this includes `model.forward`** (which is what's implicitly used when you do eg `model(\"Hello World\")`). This is called a **Beginning of Sequence (BOS)** token, and it's a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
        "\n",
        "**Gotcha:** You only want to prepend a BOS token at the *start* of a prompt. If you, eg, want to input a question followed by an answer, and want to tokenize these separately, you do *not* want to prepend_bos on the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQgVTVtaTq-d",
        "outputId": "c024f337-ef82-4b0f-f7a7-cd3fbf7f577e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape by default (with BOS) torch.Size([1, 3, 50257])\n",
            "Logits shape with BOS torch.Size([1, 3, 50257])\n",
            "Logits shape without BOS - only 2 positions! torch.Size([1, 2, 50257])\n"
          ]
        }
      ],
      "source": [
        "print(\"Logits shape by default (with BOS)\", model(\"Hello World\").shape)\n",
        "print(\"Logits shape with BOS\", model(\"Hello World\", prepend_bos=True).shape)\n",
        "print(\"Logits shape without BOS - only 2 positions!\", model(\"Hello World\", prepend_bos=False).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qvSgY3ITq-d"
      },
      "source": [
        "`prepend_bos` is a bit of a hack, and I've gone back and forth on what the correct default here is. The reason I do this is that transformers tend to treat the first token weirdly - this doesn't really matter in training (where all inputs are >1000 tokens), but this can be a big issue when investigating short prompts! The reason for this is that attention patterns are a probability distribution and so need to add up to one, so to simulate being \"off\" they normally look at the first token. Giving them a BOS token lets the heads rest by looking at that, preserving the information in the first \"real\" token.\n",
        "\n",
        "Further, *some* models are trained to need a BOS token (OPT and my interpretability-friendly models are, GPT-2 and GPT-Neo are not). But despite GPT-2 not being trained with this, empirically it seems to make interpretability easier.\n",
        "\n",
        "(However, if you want to change the default behaviour to *not* prepending a BOS token, pass `default_prepend_bos=False` when you instantiate the model, e.g., `model = HookedTransformer.from_pretrained('gpt2', default_prepend_bos=False)`.)\n",
        "\n",
        "For example, the model can get much worse at Indirect Object Identification without a BOS (and with a name as the first token):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9G0gY4pTq-d",
        "outputId": "9ff3c8d4-338b-4f1e-9bdb-602f0f63e8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logit difference with BOS: 6.754\n",
            "Logit difference without BOS: 2.782\n"
          ]
        }
      ],
      "source": [
        "ioi_logits_with_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=True)\n",
        "mary_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference with BOS: {(claire_logit_with_bos - mary_logit_with_bos):.3f}\")\n",
        "\n",
        "ioi_logits_without_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=False)\n",
        "mary_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference without BOS: {(claire_logit_without_bos - mary_logit_without_bos):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lrWkqhLTq-d"
      },
      "source": [
        "Though, note that this also illustrates another gotcha - when `Claire` is at the start of a sentence (no preceding space), it's actually *two* tokens, not one, which probably confuses the relevant circuit. (Note - in this test we put `prepend_bos=False`, because we want to analyse the tokenization of a specific string, not to give an input to the model!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kJJe4_MTq-d",
        "outputId": "93ea5ae5-19c5-49c4-cec8-06fcfafbbcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Claire| -> [' Claire']\n",
            "|Claire| -> ['Cl', 'aire']\n"
          ]
        }
      ],
      "source": [
        "print(f\"| Claire| -> {model.to_str_tokens(' Claire', prepend_bos=False)}\")\n",
        "print(f\"|Claire| -> {model.to_str_tokens('Claire', prepend_bos=False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rMPjpxKTq-d"
      },
      "source": [
        "## Factored Matrix Class\n",
        "\n",
        "In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers, and the `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, such as computing the trace, eigenvalues, Frobenius norm, singular value decomposition, and products with other matrices. It can (approximately) act as a drop-in replacement for the original matrix, and supports leading batch dimensions to the factored matrix.\n",
        "\n",
        "<details><summary>Why are low-rank factorized matrices useful for transformer interpretability?</summary>\n",
        "\n",
        "As argued in [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), an unexpected fact about transformer attention heads is that rather than being best understood as keys, queries and values (and the requisite weight matrices), they're actually best understood as two low rank factorized matrices.\n",
        "* **Where to move information from:** $W_QK = W_Q W_K^T$, used for determining the attention pattern - what source positions to move information from and what destination positions to move them to.\n",
        "    * Intuitively, residual stream -> query and residual stream -> key are linear maps, *and* `attention_score = query @ key.T` is a linear map, so the whole thing can be factored into one big bilinear form `residual @ W_QK @ residual.T`\n",
        "* **What information to move:** $W_OV = W_V W_O$, used to determine what information to copy from the source position to the destination position (weighted by the attention pattern weight from that destination to that source).\n",
        "    * Intuitively, the residual stream is a `[position, d_model]` tensor (ignoring batch). The attention pattern acts on the *position* dimension (where to move information from and to) and the value and output weights act on the *d_model* dimension - ie *what* information is contained at that source position. So we can factor it all into `attention_pattern @ residual @ W_V @ W_O`, and so only need to care about `W_OV = W_V @ W_O`\n",
        "* Note - the internal head dimension is smaller than the residual stream dimension, so the factorization is low rank. (here, `d_model=768` and `d_head=64`)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwY9WqqTq-d"
      },
      "source": [
        "### Basic Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cH9hEbkTq-d"
      },
      "source": [
        "We can use the basic class directly - let's make a factored matrix directly and look at the basic operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIkSFOlZTq-d",
        "outputId": "8a95d640-0596-48ac-c338-8bb6e0899b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norms:\n",
            "tensor(9.9105)\n",
            "tensor(9.9105)\n",
            "Right dimension: 5, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "A = torch.randn(5, 2)\n",
        "B = torch.randn(2, 5)\n",
        "\n",
        "AB = A @ B\n",
        "AB_factor = FactoredMatrix(A, B)\n",
        "print(\"Norms:\")\n",
        "print(AB.norm())\n",
        "print(AB_factor.norm())\n",
        "\n",
        "print(f\"Right dimension: {AB_factor.rdim}, Left dimension: {AB_factor.ldim}, Hidden dimension: {AB_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdWVKe-oTq-d"
      },
      "source": [
        "We can also look at the eigenvalues and singular values of the matrix. Note that, because the matrix is rank 2 but 5 by 5, the final 3 eigenvalues and singular values are zero - the factored class omits the zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAq9ENJTTq-e",
        "outputId": "af825fae-2d47-4723-f1e7-be53b6873139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eigenvalues:\n",
            "tensor([-6.2877e+00+0.j,  1.9337e-07+0.j,  2.3121e+00+0.j, -5.9987e-07+0.j,\n",
            "        -1.1409e-07+0.j])\n",
            "tensor([-6.2877+0.j,  2.3121+0.j])\n",
            "\n",
            "Singular Values:\n",
            "tensor([8.3126e+00, 5.3963e+00, 1.4519e-07, 7.4293e-08, 2.1726e-09])\n",
            "tensor([8.3126, 5.3963])\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "print(\"Eigenvalues:\")\n",
        "print(torch.linalg.eig(AB).eigenvalues)\n",
        "print(AB_factor.eigenvalues)\n",
        "print()\n",
        "print(\"Singular Values:\")\n",
        "print(torch.linalg.svd(AB).S)\n",
        "print(AB_factor.S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orDORw4qTq-e"
      },
      "source": [
        "We can multiply with other matrices - it automatically chooses the smallest possible dimension to factor along (here it's 2, rather than 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cLVxLhRTq-e",
        "outputId": "c5583185-dea2-4de9-ecc6-4598ac694501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfactored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Factored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Right dimension: 300, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "C = torch.randn(5, 300)\n",
        "\n",
        "ABC = AB @ C\n",
        "ABC_factor = AB_factor @ C\n",
        "print(\"Unfactored:\", ABC.shape, ABC.norm().round(decimals=3))\n",
        "print(\"Factored:\", ABC_factor.shape, ABC_factor.norm().round(decimals=3))\n",
        "print(f\"Right dimension: {ABC_factor.rdim}, Left dimension: {ABC_factor.ldim}, Hidden dimension: {ABC_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfkSxkxTq-e"
      },
      "source": [
        "If we want to collapse this back to an unfactored matrix, we can use the AB property to get the product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvf9I_3YTq-e",
        "outputId": "bf9b150a-305d-4a72-97b6-a3c188feb330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "AB_unfactored = AB_factor.AB\n",
        "print(torch.isclose(AB_unfactored, AB).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIkT9kXTq-e"
      },
      "source": [
        "### Medium Example: Eigenvalue Copying Scores\n",
        "\n",
        "(This is a more involved example of how to use the factored matrix class, skip it if you aren't following)\n",
        "\n",
        "For a more involved example, let's look at the eigenvalue copying score from [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html) of the OV circuit for various heads. The OV Circuit for a head (the factorised matrix $W_OV = W_V W_O$) is a linear map that determines what information is moved from the source position to the destination position. Because this is low rank, it can be thought of as *reading in* some low rank subspace of the source residual stream and *writing to* some low rank subspace of the destination residual stream (with maybe some processing happening in the middle).\n",
        "\n",
        "A common operation for this will just be to *copy*, ie to have the same reading and writing subspace, and to do minimal processing in the middle. Empirically, this tends to coincide with the OV Circuit having (approximately) positive real eigenvalues. I mostly assert this as an empirical fact, but intuitively, operations that involve mapping eigenvectors to different directions (eg rotations) tend to have complex eigenvalues. And operations that preserve eigenvector direction but negate it tend to have negative real eigenvalues. And \"what happens to the eigenvectors\" is a decent proxy for what happens to an arbitrary vector.\n",
        "\n",
        "We can get a score for \"how positive real the OV circuit eigenvalues are\" with $\\frac{\\sum \\lambda_i}{\\sum |\\lambda_i|}$, where $\\lambda_i$ are the eigenvalues of the OV circuit. This is a bit of a hack, but it seems to work well in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRf46ozbTq-e"
      },
      "source": [
        "Let's use FactoredMatrix to compute this for every head in the model! We use the helper `model.OV` to get the concatenated OV circuits for all heads across all layers in the model. This has the shape `[n_layers, n_heads, d_model, d_model]`, where `n_layers` and `n_heads` are batch dimensions and the final two dimensions are factorised as `[n_layers, n_heads, d_model, d_head]` and `[n_layers, n_heads, d_head, d_model]` matrices.\n",
        "\n",
        "We can then get the eigenvalues for this, where there are separate eigenvalues for each element of the batch (a `[n_layers, n_heads, d_head]` tensor of complex numbers), and calculate the copying score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzLXbgcGTq-e",
        "outputId": "fc4a319a-5b12-48c5-ce3f-39c91ab09d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 768, 768])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads = model.OV\n",
        "print(OV_circuit_all_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHCmbL8dTq-e",
        "outputId": "cf230b73-5503-41c0-f85d-365c62ecffe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads_eigenvalues = OV_circuit_all_heads.eigenvalues\n",
        "print(OV_circuit_all_heads_eigenvalues.shape)\n",
        "print(OV_circuit_all_heads_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afg3UwtpTq-e",
        "outputId": "5347e52e-3780-4279-8a04-80fe5000a7ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a09834af-1357-479f-b958-ca36d205cbf8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a09834af-1357-479f-b958-ca36d205cbf8\")) {                    Plotly.newPlot(                        \"a09834af-1357-479f-b958-ca36d205cbf8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353],[-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801],[-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453],[0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517],[0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477],[0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559],[0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053],[0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916],[-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563],[0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555],[0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959],[0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a09834af-1357-479f-b958-ca36d205cbf8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "OV_copying_score = OV_circuit_all_heads_eigenvalues.sum(dim=-1).real / OV_circuit_all_heads_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoBZB3O4Tq-e"
      },
      "source": [
        "Head 11 in Layer 11 (L11H11) has a high copying score, and if we plot the eigenvalues they look approximately as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvqL_l9PTq-e",
        "outputId": "f7f9d017-1531-40f6-eaba-6e212f143019"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\")) {                    Plotly.newPlot(                        \"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\",                        [{\"hovertemplate\":\"Real=%{x}\\u003cbr\\u003eImaginary=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.1397297382354736,1.4152636528015137,3.444455146789551,4.027669906616211,8.882655143737793,4.866769790649414,4.866769790649414,4.843714714050293,4.843714714050293,8.477535247802734,8.216809272766113,8.216809272766113,5.07860803604126,7.855461120605469,7.855461120605469,5.365756034851074,5.365756034851074,5.563426971435547,5.563426971435547,5.4217329025268555,7.769133567810059,7.769133567810059,7.0422773361206055,7.0422773361206055,5.675145626068115,5.675145626068115,7.678577423095703,7.678577423095703,6.573329925537109,6.573329925537109,7.67294979095459,7.17219877243042,7.17219877243042,7.423620223999023,7.423620223999023,7.470810413360596,6.089095115661621,6.089095115661621,6.306834697723389,6.306834697723389,6.511750221252441,6.511750221252441,5.955246448516846,5.955246448516846,5.858811378479004,5.858811378479004,7.147887229919434,7.147887229919434,7.185712814331055,7.185712814331055,6.670608043670654,6.670608043670654,6.735983848571777,6.735983848571777,6.149757385253906,6.149757385253906,6.288776874542236,6.288776874542236,6.344796657562256,6.625571250915527,6.625571250915527,6.8991899490356445,6.8991899490356445,6.85640811920166],\"xaxis\":\"x\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.4185231328010559,-0.4185231328010559,0.09079001098871231,-0.09079001098871231,0.0,0.40868881344795227,-0.40868881344795227,0.0,0.7007214426994324,-0.7007214426994324,0.46421411633491516,-0.46421411633491516,0.5558239817619324,-0.5558239817619324,0.0,0.4705662131309509,-0.4705662131309509,1.0298681259155273,-1.0298681259155273,0.48253530263900757,-0.48253530263900757,0.3356489837169647,-0.3356489837169647,0.9988697171211243,-0.9988697171211243,0.0,0.7531778812408447,-0.7531778812408447,0.4257569909095764,-0.4257569909095764,0.0,0.643626868724823,-0.643626868724823,0.7701709270477295,-0.7701709270477295,0.7558017373085022,-0.7558017373085022,0.25911131501197815,-0.25911131501197815,0.013043955899775028,-0.013043955899775028,0.40166252851486206,-0.40166252851486206,0.28192126750946045,-0.28192126750946045,0.6146255135536194,-0.6146255135536194,0.5391282439231873,-0.5391282439231873,0.28234055638313293,-0.28234055638313293,0.3528330624103546,-0.3528330624103546,0.0,0.24867765605449677,-0.24867765605449677,0.15545639395713806,-0.15545639395713806,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Real\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Imaginary\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Eigenvalues of Head L11H11 of GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e3711f8-c7bc-42a1-aea4-6c909a93f24e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=OV_circuit_all_heads_eigenvalues[-1, -1, :].real, y=OV_circuit_all_heads_eigenvalues[-1, -1, :].imag, title=\"Eigenvalues of Head L11H11 of GPT-2 Small\", xaxis=\"Real\", yaxis=\"Imaginary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S32UppOvTq-e"
      },
      "source": [
        "We can even look at the full OV circuit, from the input tokens to output tokens: $W_E W_V W_O W_U$. This is a `[d_vocab, d_vocab]==[50257, 50257]` matrix, so absolutely enormous, even for a single head. But with the FactoredMatrix class, we can compute the full eigenvalue copying score of every head in a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHJZx9HgTq-e",
        "outputId": "b3cc8980-ce6e-4a2c-a7bb-4107aa9fc298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 50257, 50257])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit = model.embed.W_E @ OV_circuit_all_heads @ model.unembed.W_U\n",
        "print(full_OV_circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WhHt-itTq-e",
        "outputId": "1111358a-b4df-4b70-d8d5-20e0164ea889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit_eigenvalues = full_OV_circuit.eigenvalues\n",
        "print(full_OV_circuit_eigenvalues.shape)\n",
        "print(full_OV_circuit_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqCFb6IMTq-e",
        "outputId": "ce586355-9764-416d-d5ea-9eac092abf03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\")) {                    Plotly.newPlot(                        \"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262],[-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352],[-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857],[0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744],[0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906],[0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618],[0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554],[0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686],[-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529],[0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375],[0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871],[0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c709dad6-6ca6-4c75-8231-0ee7b1e7e752');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "full_OV_copying_score = full_OV_circuit_eigenvalues.sum(dim=-1).real / full_OV_circuit_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(full_OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abWqCiP-Tq-e"
      },
      "source": [
        "Interestingly, these are highly (but not perfectly!) correlated. I'm not sure what to read from this, or what's up with the weird outlier heads!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xrfDZXgTq-e",
        "outputId": "2e9dc320-04db-4c87-fd45-117b3bf214da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\")) {                    Plotly.newPlot(                        \"3e59929d-31e9-49b1-ad1a-9d9811d4801d\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eFull OV Copying Score=%{x}\\u003cbr\\u003eOV Copying Score=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L0H8\",\"L0H9\",\"L0H10\",\"L0H11\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\",\"L1H8\",\"L1H9\",\"L1H10\",\"L1H11\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2H4\",\"L2H5\",\"L2H6\",\"L2H7\",\"L2H8\",\"L2H9\",\"L2H10\",\"L2H11\",\"L3H0\",\"L3H1\",\"L3H2\",\"L3H3\",\"L3H4\",\"L3H5\",\"L3H6\",\"L3H7\",\"L3H8\",\"L3H9\",\"L3H10\",\"L3H11\",\"L4H0\",\"L4H1\",\"L4H2\",\"L4H3\",\"L4H4\",\"L4H5\",\"L4H6\",\"L4H7\",\"L4H8\",\"L4H9\",\"L4H10\",\"L4H11\",\"L5H0\",\"L5H1\",\"L5H2\",\"L5H3\",\"L5H4\",\"L5H5\",\"L5H6\",\"L5H7\",\"L5H8\",\"L5H9\",\"L5H10\",\"L5H11\",\"L6H0\",\"L6H1\",\"L6H2\",\"L6H3\",\"L6H4\",\"L6H5\",\"L6H6\",\"L6H7\",\"L6H8\",\"L6H9\",\"L6H10\",\"L6H11\",\"L7H0\",\"L7H1\",\"L7H2\",\"L7H3\",\"L7H4\",\"L7H5\",\"L7H6\",\"L7H7\",\"L7H8\",\"L7H9\",\"L7H10\",\"L7H11\",\"L8H0\",\"L8H1\",\"L8H2\",\"L8H3\",\"L8H4\",\"L8H5\",\"L8H6\",\"L8H7\",\"L8H8\",\"L8H9\",\"L8H10\",\"L8H11\",\"L9H0\",\"L9H1\",\"L9H2\",\"L9H3\",\"L9H4\",\"L9H5\",\"L9H6\",\"L9H7\",\"L9H8\",\"L9H9\",\"L9H10\",\"L9H11\",\"L10H0\",\"L10H1\",\"L10H2\",\"L10H3\",\"L10H4\",\"L10H5\",\"L10H6\",\"L10H7\",\"L10H8\",\"L10H9\",\"L10H10\",\"L10H11\",\"L11H0\",\"L11H1\",\"L11H2\",\"L11H3\",\"L11H4\",\"L11H5\",\"L11H6\",\"L11H7\",\"L11H8\",\"L11H9\",\"L11H10\",\"L11H11\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262,-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352,-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857,0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744,0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906,0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618,0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554,0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686,-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529,0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375,0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871,0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334],\"xaxis\":\"x\",\"y\":[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353,-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801,-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453,0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517,0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477,0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559,0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053,0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916,-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563,0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555,0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959,0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Full OV Copying Score\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OV Copying Score\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3e59929d-31e9-49b1-ad1a-9d9811d4801d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=full_OV_copying_score.flatten(), y=OV_copying_score.flatten(), hover_name=[f\"L{layer}H{head}\" for layer in range(12) for head in range(12)], title=\"OV Copying Score for each head in GPT-2 Small\", xaxis=\"Full OV Copying Score\", yaxis=\"OV Copying Score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsklWKQqTq-e",
        "outputId": "87f56a23-ae54-4b3a-de16-b0b1902406fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTbLGrEaTq-f"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHds87l0Tq-f"
      },
      "source": [
        "TransformerLens also has basic text generation functionality, which can be useful for generally exploring what the model is capable of (thanks to Ansh Radhakrishnan for adding this!). This is pretty rough functionality, and where possible I recommend using more established libraries like HuggingFace for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XDoKtsCTq-f",
        "outputId": "f39819f5-fa51-46da-973c-1a1336c132d9",
        "colab": {
          "referenced_widgets": [
            "f16e699caef243e3bd730cd876600c4a"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f16e699caef243e3bd730cd876600c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'(CNN) President Barack Obama caught in embarrassing new scandal\\n\\nAmerican voters who backed Hillary Clinton gave President Barack Obama a 9.5-point lead over Republican Mitt Romney in the latest CNN/ORC International poll, his lowest level since the last CNN-ORC poll in 2006.\\n\\nRepublican voters'"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model.generate(\"(CNN) President Barack Obama caught in embarrassing new scandal\\n\", max_new_tokens=50, temperature=0.7, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJu9D_reTq-f"
      },
      "source": [
        "## Hook Points\n",
        "\n",
        "The key part of TransformerLens that lets us access and edit intermediate activations are the HookPoints around every model activation. Importantly, this technique will work for *any* model architecture, not just transformers, so long as you're able to edit the model code to add in HookPoints! This is essentially a lightweight library bundled with TransformerLens that should let you take an arbitrary model and make it easier to study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sihwg1fGTq-f"
      },
      "source": [
        "This is implemented by having a HookPoint layer. Each transformer component has a HookPoint for every activation, which wraps around that activation. The HookPoint acts as an identity function, but has a variety of helper functions that allows us to put PyTorch hooks in to edit and access the relevant activation.\n",
        "\n",
        "There is also a `HookedRootModule` class - this is a utility class that the root module should inherit from (root module = the model we run) - it has several utility functions for using hooks well, notably `reset_hooks`, `run_with_cache` and `run_with_hooks`.\n",
        "\n",
        "The default interface is the `run_with_hooks` function on the root module, which lets us run a forwards pass on the model, and pass on a list of hooks paired with layer names to run on that pass.\n",
        "\n",
        "The syntax for a hook is `function(activation, hook)` where `activation` is the activation the hook is wrapped around, and `hook` is the `HookPoint` class the function is attached to. If the function returns a new activation or edits the activation in-place, that replaces the old one, if it returns None then the activation remains as is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_X6-468Tq-f"
      },
      "source": [
        "### Toy Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJe5X3BXTq-f"
      },
      "source": [
        "\n",
        "Here's a simple example of defining a small network with HookPoints:\n",
        "\n",
        "We define a basic network with two layers that each take a scalar input $x$, square it, and add a constant:\n",
        "$x_0=x$, $x_1=x_0^2+3$, $x_2=x_1^2-4$.\n",
        "\n",
        "We wrap the input, each layer's output, and the intermediate value of each layer (the square) in a hook point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3NN2TBbTq-f"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
        "\n",
        "\n",
        "class SquareThenAdd(nn.Module):\n",
        "    def __init__(self, offset):\n",
        "        super().__init__()\n",
        "        self.offset = nn.Parameter(torch.tensor(offset))\n",
        "        self.hook_square = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The hook_square doesn't change the value, but lets us access it\n",
        "        square = self.hook_square(x * x)\n",
        "        return self.offset + square\n",
        "\n",
        "\n",
        "class TwoLayerModel(HookedRootModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = SquareThenAdd(3.0)\n",
        "        self.layer2 = SquareThenAdd(-4.0)\n",
        "        self.hook_in = HookPoint()\n",
        "        self.hook_mid = HookPoint()\n",
        "        self.hook_out = HookPoint()\n",
        "\n",
        "        # We need to call the setup function of HookedRootModule to build an\n",
        "        # internal dictionary of modules and hooks, and to give each hook a name\n",
        "        super().setup()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We wrap the input and each layer's output in a hook - they leave the\n",
        "        # value unchanged (unless there's a hook added to explicitly change it),\n",
        "        # but allow us to access it.\n",
        "        x_in = self.hook_in(x)\n",
        "        x_mid = self.hook_mid(self.layer1(x_in))\n",
        "        x_out = self.hook_out(self.layer2(x_mid))\n",
        "        return x_out\n",
        "\n",
        "\n",
        "model = TwoLayerModel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQJfxXlsTq-f"
      },
      "source": [
        "\n",
        "We can add a cache, to save the activation at each hook point\n",
        "\n",
        "(There's a custom `run_with_cache` function on the root module as a convenience, which is a wrapper around model.forward that return model_out, cache_object - we could also manually add hooks with `run_with_hooks` that store activations in a global caching dictionary. This is often useful if we only want to store, eg, subsets or functions of some activations.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzdpY8b3Tq-f",
        "outputId": "497bba42-5b44-425b-e365-55ff679f4e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output: 780.0\n",
            "Value cached at hook hook_in 5.0\n",
            "Value cached at hook layer1.hook_square 25.0\n",
            "Value cached at hook hook_mid 28.0\n",
            "Value cached at hook layer2.hook_square 784.0\n",
            "Value cached at hook hook_out 780.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "out, cache = model.run_with_cache(torch.tensor(5.0))\n",
        "print(\"Model output:\", out.item())\n",
        "for key in cache:\n",
        "    print(f\"Value cached at hook {key}\", cache[key].item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdLKQGsHTq-f"
      },
      "source": [
        "\n",
        "We can also use hooks to intervene on activations - eg, we can set the intermediate value in layer 2 to zero to change the output to -5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEw7-VTMTq-f",
        "outputId": "9aab5521-ec82-4588-a127-9bf191d9e236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer2.hook_square\n",
            "Output after intervening on layer2.hook_scaled -4.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def set_to_zero_hook(tensor, hook):\n",
        "    print(hook.name)\n",
        "    return torch.tensor(0.0)\n",
        "\n",
        "\n",
        "print(\n",
        "    \"Output after intervening on layer2.hook_scaled\",\n",
        "    model.run_with_hooks(\n",
        "        torch.tensor(5.0), fwd_hooks=[(\"layer2.hook_square\", set_to_zero_hook)]\n",
        "    ).item(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTEKOXhqTq-f"
      },
      "source": [
        "## Loading Pre-Trained Checkpoints\n",
        "\n",
        "There are a lot of interesting questions combining mechanistic interpretability and training dynamics - analysing model capabilities and the underlying circuits that make them possible, and how these change as we train the model.\n",
        "\n",
        "TransformerLens supports these by having several model families with checkpoints throughout training. `HookedTransformer.from_pretrained` can load a checkpoint of a model with the `checkpoint_index` (the label 0 to `num_checkpoints-1`) or `checkpoint_value` (the step or token number, depending on how the checkpoints were labelled)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9snkMDFTq-f"
      },
      "source": [
        "\n",
        "Available models:\n",
        "* All of my interpretability-friendly models have checkpoints available, including:\n",
        "    * The toy models - `attn-only`, `solu`, `gelu` 1L to 4L\n",
        "        * These have ~200 checkpoints, taken on a piecewise linear schedule (more checkpoints near the start of training), up to 22B tokens. Labelled by number of tokens seen.\n",
        "    * The SoLU models trained on 80% Web Text and 20% Python Code (`solu-6l` to `solu-12l`)\n",
        "        * Same checkpoint schedule as the toy models, this time up to 30B tokens\n",
        "    * The SoLU models trained on the pile (`solu-1l-pile` to `solu-12l-pile`)\n",
        "        * These have ~100 checkpoints, taken on a linear schedule, up to 15B tokens. Labelled by number of steps.\n",
        "        * The 12L training crashed around 11B tokens, so is truncated.\n",
        "* The Stanford Centre for Research of Foundation Models trained 5 GPT-2 Small sized and 5 GPT-2 Medium sized models (`stanford-gpt2-small-a` to `e` and `stanford-gpt2-medium-a` to `e`)\n",
        "    * 600 checkpoints, taken on a piecewise linear schedule, labelled by the number of steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZJgeNB2Tq-f"
      },
      "source": [
        "The checkpoint structure and labels is somewhat messy and ad-hoc, so I mostly recommend using the `checkpoint_index` syntax (where you can just count from 0 to the number of checkpoints) rather than `checkpoint_value` syntax (where you need to know the checkpoint schedule, and whether it was labelled with the number of tokens or steps). The helper function `get_checkpoint_labels` tells you the checkpoint schedule for a given model - ie what point was each checkpoint taken at, and what type of label was used.\n",
        "\n",
        "Here are graphs of the schedules for several checkpointed models: (note that the first 3 use a log scale, latter 2 use a linear scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgeTbGoDTq-h",
        "outputId": "b8e06024-47ad-4d11-c28c-565112e1bbd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"9670aaf8-c497-4268-aefd-f91bf035117f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9670aaf8-c497-4268-aefd-f91bf035117f\")) {                    Plotly.newPlot(                        \"9670aaf8-c497-4268-aefd-f91bf035117f\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[262144,2621440,4718592,7077888,9175040,11272192,13631488,15728640,18087936,20185088,22282240,33292288,44302336,55312384,66322432,77332480,88342528,99352576,110362624,121372672,132382720,143392768,154402816,165412864,176422912,187432960,198443008,209453056,220463104,264503296,308281344,352321536,396361728,440401920,484442112,528482304,572522496,616300544,660340736,704380928,748421120,792461312,836501504,880279552,924319744,968359936,1012400128,1056440320,1100480512,1144520704,1188298752,1232338944,1276379136,1320419328,1364459520,1408499712,1452277760,1496317952,1540358144,1584398336,1628438528,1672478720,1716518912,1760296960,1804337152,1848377344,1892417536,1936457728,1980497920,2024275968,2068316160,2112356352,2156396544,2200436736,2420375552,2640314368,2860515328,3080454144,3300392960,3520331776,3740270592,3960471552,4180410368,4400349184,4620288000,4840488960,5060427776,5280366592,5500305408,5720506368,5940445184,6160384000,6380322816,6600523776,6820462592,7040401408,7260340224,7480279040,7700480000,7920418816,8140357632,8360296448,8580497408,8800436224,9020375040,9240313856,9460514816,9680453632,9900392448,10120331264,10340270080,10560471040,10780409856,11000348672,11220287488,11440488448,11660427264,11880366080,12100304896,12320505856,12540444672,12760383488,12980322304,13200523264,13420462080,13640400896,13860339712,14080278528,14300479488,14520418304,14740357120,14960295936,15180496896,15400435712,15620374528,15840313344,16060514304,16280453120,16500391936,16720330752,16940269568,17160470528,17380409344,17600348160,17820286976,18040487936,18260426752,18480365568,18700304384,18920505344,19140444160,19360382976,19580321792,19800522752,20020461568,20240400384,20460339200,20680278016,20900478976,21120417792,21340356608,21560295424,21780496384],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for attn-only-2l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9670aaf8-c497-4268-aefd-f91bf035117f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"87db2943-c842-478c-8c64-5289a60ba868\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87db2943-c842-478c-8c64-5289a60ba868\")) {                    Plotly.newPlot(                        \"87db2943-c842-478c-8c64-5289a60ba868\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[196608,3342336,6291456,9240576,12386304,15335424,18284544,21233664,24379392,27328512,30277632,45219840,60358656,75300864,90243072,105381888,120324096,135266304,150208512,165347328,180289536,195231744,210370560,225312768,240254976,255197184,270336000,285278208,300220416,360382464,420347904,480313344,540278784,600244224,660209664,720371712,780337152,840302592,900268032,960233472,1020198912,1080360960,1140326400,1200291840,1260257280,1320222720,1380384768,1440350208,1500315648,1560281088,1620246528,1680211968,1740374016,1800339456,1860304896,1920270336,1980235776,2040201216,2100363264,2160328704,2220294144,2280259584,2340225024,2400387072,2460352512,2520317952,2580283392,2640248832,2700214272,2760376320,2820341760,2880307200,2940272640,3000238080,3300261888,3600285696,3900309504,4200333312,4500357120,4800380928,5100208128,5400231936,5700255744,6000279552,6300303360,6600327168,6900350976,7200374784,7500201984,7800225792,8100249600,8400273408,8700297216,9000321024,9300344832,9600368640,9900392448,10200219648,10500243456,10800267264,11100291072,11400314880,11700338688,12000362496,12300386304,12600213504,12900237312,13200261120,13500284928,13800308736,14100332544,14400356352,14700380160,15000207360,15300231168,15600254976,15900278784,16200302592,16500326400,16800350208,17100374016,17400201216,17700225024,18000248832,18300272640,18600296448,18900320256,19200344064,19500367872,19800391680,20100218880,20400242688,20700266496,21000290304,21300314112,21600337920,21900361728,22200385536,22500212736,22800236544,23100260352,23400284160,23700307968,24000331776,24300355584,24600379392,24900206592,25200230400,25500254208,25800278016,26100301824,26400325632,26700349440,27000373248,27300200448,27600224256,27900248064,28200271872,28500295680,28800319488,29100343296,29400367104,29700390912],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-12l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87db2943-c842-478c-8c64-5289a60ba868');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a5b83399-2637-48e9-980b-098ce30dc2fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a5b83399-2637-48e9-980b-098ce30dc2fd\")) {                    Plotly.newPlot(                        \"a5b83399-2637-48e9-980b-098ce30dc2fd\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608],\"xaxis\":\"x\",\"y\":[0,10,20,30,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900,15000,15100,15200,15300,15400,15500,15600,15700,15800,15900,16000,16100,16200,16300,16400,16500,16600,16700,16800,16900,17000,17100,17200,17300,17400,17500,17600,17700,17800,17900,18000,18100,18200,18300,18400,18500,18600,18700,18800,18900,19000,19100,19200,19300,19400,19500,19600,19700,19800,19900,20000,21000,22000,23000,24000,25000,26000,27000,28000,29000,30000,31000,32000,33000,34000,35000,36000,37000,38000,39000,40000,41000,42000,43000,44000,45000,46000,47000,48000,49000,50000,51000,52000,53000,54000,55000,56000,57000,58000,59000,60000,61000,62000,63000,64000,65000,66000,67000,68000,69000,70000,71000,72000,73000,74000,75000,76000,77000,78000,79000,80000,81000,82000,83000,84000,85000,86000,87000,88000,89000,90000,91000,92000,93000,94000,95000,96000,97000,98000,99000,100000,101000,102000,103000,104000,105000,106000,107000,108000,109000,110000,111000,112000,113000,114000,115000,116000,117000,118000,119000,120000,121000,122000,123000,124000,125000,126000,127000,128000,129000,130000,131000,132000,133000,134000,135000,136000,137000,138000,139000,140000,141000,142000,143000,144000,145000,146000,147000,148000,149000,150000,151000,152000,153000,154000,155000,156000,157000,158000,159000,160000,161000,162000,163000,164000,165000,166000,167000,168000,169000,170000,171000,172000,173000,174000,175000,176000,177000,178000,179000,180000,181000,182000,183000,184000,185000,186000,187000,188000,189000,190000,191000,192000,193000,194000,195000,196000,197000,198000,199000,200000,201000,202000,203000,204000,205000,206000,207000,208000,209000,210000,211000,212000,213000,214000,215000,216000,217000,218000,219000,220000,221000,222000,223000,224000,225000,226000,227000,228000,229000,230000,231000,232000,233000,234000,235000,236000,237000,238000,239000,240000,241000,242000,243000,244000,245000,246000,247000,248000,249000,250000,251000,252000,253000,254000,255000,256000,257000,258000,259000,260000,261000,262000,263000,264000,265000,266000,267000,268000,269000,270000,271000,272000,273000,274000,275000,276000,277000,278000,279000,280000,281000,282000,283000,284000,285000,286000,287000,288000,289000,290000,291000,292000,293000,294000,295000,296000,297000,298000,299000,300000,301000,302000,303000,304000,305000,306000,307000,308000,309000,310000,311000,312000,313000,314000,315000,316000,317000,318000,319000,320000,321000,322000,323000,324000,325000,326000,327000,328000,329000,330000,331000,332000,333000,334000,335000,336000,337000,338000,339000,340000,341000,342000,343000,344000,345000,346000,347000,348000,349000,350000,351000,352000,353000,354000,355000,356000,357000,358000,359000,360000,361000,362000,363000,364000,365000,366000,367000,368000,369000,370000,371000,372000,373000,374000,375000,376000,377000,378000,379000,380000,381000,382000,383000,384000,385000,386000,387000,388000,389000,390000,391000,392000,393000,394000,395000,396000,397000,398000,399000,400000],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for stanford-gpt2-small-a (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a5b83399-2637-48e9-980b-098ce30dc2fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\")) {                    Plotly.newPlot(                        \"4c28ffe1-8565-4e92-babd-d57cc8bc847d\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"xaxis\":\"x\",\"y\":[832,1664,2496,3328,4160,4992,5824,6656,7488,8320,9152,9984,10816,11648,12480,13312,14144,14976,15808,16640,17472,18304,19136,19968,20800,21632,22464,23296,24128,24960,25792,26624,27456,28288,29120,29952,30784,31616,32448,33280,34112,34944,35776,36608,37440,38272,39104,39936,40768,41600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-1l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4c28ffe1-8565-4e92-babd-d57cc8bc847d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"d92c9f04-9700-4de1-9237-9cba28fcdafb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d92c9f04-9700-4de1-9237-9cba28fcdafb\")) {                    Plotly.newPlot(                        \"d92c9f04-9700-4de1-9237-9cba28fcdafb\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[326,652,978,1304,1630,1956,2282,2608,2934,3260,3586,3912,4238,4564,4890,5216,5542,5868,6194,6520,6846,7172,7498,7824,8150,8476,8802,9128,9454,9780,10106,10432,10758,11084,11410,11736,12062,12388,12714,13040,13366,13692,14018,14344,14670,14996,15322,15648,15974,16300,16626,16952,17278,17604,17930,18256,18582,18908,19234,19560,19886,20212,20538,20864,21190,21516,21842,22168,22494,22820,23146,23472,23798,24124,24450,24776,25102,25428,25754,26080,26406,26732,27058,27384,27710,28036,28362,28688,29014,29340,29666,29992,30318,30644,30970,31296,31622,31948,32274,32600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-6l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d92c9f04-9700-4de1-9237-9cba28fcdafb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens.loading_from_pretrained import get_checkpoint_labels\n",
        "for model_name in [\"attn-only-2l\", \"solu-12l\", \"stanford-gpt2-small-a\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Log scale)\", log_y=True, markers=True)\n",
        "for model_name in [\"solu-1l-pile\", \"solu-6l-pile\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Linear scale)\", log_y=False, markers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9aRvWDXTq-h"
      },
      "source": [
        "### Example: Induction Head Phase Transition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLcnzPQeTq-h"
      },
      "source": [
        "One of the more interesting results analysing circuit formation during training is the [induction head phase transition](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). They find a pretty dramatic shift in models during training - there's a brief period where models go from not having induction heads to having them, which leads to the models suddenly becoming much better at in-context learning (using far back tokens to predict the next token, eg over 500 words back). This is enough of a big deal that it leads to a visible *bump* in the loss curve, where the model's rate of improvement briefly increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uf1s-MeTq-h"
      },
      "source": [
        "As a brief demonstration of the existence of the phase transition, let's load some checkpoints of a two layer model, and see whether they have induction heads. An easy test, as we used above, is to give the model a repeated sequence of random tokens, and to check how good its loss is on the second half. `evals.induction_loss` is a rough util that runs this test on a model.\n",
        "(Note - this is deliberately a rough, non-rigorous test for the purposes of demonstration, eg `evals.induction_loss` by default just runs it on 4 sequences of 384 tokens repeated twice. These results totally don't do the paper justice - go check it out if you want to see the full results!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5A7DCo8Tq-h"
      },
      "source": [
        "In the interests of time and memory, let's look at a handful of checkpoints (chosen to be around the phase change), indices `[10, 25, 35, 60, -1]`. These are roughly 22M, 200M, 500M, 1.6B and 21.8B tokens through training, respectively. (I generally recommend looking things up based on indices, rather than checkpoint value!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL-sLJ23Tq-h"
      },
      "outputs": [],
      "source": [
        "from transformer_lens import evals\n",
        "# We use the two layer model with SoLU activations, chosen fairly arbitrarily as being both small (so fast to download and keep in memory) and pretty good at the induction task.\n",
        "model_name = \"solu-2l\"\n",
        "# We can load a model from a checkpoint by specifying the checkpoint_index, -1 means the final checkpoint\n",
        "checkpoint_indices = [10, 25, 35, 60, -1]\n",
        "checkpointed_models = []\n",
        "tokens_trained_on = []\n",
        "induction_losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ortASQLpTq-h"
      },
      "source": [
        "We load the models, cache them in a list, and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dDTzfqpTq-h"
      },
      "outputs": [],
      "source": [
        "if not IN_GITHUB:\n",
        "    for index in checkpoint_indices:\n",
        "        # Load the model from the relevant checkpoint by index\n",
        "        model_for_this_checkpoint = HookedTransformer.from_pretrained(model_name, checkpoint_index=index, device=device)\n",
        "        checkpointed_models.append(model_for_this_checkpoint)\n",
        "\n",
        "        tokens_seen_for_this_checkpoint = model_for_this_checkpoint.cfg.checkpoint_value\n",
        "        tokens_trained_on.append(tokens_seen_for_this_checkpoint)\n",
        "\n",
        "        induction_loss_for_this_checkpoint = evals.induction_loss(model_for_this_checkpoint, device=device).item()\n",
        "        induction_losses.append(induction_loss_for_this_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC9oEiSNTq-h"
      },
      "source": [
        "We can plot this, and see there's a sharp shift from ~200-500M tokens trained on (note the log scale on the x axis). Interestingly, this is notably earlier than the phase transition in the paper, I'm not sure what's up with that.\n",
        "\n",
        "(To contextualise the numbers, the tokens in the random sequence are uniformly chosen from the first 20,000 tokens (out of ~48,000 total), so random performance is at least $\\ln(20000)\\approx 10$. A naive strategy like \"randomly choose a token that's already appeared in the first half of the sequence (384 elements)\" would get $\\ln(384)\\approx 5.95$, so the model is doing pretty well here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwSMQOL4Tq-h",
        "outputId": "b63af003-9b76-4670-e8ec-419cec49d07b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1b82f6dc-4619-4786-ac45-c3cf11921de0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b82f6dc-4619-4786-ac45-c3cf11921de0\")) {                    Plotly.newPlot(                        \"1b82f6dc-4619-4786-ac45-c3cf11921de0\",                        [],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Induction Loss over training: solu-2l\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b82f6dc-4619-4786-ac45-c3cf11921de0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "line(induction_losses, x=tokens_trained_on, xaxis=\"Tokens Trained On\", yaxis=\"Induction Loss\", title=\"Induction Loss over training: solu-2l\", markers=True, log_x=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c92f4727002149d18498a871a7f5e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2091b2c859f54d3ebe3f1e1add0e93ef",
              "IPY_MODEL_072507e920d5403aa52586d2c9fac973",
              "IPY_MODEL_3287f0bea87f4d4d9db66c4edeacf8d5"
            ],
            "layout": "IPY_MODEL_eee1e9d7530e415ab3e42512ee8e3209"
          }
        },
        "2091b2c859f54d3ebe3f1e1add0e93ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32f0a93ce9443b5a9503107e8e0bf16",
            "placeholder": "​",
            "style": "IPY_MODEL_5e733695b21f4d58816e4570b4d6a827",
            "value": "config.json: 100%"
          }
        },
        "072507e920d5403aa52586d2c9fac973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7147bd0fc7f540ba859d4c1de0953fa1",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db24854bb8bc4cca89f5ceaa4d44af24",
            "value": 665
          }
        },
        "3287f0bea87f4d4d9db66c4edeacf8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb759d7d33942b694c37c87e944949b",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac7ca8ee960434eaf93a9714a729766",
            "value": " 665/665 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "eee1e9d7530e415ab3e42512ee8e3209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32f0a93ce9443b5a9503107e8e0bf16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e733695b21f4d58816e4570b4d6a827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7147bd0fc7f540ba859d4c1de0953fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db24854bb8bc4cca89f5ceaa4d44af24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcb759d7d33942b694c37c87e944949b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac7ca8ee960434eaf93a9714a729766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ecf6ab872f742229b2cb273d1e64537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae3b48589f1b47398ae42509de9682bb",
              "IPY_MODEL_18dff247fe8c466cab56231e7c842a52",
              "IPY_MODEL_83ed570715884746a483b21794dac845"
            ],
            "layout": "IPY_MODEL_f1eded877c1943b6add09f1d673c6834"
          }
        },
        "ae3b48589f1b47398ae42509de9682bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3e0d35a42d48abb5db20b0955fb5ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0389cf284821416ea0e753b58b70755f",
            "value": "model.safetensors: 100%"
          }
        },
        "18dff247fe8c466cab56231e7c842a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c883751fe624ed6b54cd6d6c0ad0c8b",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edb7e9cecf4b4e6199c689f03bdf9202",
            "value": 548105171
          }
        },
        "83ed570715884746a483b21794dac845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3538e6f0d9a7451ba2366e5f848ee49c",
            "placeholder": "​",
            "style": "IPY_MODEL_d1264a2b3d7c4057bd62bf7049eb408f",
            "value": " 548M/548M [00:07&lt;00:00, 68.2MB/s]"
          }
        },
        "f1eded877c1943b6add09f1d673c6834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3e0d35a42d48abb5db20b0955fb5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0389cf284821416ea0e753b58b70755f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c883751fe624ed6b54cd6d6c0ad0c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb7e9cecf4b4e6199c689f03bdf9202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3538e6f0d9a7451ba2366e5f848ee49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1264a2b3d7c4057bd62bf7049eb408f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18cfe09e499b4e04b3435171de3ea2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89cc1cb9f2de43788133ad3500dc7d7c",
              "IPY_MODEL_159fb8938c594ffcb8f9c8641583363c",
              "IPY_MODEL_0965257960af4f8ca2b3985735ec83eb"
            ],
            "layout": "IPY_MODEL_cd8a648b154a4a93b9205e5bdac5314f"
          }
        },
        "89cc1cb9f2de43788133ad3500dc7d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14855bc51e9d473785a4d88233211f2a",
            "placeholder": "​",
            "style": "IPY_MODEL_cd475ddf6723418faf2031998097d413",
            "value": "generation_config.json: 100%"
          }
        },
        "159fb8938c594ffcb8f9c8641583363c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171c6aae133b4b6687e72ce6fe41779f",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d19d71d6066c472b96738c303f10bbd5",
            "value": 124
          }
        },
        "0965257960af4f8ca2b3985735ec83eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a200d6e9676452ba20fad03bc7a188d",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab784bf88dd4cb8ae2852742e212fc5",
            "value": " 124/124 [00:00&lt;00:00, 3.55kB/s]"
          }
        },
        "cd8a648b154a4a93b9205e5bdac5314f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14855bc51e9d473785a4d88233211f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd475ddf6723418faf2031998097d413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "171c6aae133b4b6687e72ce6fe41779f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19d71d6066c472b96738c303f10bbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a200d6e9676452ba20fad03bc7a188d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab784bf88dd4cb8ae2852742e212fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8fe3d93130d4656a6b2f006e228fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d9bac38228c421f85230458ee5d7cf8",
              "IPY_MODEL_26c0dde47219425a9e6adb7df1469e6f",
              "IPY_MODEL_fc020fb6426549beb69285faa9f47b9e"
            ],
            "layout": "IPY_MODEL_b57d629055854c009c18dd76ea0a845b"
          }
        },
        "6d9bac38228c421f85230458ee5d7cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550b5195fafa4151a2444a4a26afd3ee",
            "placeholder": "​",
            "style": "IPY_MODEL_f61603958ef744f08295362b6df2e063",
            "value": "vocab.json: 100%"
          }
        },
        "26c0dde47219425a9e6adb7df1469e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3149a028844b7ba52b9a559120abf7",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cd5adbbb390480fbce95a7854e6b944",
            "value": 1042301
          }
        },
        "fc020fb6426549beb69285faa9f47b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c593c1e5663466c93f349867ee4cb3f",
            "placeholder": "​",
            "style": "IPY_MODEL_bac498965ca2480b8416872d21ccbe86",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 9.78MB/s]"
          }
        },
        "b57d629055854c009c18dd76ea0a845b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550b5195fafa4151a2444a4a26afd3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61603958ef744f08295362b6df2e063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3149a028844b7ba52b9a559120abf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd5adbbb390480fbce95a7854e6b944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c593c1e5663466c93f349867ee4cb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac498965ca2480b8416872d21ccbe86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d524ff688064d78b038c14c394f2d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51a882e6004040cba1ca3b95b8bc2079",
              "IPY_MODEL_c101add0002945c6b9c30eac7926d80f",
              "IPY_MODEL_4394f3ea155a4769b492daef20cfdd5f"
            ],
            "layout": "IPY_MODEL_2fbc921b89ca4674a1a5b76a6ad7e5ed"
          }
        },
        "51a882e6004040cba1ca3b95b8bc2079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491d3df2241c4285884b7eef31361d18",
            "placeholder": "​",
            "style": "IPY_MODEL_670ce8dcff2b44fdb4b22ac413f23b9f",
            "value": "merges.txt: 100%"
          }
        },
        "c101add0002945c6b9c30eac7926d80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07cc0282bf134a24991c8fb06f0a7987",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e42294fe5124b9e95b199fa25da9f94",
            "value": 456318
          }
        },
        "4394f3ea155a4769b492daef20cfdd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513e223681504ca4891829ed46a4063a",
            "placeholder": "​",
            "style": "IPY_MODEL_ab881e7421d34bcb87ba32104cb1e8cc",
            "value": " 456k/456k [00:00&lt;00:00, 5.06MB/s]"
          }
        },
        "2fbc921b89ca4674a1a5b76a6ad7e5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491d3df2241c4285884b7eef31361d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670ce8dcff2b44fdb4b22ac413f23b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07cc0282bf134a24991c8fb06f0a7987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e42294fe5124b9e95b199fa25da9f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513e223681504ca4891829ed46a4063a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab881e7421d34bcb87ba32104cb1e8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "141297a0f9704ff1ae679248d9ef30f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8f8c1c71103461486ec3ed5e7d371d1",
              "IPY_MODEL_684dd6be54df462087a018d0e156ae3c",
              "IPY_MODEL_6f761cdf14264847b58161210280e162"
            ],
            "layout": "IPY_MODEL_7dcc81c28a224e77b6fedfa3641ddf49"
          }
        },
        "d8f8c1c71103461486ec3ed5e7d371d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5189e96f77894d20af55315a45cbb7a5",
            "placeholder": "​",
            "style": "IPY_MODEL_ffb9217cc7654ada86a8753cafca01c8",
            "value": "tokenizer.json: 100%"
          }
        },
        "684dd6be54df462087a018d0e156ae3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c406133446fc47d4a3cccebcf9c0153e",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d958eb0a74246da990e18ca5961d0a1",
            "value": 1355256
          }
        },
        "6f761cdf14264847b58161210280e162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4620181d9e7744639af61fa6693a3930",
            "placeholder": "​",
            "style": "IPY_MODEL_d756cd7440e54289a7ecd7ab38190696",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 21.9MB/s]"
          }
        },
        "7dcc81c28a224e77b6fedfa3641ddf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5189e96f77894d20af55315a45cbb7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb9217cc7654ada86a8753cafca01c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c406133446fc47d4a3cccebcf9c0153e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d958eb0a74246da990e18ca5961d0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4620181d9e7744639af61fa6693a3930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d756cd7440e54289a7ecd7ab38190696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}